{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SimulAI","text":"<p>An extensible Python package with data-driven pipelines for physics-informed machine learning.</p> <p>The SimulAI toolkit provides easy access to state-of-the-art models and algorithms for physics-informed machine learning. Currently, it includes the following methods described in the literature:</p> <ul> <li>Physics-Informed Neural Networks (PINNs)</li> <li>Deep Operator Networks (DeepONets)</li> <li>Variational Encoder-Decoders (VED)</li> <li>Operator Inference (OpInf)</li> <li>Koopman Autoencoders (experimental)</li> <li>Echo State Networks (experimental GPU support)</li> <li>Transformers</li> <li>U-Nets</li> </ul> <p>In addition to the methods above, many more techniques for model reduction and regularization are included in SimulAI. See documentation.</p>"},{"location":"#installing","title":"Installing","text":"<p>Python version requirements: 3.9 \\&lt;= python \\&lt;= 3.11</p>"},{"location":"#using-pip","title":"Using pip","text":"<p>For installing the most recent stable version from PyPI:</p> <pre><code>pip install simulai-toolkit\n</code></pre> <p>For installing from the latest commit sent to GitHub (just for testing and developing purposes):</p> <pre><code>pip uninstall simulai_toolkit\npip install -U git+https://github.com/IBM/simulai@$(git ls-remote git@github.com:IBM/simulai.git  | head -1 | awk '{print $1;}')#egg=simulai_toolkit\n</code></pre>"},{"location":"#contributing-code-to-simulai","title":"Contributing code to SimulAI","text":"<p>If you are interested in directly contributing to this project, please see CONTRIBUTING.</p>"},{"location":"#using-mpi","title":"Using MPI","text":"<p>Some methods implemented on SimulAI support multiprocessing with MPI.</p> <p>In order to use it, you will need a valid MPI distribution, e.g. MPICH, OpenMPI. As an example, you can use <code>conda</code> to install MPICH as follows:</p> <pre><code>conda install -c conda-forge mpich gcc\n</code></pre>"},{"location":"#issues-with-macos","title":"Issues with macOS","text":"<p>If you have problems installing <code>gcc</code> using the command above, we recommend you to install it using Homebrew.</p>"},{"location":"#using-tensorboard","title":"Using Tensorboard","text":"<p>Tensorboard is supported for monitoring neural network training tasks. For a tutorial about how to set it see this example.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Please, refer to the SimulAI API documentation before using the toolkit.</p>"},{"location":"#examples","title":"Examples","text":"<p>Additionally, you can refer to examples in the respective folder.</p>"},{"location":"#license","title":"License","text":"<p>This software is licensed under Apache license 2.0. See LICENSE.</p>"},{"location":"#contributing-code-to-simulai_1","title":"Contributing code to SimulAI","text":"<p>If you are interested in directly contributing to this project, please see CONTRIBUTING.</p>"},{"location":"#how-to-cite-simulai-in-your-publications","title":"How to cite SimulAI in your publications","text":"<p>If you find SimulAI to be useful, please consider citing it in your published work:</p> <pre><code>@misc{simulai,\n  author = {IBM},\n  title = {SimulAI Toolkit},\n  subtitle = {A Python package with data-driven pipelines for physics-informed machine learning},\n  note = \"https://github.com/IBM/simulai\",\n  doi = {10.5281/zenodo.7351516},\n  year = {2022},\n}\n</code></pre> <p>or, via Zenodo:</p> <pre><code>@software{joao_lucas_de_sousa_almeida_2023_7566603,\n      author       = {Jo\u00e3o Lucas de Sousa Almeida and\n                      Leonardo Martins and\n                      Tar\u0131k Kaan Ko\u00e7},\n      title        = {IBM/simulai: 0.99.13},\n      month        = jan,\n      year         = 2023,\n      publisher    = {Zenodo},\n      version      = {0.99.25},\n      doi          = {10.5281/zenodo.7566603},\n      url          = {https://doi.org/10.5281/zenodo.7566603}\n    }\n</code></pre>"},{"location":"#publications","title":"Publications","text":"<p>Jo\u00e3o Lucas de Sousa Almeida, Pedro Roberto Barbosa Rocha, Allan Moreira de Carvalho and Alberto Costa Nogueira Jr. A coupled Variational Encoder-Decoder - DeepONet surrogate model for the Rayleigh-B\u00e9nard convection problem. In When Machine Learning meets Dynamical Systems: Theory and Applications, AAAI, 2023.</p> <p>Jo\u00e3o Lucas S. Almeida, Arthur C. Pires, Klaus F. V. Cid, and Alberto C. Nogueira Jr. Non-intrusive operator inference for chaotic systems. IEEE Transactions on Artificial Intelligence, pages 1--14, 2022.</p> <p>Pedro Roberto Barbosa Rocha, Marcos Sebasti\u00e3o de Paula Gomes, Allan Moreira de Carvalho, Jo\u00e3o Lucas de Sousa Almeida and Alberto Costa Nogueira Jr. Data-driven reduced-order model for atmospheric CO2 dispersion. In AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges, 2022.</p> <p>Pedro Roberto Barbosa Rocha, Jo\u00e3o Lucas de Sousa Almeida, Marcos Sebasti\u00e3o de Paula Gomes, Alberto Costa Nogueira, Reduced-order modeling of the two-dimensional Rayleigh--B\u00e9nard convection flow through a non-intrusive operator inference, Engineering Applications of Artificial Intelligence, Volume 126, Part B, 2023, 106923, ISSN 0952-1976, https://doi.org/10.1016/j.engappai.2023.106923. (https://www.sciencedirect.com/science/article/pii/S0952197623011077)</p>"},{"location":"#references","title":"References","text":"<p>Jaeger, H., Haas, H. (2004). \\\"Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication,\\\" Science, 304 (5667): 78--80.  \\&lt;https://doi.org/10.1126/science.1091277&gt;`_. <p>Lu, L., Jin, P., Pang, G., Zhang, Z., Karniadakis, G. E. (2021). \\\"Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators,\\\" Nature Machine Intelligence, 3 (1): 218--229. ISSN: 2522-5839.  \\&lt;https://doi.org/10.1038/s42256-021-00302-5&gt;`_. <p>Eivazi, H., Le Clainche, S., Hoyas, S., Vinuesa, R. (2022) \\\"Towards extraction of orthogonal and parsimonious non-linear modes from turbulent flows\\\" Expert Systems with Applications, 202. ISSN: 0957-4174.  \\&lt;https://doi.org/10.1016/j.eswa.2022.117038&gt;`_. <p>Raissi, M., Perdikaris, P., Karniadakis, G. E. (2019). \\\"Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations,\\\" Journal of Computational Physics, 378 (1): 686-707. ISSN: 0021-9991.  \\&lt;https://doi.org/10.1016/j.jcp.2018.10.045&gt;`_. <p>Lusch, B., Kutz, J. N., Brunton, S.L. (2018). \\\"Deep learning for universal linear embeddings of nonlinear dynamics,\\\" Nature Communications, 9: 4950. ISSN: 2041-1723.  \\&lt;https://doi.org/10.1038/s41467-018-07210-0&gt;`_. <p>McQuarrie, S., Huang, C. and Willcox, K. (2021). \\\"Data-driven reduced-order models via regularized operator inference for a single-injector combustion process,\\\" Journal of the Royal Society of New Zealand, 51(2): 194-211. ISSN: 0303-6758.  \\&lt;https://doi.org/10.1080/03036758.2020.1863237&gt;`_."},{"location":"simulai_io/","title":"simulai.io","text":""},{"location":"simulai_io/#bypasspreparer","title":"ByPassPreparer","text":"<p>             Bases: <code>DataPreparer</code></p> <p>ByPass class, it fills the DataPreparer blank, but does nothing.</p> Source code in <code>simulai/io.py</code> <pre><code>class ByPassPreparer(DataPreparer):\n    \"\"\"ByPass class, it fills the DataPreparer blank, but does nothing.\"\"\"\n\n    name = \"no_preparer\"\n\n    def __init__(self, channels_last: bool = False) -&gt; None:\n        super().__init__()\n\n        self.channels_last = channels_last\n        self.collapsible_shapes = None\n        self.dtype = None\n\n    def prepare_input_data(self, data: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Prepare input data.\n\n        Args:\n            data (np.ndarray):\n\n        Returns:\n            numpy.ndarray:\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.random.rand(5, 3, 4, 2)\n            &gt;&gt;&gt; preparer = ByPassPreparer()\n            &gt;&gt;&gt; prepared_data = preparer.prepare_input_data(data)\n            &gt;&gt;&gt; prepared_data.shape\n            (5, 3, 4, 2)\n        \"\"\"\n        self.collapsible_shapes = data.shape[1:]\n        return data\n\n    def prepare_output_data(self, data: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Prepare output data.\n\n        Args:\n            data (np.ndarray):\n\n        Returns:\n            numpy.ndarray: The output data in the original format\n\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.random.rand(5, 3)\n            &gt;&gt;&gt; preparer = ByPassPreparer()\n            &gt;&gt;&gt; prepared_data = preparer.prepare_output_data(data)\n            &gt;&gt;&gt; prepared_data.shape\n            (5, 3)\n        \"\"\"\n\n        return data\n\n    def prepare_input_structured_data(self, data: np.recarray) -&gt; np.ndarray:\n        \"\"\"Prepare structured input data by converting it to an ndarray.\n\n        Args:\n            data (np.recarray):\n\n        Returns:\n            np.ndarray: numpy ndarray version of the input data.\n\n        Note:\n            This function is used when the input data is in the form of a structured array and needs to be converted to a regular numpy ndarray.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.array([(1, 'a', 0.5), (2, 'b', 0.6)], dtype=[('a', int), ('b', '|S1'), ('c', float)])\n            &gt;&gt;&gt; preparer = ByPassPreparer()\n            &gt;&gt;&gt; preparer.prepare_input_structured_data(data)\n            array([[1, 'a', 0.5],\n                   [2, 'b', 0.6]])\n        \"\"\"\n\n        return data\n\n    def prepare_output_structured_data(self, data: np.ndarray) -&gt; np.recarray:\n        \"\"\"Prepare structured output data by converting it to a recarray.\n\n        Args:\n            data (np.ndarray):\n\n        Returns:\n            np.recarray: numpy recarray version of the output data.\n\n        Note:\n            This function is used when the output data needs to be in the form of a structured array and is currently in the form of a regular numpy ndarray.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.array([[1, 'a', 0.5], [2, 'b', 0.6]])\n            &gt;&gt;&gt; preparer = ByPassPreparer()\n            &gt;&gt;&gt; preparer.prepare_output_structured_data(data)\n            rec.array([(1, 'a', 0.5), (2, 'b', 0.6)],\n            dtype=[('f0', '&lt;i4'), ('f1', 'S1'), ('f2', '&lt;f8')])\n        \"\"\"\n        return data\n</code></pre>"},{"location":"simulai_io/#simulai.io.ByPassPreparer.prepare_input_data","title":"<code>prepare_input_data(data)</code>","text":"<p>Prepare input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray:</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.random.rand(5, 3, 4, 2)\n&gt;&gt;&gt; preparer = ByPassPreparer()\n&gt;&gt;&gt; prepared_data = preparer.prepare_input_data(data)\n&gt;&gt;&gt; prepared_data.shape\n(5, 3, 4, 2)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_data(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Prepare input data.\n\n    Args:\n        data (np.ndarray):\n\n    Returns:\n        numpy.ndarray:\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.random.rand(5, 3, 4, 2)\n        &gt;&gt;&gt; preparer = ByPassPreparer()\n        &gt;&gt;&gt; prepared_data = preparer.prepare_input_data(data)\n        &gt;&gt;&gt; prepared_data.shape\n        (5, 3, 4, 2)\n    \"\"\"\n    self.collapsible_shapes = data.shape[1:]\n    return data\n</code></pre>"},{"location":"simulai_io/#simulai.io.ByPassPreparer.prepare_input_structured_data","title":"<code>prepare_input_structured_data(data)</code>","text":"<p>Prepare structured input data by converting it to an ndarray.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>recarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: numpy ndarray version of the input data.</p> Note <p>This function is used when the input data is in the form of a structured array and needs to be converted to a regular numpy ndarray.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([(1, 'a', 0.5), (2, 'b', 0.6)], dtype=[('a', int), ('b', '|S1'), ('c', float)])\n&gt;&gt;&gt; preparer = ByPassPreparer()\n&gt;&gt;&gt; preparer.prepare_input_structured_data(data)\narray([[1, 'a', 0.5],\n       [2, 'b', 0.6]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_structured_data(self, data: np.recarray) -&gt; np.ndarray:\n    \"\"\"Prepare structured input data by converting it to an ndarray.\n\n    Args:\n        data (np.recarray):\n\n    Returns:\n        np.ndarray: numpy ndarray version of the input data.\n\n    Note:\n        This function is used when the input data is in the form of a structured array and needs to be converted to a regular numpy ndarray.\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.array([(1, 'a', 0.5), (2, 'b', 0.6)], dtype=[('a', int), ('b', '|S1'), ('c', float)])\n        &gt;&gt;&gt; preparer = ByPassPreparer()\n        &gt;&gt;&gt; preparer.prepare_input_structured_data(data)\n        array([[1, 'a', 0.5],\n               [2, 'b', 0.6]])\n    \"\"\"\n\n    return data\n</code></pre>"},{"location":"simulai_io/#simulai.io.ByPassPreparer.prepare_output_data","title":"<code>prepare_output_data(data)</code>","text":"<p>Prepare output data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: The output data in the original format</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.random.rand(5, 3)\n&gt;&gt;&gt; preparer = ByPassPreparer()\n&gt;&gt;&gt; prepared_data = preparer.prepare_output_data(data)\n&gt;&gt;&gt; prepared_data.shape\n(5, 3)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_data(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Prepare output data.\n\n    Args:\n        data (np.ndarray):\n\n    Returns:\n        numpy.ndarray: The output data in the original format\n\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.random.rand(5, 3)\n        &gt;&gt;&gt; preparer = ByPassPreparer()\n        &gt;&gt;&gt; prepared_data = preparer.prepare_output_data(data)\n        &gt;&gt;&gt; prepared_data.shape\n        (5, 3)\n    \"\"\"\n\n    return data\n</code></pre>"},{"location":"simulai_io/#simulai.io.ByPassPreparer.prepare_output_structured_data","title":"<code>prepare_output_structured_data(data)</code>","text":"<p>Prepare structured output data by converting it to a recarray.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>recarray</code> <p>np.recarray: numpy recarray version of the output data.</p> Note <p>This function is used when the output data needs to be in the form of a structured array and is currently in the form of a regular numpy ndarray.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([[1, 'a', 0.5], [2, 'b', 0.6]])\n&gt;&gt;&gt; preparer = ByPassPreparer()\n&gt;&gt;&gt; preparer.prepare_output_structured_data(data)\nrec.array([(1, 'a', 0.5), (2, 'b', 0.6)],\ndtype=[('f0', '&lt;i4'), ('f1', 'S1'), ('f2', '&lt;f8')])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_structured_data(self, data: np.ndarray) -&gt; np.recarray:\n    \"\"\"Prepare structured output data by converting it to a recarray.\n\n    Args:\n        data (np.ndarray):\n\n    Returns:\n        np.recarray: numpy recarray version of the output data.\n\n    Note:\n        This function is used when the output data needs to be in the form of a structured array and is currently in the form of a regular numpy ndarray.\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.array([[1, 'a', 0.5], [2, 'b', 0.6]])\n        &gt;&gt;&gt; preparer = ByPassPreparer()\n        &gt;&gt;&gt; preparer.prepare_output_structured_data(data)\n        rec.array([(1, 'a', 0.5), (2, 'b', 0.6)],\n        dtype=[('f0', '&lt;i4'), ('f1', 'S1'), ('f2', '&lt;f8')])\n    \"\"\"\n    return data\n</code></pre>"},{"location":"simulai_io/#reshaper","title":"Reshaper","text":"<p>             Bases: <code>DataPreparer</code></p> <p>Reshaper converts n-dimensional arrays to two-dimensional ones, performing a simple reshaping operation F: (n0, n1, ..., nm) -&gt; (n0, prod(n1, ..., nm))</p> Source code in <code>simulai/io.py</code> <pre><code>class Reshaper(DataPreparer):\n    \"\"\"Reshaper converts n-dimensional arrays to two-dimensional ones, performing a simple reshaping operation F: (n0, n1, ..., nm) -&gt; (n0, prod(n1, ..., nm))\"\"\"\n\n    name = \"reshaper\"\n\n    def __init__(self, channels_last: bool = False) -&gt; None:\n        super().__init__()\n        self.channels_last = channels_last\n        self.collapsible_shapes = None\n        self.collapsed_shape = None\n        self.dtype = None\n        self.n_features = None\n\n    def _set_shapes_from_data(self, data: np.ndarray = None) -&gt; None:\n        \"\"\"\n\n        Args:\n            data (np.ndarray, optional): The input data to reshape. (Default value = None)\n        Example::\n\n            &gt;&gt;&gt; reshaper = Reshaper()\n            &gt;&gt;&gt; reshaper._set_shapes_from_data(np.random.random((10,3,4,5)))\n            &gt;&gt;&gt; reshaper.collapsible_shapes\n            (3, 4, 5)\n        \"\"\"\n\n        self.collapsible_shapes = data.shape[1:]\n        self.collapsed_shape = np.prod(self.collapsible_shapes).astype(int)\n        self._is_recarray = data.dtype.names is not None\n        if self._is_recarray:\n            self.n_features = len(data.dtype.names) * self.collapsed_shape\n        else:\n            self.n_features = self.collapsed_shape\n\n    def _prepare_input_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n        \"\"\"\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            This function reshapes the input data to (n0, prod(n1, ..., nm)) shape.\n        Example::\n\n            &gt;&gt;&gt; reshaper = Reshaper()\n            &gt;&gt;&gt; data = np.random.random((10,3,4,5))\n            &gt;&gt;&gt; reshaper.prepare_input_data(data)\n            array([[0.527, 0.936, ... , 0.812],\n                  [0.947, 0.865, ... , 0.947],\n                  ...,\n                  [0.865, 0.947, ... , 0.865],\n                  [0.947, 0.865, ... , 0.947]])\n        \"\"\"\n\n        assert len(data.shape) &gt; 1, \"Error! data must have at least two dimensions\"\n        return data.reshape((data.shape[0], self.n_features))\n\n    def prepare_input_data(self, data: Union[np.ndarray, np.recarray]) -&gt; np.ndarray:\n        \"\"\"Prepare input data for reshaping.\n\n        Args:\n            data (Union[np.ndarray, np.recarray]):\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            - If `data` is a structured numpy array, it will be passed to `_prepare_input_structured_data` function.\n            - If `data` is a plain numpy array, it will be passed to `_prepare_input_data` function.\n        Example::\n\n            &gt;&gt;&gt; reshaper = Reshaper()\n            &gt;&gt;&gt; input_data = np.random.rand(2, 3, 4)\n            &gt;&gt;&gt; reshaper.prepare_input_data(input_data)\n            array([[ 0.948...,  0.276...,  0.967...,  0.564...],\n                [ 0.276...,  0.948...,  0.564...,  0.967...],\n                [ 0.276...,  0.948...,  0.564...,  0.967...],\n                [ 0.948...,  0.276...,  0.967...,  0.564...],\n                [ 0.276...,  0.948...,  0.564...,  0.967...],\n                [ 0.276...,  0.948...,  0.564...,  0.967...]])\n        \"\"\"\n\n        self._set_shapes_from_data(data)\n        if self._is_recarray:\n            return self._prepare_input_structured_data(data)\n        else:\n            return self._prepare_input_data(data)\n\n    def _reshape_to_output(self, data: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Reshape the data to its original shape before reshaping.\n\n        Args:\n            data (np.ndarray):\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            The original shape of the data is stored in `collapsible_shapes` attribute.\n        Example::\n\n            &gt;&gt;&gt; reshaper = Reshaper()\n            &gt;&gt;&gt; input_data = np.random.rand(2, 3, 4)\n            &gt;&gt;&gt; reshaper._set_shapes_from_data(input_data)\n            &gt;&gt;&gt; reshaped_data = reshaper._reshape_to_output(input_data.flatten())\n            &gt;&gt;&gt; reshaped_data.shape\n            (2, 3, 4)\n        \"\"\"\n\n        return data.reshape((data.shape[0],) + self.collapsible_shapes)\n\n    def _prepare_output_data(\n        self, data: np.ndarray = None, single: bool = False\n    ) -&gt; np.ndarray:\n        \"\"\"Prepare the input data to be in the shape and format expected by the model.\n\n        Args:\n            data (np.ndarray, optional): The input data to be prepared, by default None\n            single (bool, optional):  (Default value = False)\n\n        Returns:\n            np.ndarray: The prepared input data\n\n        \"\"\"\n        if self._is_recarray:\n            return self._prepare_output_structured_data(data)\n        else:\n            return self._reshape_to_output(data)\n\n    def prepare_output_data(self, data: np.ndarray, single: bool = False) -&gt; np.ndarray:\n        \"\"\"Prepare the input data to be in the shape and format expected by the model.\n\n        Args:\n            data (np.ndarray): The input data to be prepared\n            single (bool, optional):  (Default value = False)\n\n        Returns:\n            np.ndarray: The prepared input data\n\n        \"\"\"\n        return self._prepare_output_data(data)\n\n    def _prepare_input_structured_data(self, data: np.recarray = None) -&gt; np.ndarray:\n        \"\"\"Prepare the input structured data to be in the shape and format expected by the model.\n\n        Args:\n            data (np.recarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray: The prepared input structured data\n\n        \"\"\"\n        self.dtype = data.dtype\n        self._set_shapes_from_data(data)\n        data_ = recfunctions.structured_to_unstructured(data)\n        reshaped_data_ = self._prepare_input_data(data_)\n        return reshaped_data_\n\n    def prepare_input_structured_data(self, data: np.recarray = None) -&gt; np.ndarray:\n        \"\"\"Prepare the input structured data to be in the shape and format expected by the model.\n\n        Args:\n            data (np.recarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray: The prepared input structured data\n\n        \"\"\"\n        return self._prepare_input_structured_data(data)\n\n    def prepare_output_structured_data(self, data: np.ndarray = None) -&gt; np.recarray:\n        \"\"\"Prepare the output data to be in the shape and format expected by the user.\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.recarray: The prepared output structured data\n\n        \"\"\"\n        return self._prepare_output_structured_data(data)\n\n    def _prepare_output_structured_data(self, data: np.ndarray = None) -&gt; np.recarray:\n        \"\"\"Prepare the output data to be in the shape and format expected by the user.\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.recarray: The prepared output structured data\n\n        \"\"\"\n        data = data.reshape(\n            (data.shape[0],) + self.collapsible_shapes + (len(self.dtype),)\n        )\n        output_data = recfunctions.unstructured_to_structured(data, self.dtype)\n        output_data = self._reshape_to_output(output_data)\n        return output_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.Reshaper.prepare_input_data","title":"<code>prepare_input_data(data)</code>","text":"<p>Prepare input data for reshaping.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[ndarray, recarray]</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <ul> <li>If <code>data</code> is a structured numpy array, it will be passed to <code>_prepare_input_structured_data</code> function.</li> <li>If <code>data</code> is a plain numpy array, it will be passed to <code>_prepare_input_data</code> function.</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; reshaper = Reshaper()\n&gt;&gt;&gt; input_data = np.random.rand(2, 3, 4)\n&gt;&gt;&gt; reshaper.prepare_input_data(input_data)\narray([[ 0.948...,  0.276...,  0.967...,  0.564...],\n    [ 0.276...,  0.948...,  0.564...,  0.967...],\n    [ 0.276...,  0.948...,  0.564...,  0.967...],\n    [ 0.948...,  0.276...,  0.967...,  0.564...],\n    [ 0.276...,  0.948...,  0.564...,  0.967...],\n    [ 0.276...,  0.948...,  0.564...,  0.967...]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_data(self, data: Union[np.ndarray, np.recarray]) -&gt; np.ndarray:\n    \"\"\"Prepare input data for reshaping.\n\n    Args:\n        data (Union[np.ndarray, np.recarray]):\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        - If `data` is a structured numpy array, it will be passed to `_prepare_input_structured_data` function.\n        - If `data` is a plain numpy array, it will be passed to `_prepare_input_data` function.\n    Example::\n\n        &gt;&gt;&gt; reshaper = Reshaper()\n        &gt;&gt;&gt; input_data = np.random.rand(2, 3, 4)\n        &gt;&gt;&gt; reshaper.prepare_input_data(input_data)\n        array([[ 0.948...,  0.276...,  0.967...,  0.564...],\n            [ 0.276...,  0.948...,  0.564...,  0.967...],\n            [ 0.276...,  0.948...,  0.564...,  0.967...],\n            [ 0.948...,  0.276...,  0.967...,  0.564...],\n            [ 0.276...,  0.948...,  0.564...,  0.967...],\n            [ 0.276...,  0.948...,  0.564...,  0.967...]])\n    \"\"\"\n\n    self._set_shapes_from_data(data)\n    if self._is_recarray:\n        return self._prepare_input_structured_data(data)\n    else:\n        return self._prepare_input_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.Reshaper.prepare_input_structured_data","title":"<code>prepare_input_structured_data(data=None)</code>","text":"<p>Prepare the input structured data to be in the shape and format expected by the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>recarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The prepared input structured data</p> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_structured_data(self, data: np.recarray = None) -&gt; np.ndarray:\n    \"\"\"Prepare the input structured data to be in the shape and format expected by the model.\n\n    Args:\n        data (np.recarray, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray: The prepared input structured data\n\n    \"\"\"\n    return self._prepare_input_structured_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.Reshaper.prepare_output_data","title":"<code>prepare_output_data(data, single=False)</code>","text":"<p>Prepare the input data to be in the shape and format expected by the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The input data to be prepared</p> required <code>single</code> <code>bool</code> <p>(Default value = False)</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The prepared input data</p> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_data(self, data: np.ndarray, single: bool = False) -&gt; np.ndarray:\n    \"\"\"Prepare the input data to be in the shape and format expected by the model.\n\n    Args:\n        data (np.ndarray): The input data to be prepared\n        single (bool, optional):  (Default value = False)\n\n    Returns:\n        np.ndarray: The prepared input data\n\n    \"\"\"\n    return self._prepare_output_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.Reshaper.prepare_output_structured_data","title":"<code>prepare_output_structured_data(data=None)</code>","text":"<p>Prepare the output data to be in the shape and format expected by the user.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>recarray</code> <p>np.recarray: The prepared output structured data</p> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_structured_data(self, data: np.ndarray = None) -&gt; np.recarray:\n    \"\"\"Prepare the output data to be in the shape and format expected by the user.\n\n    Args:\n        data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        np.recarray: The prepared output structured data\n\n    \"\"\"\n    return self._prepare_output_structured_data(data)\n</code></pre>"},{"location":"simulai_io/#scalerreshaper","title":"ScalerReshaper","text":"<p>             Bases: <code>Reshaper</code></p> <p>ScalerReshaper is a class that inherits from the Reshaper class and performs additional scaling on the input data.</p> Source code in <code>simulai/io.py</code> <pre><code>class ScalerReshaper(Reshaper):\n\n    \"\"\"ScalerReshaper is a class that inherits from the Reshaper class and performs additional scaling on the input data.\"\"\"\n\n    name = \"scalerreshaper\"\n\n    def __init__(\n        self, bias: float = 0.0, scale: float = 1.0, channels_last: bool = False\n    ) -&gt; None:\n        \"\"\"Reshaper converts n-dimensional arrays to two-dimensional ones, performing a\n        simple reshaping operation F: (n0, n1, ..., nm) -&gt; (n0, prod(n1, ..., nm))\n\n        Args:\n            bias (float, optional):  (Default value = 0.0)\n            scale (float, optional):  (Default value = 1.0)\n            channels_last (bool, optional):  (Default value = False)\n        \"\"\"\n        super().__init__(channels_last=channels_last)\n        self.bias = bias\n        self.scale = scale\n\n    def prepare_input_data(\n        self, data: Union[np.ndarray, np.recarray] = None, *args, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"Prepare the input data by subtracting the bias and scaling the data.\n\n        Args:\n            data (Union[np.ndarray, np.recarray], optional): The input data to be prepared (Default value = None)\n            *args:\n            **kwargs:\n\n        Returns:\n            np.ndarray: The prepared input data\n\n        Note:\n            If the input data is a structured array, the method 'prepare_input_structured_data' will be called instead.\n        Example::\n\n            &gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n            &gt;&gt;&gt; reshaper.prepare_input_data(np.array([1, 2, 3]))\n            array([-4.5, -3.5, -2.5])\n        \"\"\"\n\n        if data.dtype.names is None:\n            return super(ScalerReshaper, self).prepare_input_data(\n                (data - self.bias) / self.scale, *args, **kwargs\n            )\n        else:\n            return self.prepare_input_structured_data(data, *args, **kwargs)\n\n    def prepare_output_data(\n        self, data: Union[np.ndarray, np.recarray] = None, *args, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"Prepare the output data by scaling it and adding the bias.\n\n        Args:\n            data (Union[np.ndarray, np.recarray], optional): The output data to be prepared (Default value = None)\n            *args:\n            **kwargs\n\n        Returns:\n            np.ndarray: The prepared output data\n\n        Note:\n            If the input data is a structured array, the method 'prepare_output_structured_data' will be called\n        Example::\n\n            &gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n            &gt;&gt;&gt; reshaper.prepare_output_data(np.array([1, 2, 3]))\n            array([12., 14., 16.])\n        \"\"\"\n\n        if not self._is_recarray:\n            return super(ScalerReshaper, self).prepare_output_data(\n                data * self.scale + self.bias, *args, **kwargs\n            )\n        else:\n            return self.prepare_output_structured_data(data)\n\n    def _get_structured_bias_scale(self, dtype: np.dtype = None) -&gt; Tuple[dict, dict]:\n        \"\"\"Get the bias and scale values for each field of a structured array.\n\n        Args:\n            dtype (np.dtype, optional):  (Default value = None)\n\n        Returns:\n            Tuple[dict, dict]: A tuple of two dictionaries, the first containing the bias values for each field and the second\n\n        Note:\n            If the bias and scale attributes are floats, they will be used for all fields.\n        Example::\n\n            &gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n            &gt;&gt;&gt; reshaper._get_structured_bias_scale(np.dtype([('a', float), ('b', float)]))\n            ({'a': 10, 'b': 10}, {'a': 2, 'b': 2})\n        \"\"\"\n\n        bias = self.bias\n        if isinstance(self.bias, float):\n            bias = {n: self.bias for n in dtype.names}\n        scale = self.scale\n        if isinstance(self.scale, float):\n            scale = {n: self.scale for n in dtype.names}\n\n        return bias, scale\n\n    def prepare_input_structured_data(\n        self, data: np.recarray = None, *args, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"Scale and reshape structured data (np.recarray) before passing it to the next layer.\n\n        Args:\n            data (np.recarray, optional): structured data to be transformed (Default value = None)\n            *args (Additional arguments passed to the parent class):\n            **kwargs\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.\n        Example::\n\n            &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[(\"a\", int), (\"b\", int), (\"c\", int)])\n            &gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n            &gt;&gt;&gt; reshaper.prepare_input_structured_data(data)\n                array([[-0.5, 0.33333333, 0.75      ],\n                    [ 1.5, 1.66666667, 2.        ]])\n        \"\"\"\n\n        bias, scale = self._get_structured_bias_scale(data.dtype)\n        data = data.copy()\n        names = data.dtype.names\n        for name in names:\n            data[name] = (data[name] - bias[name]) / scale[name]\n        return super(ScalerReshaper, self).prepare_input_structured_data(\n            data, *args, **kwargs\n        )\n\n    def prepare_output_structured_data(\n        self, data: np.ndarray = None, *args, **kwargs\n    ) -&gt; np.recarray:\n        \"\"\"Scale and reshape structured data (np.recarray) before passing it to the next layer.\n\n        Args:\n            data (np.ndarray, optional): structured data to be transformed (Default value = None)\n            *args (Additional arguments passed to the parent class):\n            **kwargs:\n\n        Returns:\n            np.recarray:\n\n        Note:\n            - The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.\n        Example::\n\n            &gt;&gt;&gt; data = np.array([[-0.5, 0.33333333, 0.75      ],\n            &gt;&gt;&gt;                  [ 1.5, 1.66666667, 2.        ]])\n            &gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n            &gt;&gt;&gt; reshaper.prepare_output_structured_data(data)\n            rec.array([(0., 2.,  6.), (6., 8., 12.)],\n                dtype=[('a', '&lt;f8'), ('b', '&lt;f8'), ('c', '&lt;f8')])\n        \"\"\"\n\n        bias, scale = self._get_structured_bias_scale(self.dtype)\n        data = super(ScalerReshaper, self).prepare_output_structured_data(\n            data, *args, **kwargs\n        )\n        data = data.copy()\n        for name in self.dtype.names:\n            data[name] = data[name] * scale[name] + bias[name]\n        return data\n</code></pre>"},{"location":"simulai_io/#simulai.io.ScalerReshaper.__init__","title":"<code>__init__(bias=0.0, scale=1.0, channels_last=False)</code>","text":"<p>Reshaper converts n-dimensional arrays to two-dimensional ones, performing a simple reshaping operation F: (n0, n1, ..., nm) -&gt; (n0, prod(n1, ..., nm))</p> <p>Parameters:</p> Name Type Description Default <code>bias</code> <code>float</code> <p>(Default value = 0.0)</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>(Default value = 1.0)</p> <code>1.0</code> <code>channels_last</code> <code>bool</code> <p>(Default value = False)</p> <code>False</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(\n    self, bias: float = 0.0, scale: float = 1.0, channels_last: bool = False\n) -&gt; None:\n    \"\"\"Reshaper converts n-dimensional arrays to two-dimensional ones, performing a\n    simple reshaping operation F: (n0, n1, ..., nm) -&gt; (n0, prod(n1, ..., nm))\n\n    Args:\n        bias (float, optional):  (Default value = 0.0)\n        scale (float, optional):  (Default value = 1.0)\n        channels_last (bool, optional):  (Default value = False)\n    \"\"\"\n    super().__init__(channels_last=channels_last)\n    self.bias = bias\n    self.scale = scale\n</code></pre>"},{"location":"simulai_io/#simulai.io.ScalerReshaper.prepare_input_data","title":"<code>prepare_input_data(data=None, *args, **kwargs)</code>","text":"<p>Prepare the input data by subtracting the bias and scaling the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[ndarray, recarray]</code> <p>The input data to be prepared (Default value = None)</p> <code>None</code> <code>*args</code> <code>()</code> <code>**kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The prepared input data</p> Note <p>If the input data is a structured array, the method 'prepare_input_structured_data' will be called instead.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n&gt;&gt;&gt; reshaper.prepare_input_data(np.array([1, 2, 3]))\narray([-4.5, -3.5, -2.5])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_data(\n    self, data: Union[np.ndarray, np.recarray] = None, *args, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Prepare the input data by subtracting the bias and scaling the data.\n\n    Args:\n        data (Union[np.ndarray, np.recarray], optional): The input data to be prepared (Default value = None)\n        *args:\n        **kwargs:\n\n    Returns:\n        np.ndarray: The prepared input data\n\n    Note:\n        If the input data is a structured array, the method 'prepare_input_structured_data' will be called instead.\n    Example::\n\n        &gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n        &gt;&gt;&gt; reshaper.prepare_input_data(np.array([1, 2, 3]))\n        array([-4.5, -3.5, -2.5])\n    \"\"\"\n\n    if data.dtype.names is None:\n        return super(ScalerReshaper, self).prepare_input_data(\n            (data - self.bias) / self.scale, *args, **kwargs\n        )\n    else:\n        return self.prepare_input_structured_data(data, *args, **kwargs)\n</code></pre>"},{"location":"simulai_io/#simulai.io.ScalerReshaper.prepare_input_structured_data","title":"<code>prepare_input_structured_data(data=None, *args, **kwargs)</code>","text":"<p>Scale and reshape structured data (np.recarray) before passing it to the next layer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>recarray</code> <p>structured data to be transformed (Default value = None)</p> <code>None</code> <code>*args</code> <code>Additional arguments passed to the parent class</code> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <p>The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[(\"a\", int), (\"b\", int), (\"c\", int)])\n&gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n&gt;&gt;&gt; reshaper.prepare_input_structured_data(data)\n    array([[-0.5, 0.33333333, 0.75      ],\n        [ 1.5, 1.66666667, 2.        ]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_structured_data(\n    self, data: np.recarray = None, *args, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Scale and reshape structured data (np.recarray) before passing it to the next layer.\n\n    Args:\n        data (np.recarray, optional): structured data to be transformed (Default value = None)\n        *args (Additional arguments passed to the parent class):\n        **kwargs\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.\n    Example::\n\n        &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[(\"a\", int), (\"b\", int), (\"c\", int)])\n        &gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n        &gt;&gt;&gt; reshaper.prepare_input_structured_data(data)\n            array([[-0.5, 0.33333333, 0.75      ],\n                [ 1.5, 1.66666667, 2.        ]])\n    \"\"\"\n\n    bias, scale = self._get_structured_bias_scale(data.dtype)\n    data = data.copy()\n    names = data.dtype.names\n    for name in names:\n        data[name] = (data[name] - bias[name]) / scale[name]\n    return super(ScalerReshaper, self).prepare_input_structured_data(\n        data, *args, **kwargs\n    )\n</code></pre>"},{"location":"simulai_io/#simulai.io.ScalerReshaper.prepare_output_data","title":"<code>prepare_output_data(data=None, *args, **kwargs)</code>","text":"<p>Prepare the output data by scaling it and adding the bias.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[ndarray, recarray]</code> <p>The output data to be prepared (Default value = None)</p> <code>None</code> <code>*args</code> <code>()</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The prepared output data</p> Note <p>If the input data is a structured array, the method 'prepare_output_structured_data' will be called</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n&gt;&gt;&gt; reshaper.prepare_output_data(np.array([1, 2, 3]))\narray([12., 14., 16.])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_data(\n    self, data: Union[np.ndarray, np.recarray] = None, *args, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Prepare the output data by scaling it and adding the bias.\n\n    Args:\n        data (Union[np.ndarray, np.recarray], optional): The output data to be prepared (Default value = None)\n        *args:\n        **kwargs\n\n    Returns:\n        np.ndarray: The prepared output data\n\n    Note:\n        If the input data is a structured array, the method 'prepare_output_structured_data' will be called\n    Example::\n\n        &gt;&gt;&gt; reshaper = ScalerReshaper(bias=10, scale=2)\n        &gt;&gt;&gt; reshaper.prepare_output_data(np.array([1, 2, 3]))\n        array([12., 14., 16.])\n    \"\"\"\n\n    if not self._is_recarray:\n        return super(ScalerReshaper, self).prepare_output_data(\n            data * self.scale + self.bias, *args, **kwargs\n        )\n    else:\n        return self.prepare_output_structured_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.ScalerReshaper.prepare_output_structured_data","title":"<code>prepare_output_structured_data(data=None, *args, **kwargs)</code>","text":"<p>Scale and reshape structured data (np.recarray) before passing it to the next layer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>structured data to be transformed (Default value = None)</p> <code>None</code> <code>*args</code> <code>Additional arguments passed to the parent class</code> <code>()</code> <code>**kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <code>recarray</code> <p>np.recarray:</p> Note <ul> <li>The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([[-0.5, 0.33333333, 0.75      ],\n&gt;&gt;&gt;                  [ 1.5, 1.66666667, 2.        ]])\n&gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n&gt;&gt;&gt; reshaper.prepare_output_structured_data(data)\nrec.array([(0., 2.,  6.), (6., 8., 12.)],\n    dtype=[('a', '&lt;f8'), ('b', '&lt;f8'), ('c', '&lt;f8')])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_structured_data(\n    self, data: np.ndarray = None, *args, **kwargs\n) -&gt; np.recarray:\n    \"\"\"Scale and reshape structured data (np.recarray) before passing it to the next layer.\n\n    Args:\n        data (np.ndarray, optional): structured data to be transformed (Default value = None)\n        *args (Additional arguments passed to the parent class):\n        **kwargs:\n\n    Returns:\n        np.recarray:\n\n    Note:\n        - The bias and scale parameters are expected to be provided in the form of dictionaries, where keys are field names and values are the corresponding bias and scale values for those fields.\n    Example::\n\n        &gt;&gt;&gt; data = np.array([[-0.5, 0.33333333, 0.75      ],\n        &gt;&gt;&gt;                  [ 1.5, 1.66666667, 2.        ]])\n        &gt;&gt;&gt; reshaper = ScalerReshaper(bias={'a': 1, 'b': 2, 'c': 3}, scale={'a': 2, 'b': 3, 'c': 4})\n        &gt;&gt;&gt; reshaper.prepare_output_structured_data(data)\n        rec.array([(0., 2.,  6.), (6., 8., 12.)],\n            dtype=[('a', '&lt;f8'), ('b', '&lt;f8'), ('c', '&lt;f8')])\n    \"\"\"\n\n    bias, scale = self._get_structured_bias_scale(self.dtype)\n    data = super(ScalerReshaper, self).prepare_output_structured_data(\n        data, *args, **kwargs\n    )\n    data = data.copy()\n    for name in self.dtype.names:\n        data[name] = data[name] * scale[name] + bias[name]\n    return data\n</code></pre>"},{"location":"simulai_io/#mapvalid","title":"MapValid","text":"<p>             Bases: <code>Reshaper</code></p> <p>MapValid is a reshaper class that converts n-dimensional arrays to two-dimensional ones performing a valid values mapping operation F: F: data.shape = (n0, n1, ..., nm) -&gt; data'.shape = (n0, n_valids) where n_valids is the number of valid elements in the data array. This class is useful for datasets in which there are invalid data.</p> Source code in <code>simulai/io.py</code> <pre><code>class MapValid(Reshaper):\n    \"\"\"MapValid is a reshaper class that converts n-dimensional arrays to two-dimensional ones performing a valid values\n    mapping operation F: F: data.shape = (n0, n1, ..., nm) -&gt; data'.shape = (n0, n_valids)\n    where n_valids is the number of valid elements in the data array.\n    This class is useful for datasets in which there are invalid data.\n\n    \"\"\"\n\n    name = \"map_valid\"\n\n    def __init__(\n        self, config: dict = None, mask=None, channels_last: bool = True\n    ) -&gt; None:\n        \"\"\"Initialize the MapValid class with the configurations and mask passed as parameters.\n\n        Args:\n            config (dict, optional): configurations dictionary, by default None\n            mask (int, np.NaN, np.inf, optional, optional): mask to select the invalid values, by default None\n            channels_last (bool, optional): if set to True, move the channel dimension to the last, by default True\n\n        \"\"\"\n        super().__init__()\n\n        self.default_dtype = \"float64\"\n\n        if mask == 0 or isinstance(mask, int):\n            self.replace_mask_with_large_number = False\n        else:\n            self.replace_mask_with_large_number = True\n\n        self.return_the_same_mask = True\n\n        for key, value in config.items():\n            setattr(self, key, value)\n\n        # Default value for very large numbers\n        self.large_number = 1e15\n\n        if not mask or self.replace_mask_with_large_number:\n            self.mask = self.large_number\n        else:\n            self.mask = mask\n\n        self.mask_ = mask\n\n        for key, value in config.items():\n            setattr(self, key, value)\n\n        self.valid_indices = None\n        self.original_dimensions = None\n\n        self.channels_last = channels_last\n\n    def prepare_input_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n        \"\"\"Internal input data preparer, executed for each label of the structured array\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            - MapValid converts n-dimensional arrays to two-dimensional ones performing a valid values\n            mapping operation F: F: data.shape = (n0, n1, ..., nm) -&gt; data'.shape = (n0, n_valids)\n            n_valids = dim([k in data[0, ...] if k != mask])\n            - WARNING: the invalid positions are expected to be static in relation to n0.\n        Example::\n\n            &gt;&gt;&gt; data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n            &gt;&gt;&gt; prepare_input_data(data)\n            array([[1, 2, 3],\n                   [5, 6, 7],\n                   [9, 10, 11]])\n        \"\"\"\n\n        data = super(MapValid, self).prepare_input_data(data)\n\n        if self.mask == self.large_number:\n            self.valid_indices_ = np.where(data[0, ...] &lt; self.mask)\n\n        elif not str(self.mask).isnumeric() or isinstance(self.mask, int):\n            self.valid_indices_ = np.where(data[0, ...] != self.mask)\n\n        else:\n            raise Exception(\n                \"The chosen mask {} does not fit in any supported case\".format(\n                    self.mask\n                )\n            )\n\n        samples_dim = data.shape[0]\n\n        valid_indices = (slice(0, samples_dim),) + self.valid_indices_\n\n        return data[valid_indices]\n\n    def prepare_output_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n        \"\"\"Prepare output data for the MapValid operation.\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            - The reshaped data will have shape (n0, n_valids) where n0 is the number of samples and n_valids are the number of valid values in the data.\n            - If the return_the_same_mask attribute is set to True, the mask used to select the invalid values will be returned. Otherwise, the reshaped data will be filled with NaN.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; reshaper = MapValid()\n            &gt;&gt;&gt; data = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n            &gt;&gt;&gt; reshaper.prepare_output_data(data)\n            array([[[ 1.,  2.,  3.],\n                    [ 4.,  5.,  6.]],\n        \"\"\"\n\n        immutable_shape = data.shape[0]\n\n        final_shape = (\n            immutable_shape,\n            self.n_features,\n        )\n\n        if self.return_the_same_mask:\n            mask = self.mask_\n        else:\n            mask = np.NaN  # For practical purposes\n        reshaped_data = np.full(final_shape, mask)\n\n        if not reshaped_data.dtype.type == self.default_dtype:\n            reshaped_data = reshaped_data.astype(self.default_dtype)\n\n        samples_dim = data.shape[0]\n        valid_indices = (slice(0, samples_dim),) + self.valid_indices_\n\n        reshaped_data[valid_indices] = data\n\n        reshaped_data = super(MapValid, self).prepare_output_data(reshaped_data)\n\n        return reshaped_data\n\n    def prepare_input_structured_data(self, data: np.recarray = None) -&gt; np.ndarray:\n        \"\"\"This function is used to prepare structured input data for further processing.\n\n        Args:\n            data (np.recarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            This function is a wrapper function that calls the 'prepare_input_data' function internally.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[('a', int), ('b', int), ('c', int)])\n            &gt;&gt;&gt; model = MapValid()\n            &gt;&gt;&gt; prepared_data = MapValid.prepare_input_structured_data(data)\n            &gt;&gt;&gt; prepared_data\n            array([[1, 2, 3],\n                  [4, 5, 6]])\n        \"\"\"\n\n        return self.prepare_input_data(data)\n\n    def prepare_output_structured_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n        \"\"\"This function is used to prepare structured output data for further processing.\n\n        Args:\n            data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            This function is a wrapper function that calls the 'prepare_output_data' function internally.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6]])\n            &gt;&gt;&gt; model = MapValid()\n            &gt;&gt;&gt; prepared_data = MapValid.prepare_output_structured_data(data)\n            &gt;&gt;&gt; prepared_data\n            array([[1, 2, 3],\n                [4, 5, 6]])\n        \"\"\"\n\n        return self.prepare_output_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.MapValid.__init__","title":"<code>__init__(config=None, mask=None, channels_last=True)</code>","text":"<p>Initialize the MapValid class with the configurations and mask passed as parameters.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>configurations dictionary, by default None</p> <code>None</code> <code>mask</code> <code>(int, NaN, inf, optional)</code> <p>mask to select the invalid values, by default None</p> <code>None</code> <code>channels_last</code> <code>bool</code> <p>if set to True, move the channel dimension to the last, by default True</p> <code>True</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(\n    self, config: dict = None, mask=None, channels_last: bool = True\n) -&gt; None:\n    \"\"\"Initialize the MapValid class with the configurations and mask passed as parameters.\n\n    Args:\n        config (dict, optional): configurations dictionary, by default None\n        mask (int, np.NaN, np.inf, optional, optional): mask to select the invalid values, by default None\n        channels_last (bool, optional): if set to True, move the channel dimension to the last, by default True\n\n    \"\"\"\n    super().__init__()\n\n    self.default_dtype = \"float64\"\n\n    if mask == 0 or isinstance(mask, int):\n        self.replace_mask_with_large_number = False\n    else:\n        self.replace_mask_with_large_number = True\n\n    self.return_the_same_mask = True\n\n    for key, value in config.items():\n        setattr(self, key, value)\n\n    # Default value for very large numbers\n    self.large_number = 1e15\n\n    if not mask or self.replace_mask_with_large_number:\n        self.mask = self.large_number\n    else:\n        self.mask = mask\n\n    self.mask_ = mask\n\n    for key, value in config.items():\n        setattr(self, key, value)\n\n    self.valid_indices = None\n    self.original_dimensions = None\n\n    self.channels_last = channels_last\n</code></pre>"},{"location":"simulai_io/#simulai.io.MapValid.prepare_input_data","title":"<code>prepare_input_data(data=None)</code>","text":"<p>Internal input data preparer, executed for each label of the structured array</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <ul> <li>MapValid converts n-dimensional arrays to two-dimensional ones performing a valid values mapping operation F: F: data.shape = (n0, n1, ..., nm) -&gt; data'.shape = (n0, n_valids) n_valids = dim([k in data[0, ...] if k != mask])</li> <li>WARNING: the invalid positions are expected to be static in relation to n0.</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n&gt;&gt;&gt; prepare_input_data(data)\narray([[1, 2, 3],\n       [5, 6, 7],\n       [9, 10, 11]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n    \"\"\"Internal input data preparer, executed for each label of the structured array\n\n    Args:\n        data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        - MapValid converts n-dimensional arrays to two-dimensional ones performing a valid values\n        mapping operation F: F: data.shape = (n0, n1, ..., nm) -&gt; data'.shape = (n0, n_valids)\n        n_valids = dim([k in data[0, ...] if k != mask])\n        - WARNING: the invalid positions are expected to be static in relation to n0.\n    Example::\n\n        &gt;&gt;&gt; data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n        &gt;&gt;&gt; prepare_input_data(data)\n        array([[1, 2, 3],\n               [5, 6, 7],\n               [9, 10, 11]])\n    \"\"\"\n\n    data = super(MapValid, self).prepare_input_data(data)\n\n    if self.mask == self.large_number:\n        self.valid_indices_ = np.where(data[0, ...] &lt; self.mask)\n\n    elif not str(self.mask).isnumeric() or isinstance(self.mask, int):\n        self.valid_indices_ = np.where(data[0, ...] != self.mask)\n\n    else:\n        raise Exception(\n            \"The chosen mask {} does not fit in any supported case\".format(\n                self.mask\n            )\n        )\n\n    samples_dim = data.shape[0]\n\n    valid_indices = (slice(0, samples_dim),) + self.valid_indices_\n\n    return data[valid_indices]\n</code></pre>"},{"location":"simulai_io/#simulai.io.MapValid.prepare_input_structured_data","title":"<code>prepare_input_structured_data(data=None)</code>","text":"<p>This function is used to prepare structured input data for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>recarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <p>This function is a wrapper function that calls the 'prepare_input_data' function internally.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[('a', int), ('b', int), ('c', int)])\n&gt;&gt;&gt; model = MapValid()\n&gt;&gt;&gt; prepared_data = MapValid.prepare_input_structured_data(data)\n&gt;&gt;&gt; prepared_data\narray([[1, 2, 3],\n      [4, 5, 6]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_structured_data(self, data: np.recarray = None) -&gt; np.ndarray:\n    \"\"\"This function is used to prepare structured input data for further processing.\n\n    Args:\n        data (np.recarray, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        This function is a wrapper function that calls the 'prepare_input_data' function internally.\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6)], dtype=[('a', int), ('b', int), ('c', int)])\n        &gt;&gt;&gt; model = MapValid()\n        &gt;&gt;&gt; prepared_data = MapValid.prepare_input_structured_data(data)\n        &gt;&gt;&gt; prepared_data\n        array([[1, 2, 3],\n              [4, 5, 6]])\n    \"\"\"\n\n    return self.prepare_input_data(data)\n</code></pre>"},{"location":"simulai_io/#simulai.io.MapValid.prepare_output_data","title":"<code>prepare_output_data(data=None)</code>","text":"<p>Prepare output data for the MapValid operation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <ul> <li>The reshaped data will have shape (n0, n_valids) where n0 is the number of samples and n_valids are the number of valid values in the data.</li> <li>If the return_the_same_mask attribute is set to True, the mask used to select the invalid values will be returned. Otherwise, the reshaped data will be filled with NaN.</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; reshaper = MapValid()\n&gt;&gt;&gt; data = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n&gt;&gt;&gt; reshaper.prepare_output_data(data)\narray([[[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.]],\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n    \"\"\"Prepare output data for the MapValid operation.\n\n    Args:\n        data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        - The reshaped data will have shape (n0, n_valids) where n0 is the number of samples and n_valids are the number of valid values in the data.\n        - If the return_the_same_mask attribute is set to True, the mask used to select the invalid values will be returned. Otherwise, the reshaped data will be filled with NaN.\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; reshaper = MapValid()\n        &gt;&gt;&gt; data = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n        &gt;&gt;&gt; reshaper.prepare_output_data(data)\n        array([[[ 1.,  2.,  3.],\n                [ 4.,  5.,  6.]],\n    \"\"\"\n\n    immutable_shape = data.shape[0]\n\n    final_shape = (\n        immutable_shape,\n        self.n_features,\n    )\n\n    if self.return_the_same_mask:\n        mask = self.mask_\n    else:\n        mask = np.NaN  # For practical purposes\n    reshaped_data = np.full(final_shape, mask)\n\n    if not reshaped_data.dtype.type == self.default_dtype:\n        reshaped_data = reshaped_data.astype(self.default_dtype)\n\n    samples_dim = data.shape[0]\n    valid_indices = (slice(0, samples_dim),) + self.valid_indices_\n\n    reshaped_data[valid_indices] = data\n\n    reshaped_data = super(MapValid, self).prepare_output_data(reshaped_data)\n\n    return reshaped_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.MapValid.prepare_output_structured_data","title":"<code>prepare_output_structured_data(data=None)</code>","text":"<p>This function is used to prepare structured output data for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <p>This function is a wrapper function that calls the 'prepare_output_data' function internally.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6]])\n&gt;&gt;&gt; model = MapValid()\n&gt;&gt;&gt; prepared_data = MapValid.prepare_output_structured_data(data)\n&gt;&gt;&gt; prepared_data\narray([[1, 2, 3],\n    [4, 5, 6]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_output_structured_data(self, data: np.ndarray = None) -&gt; np.ndarray:\n    \"\"\"This function is used to prepare structured output data for further processing.\n\n    Args:\n        data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        This function is a wrapper function that calls the 'prepare_output_data' function internally.\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6]])\n        &gt;&gt;&gt; model = MapValid()\n        &gt;&gt;&gt; prepared_data = MapValid.prepare_output_structured_data(data)\n        &gt;&gt;&gt; prepared_data\n        array([[1, 2, 3],\n            [4, 5, 6]])\n    \"\"\"\n\n    return self.prepare_output_data(data)\n</code></pre>"},{"location":"simulai_io/#sampling","title":"Sampling","text":"<p>             Bases: <code>DataPreparer</code></p> <p>This class is used for sampling data from the input dataset.</p> Source code in <code>simulai/io.py</code> <pre><code>class Sampling(DataPreparer):\n    \"\"\"This class is used for sampling data from the input dataset.\"\"\"\n\n    name = \"sampling\"\n\n    def __init__(self, choices_fraction: float = 0.1, shuffling: bool = False) -&gt; None:\n        \"\"\"Initializes the Sampling class.\n\n        Args:\n            choices_fraction (float, optional): The fraction of the dataset to be sampled, by default 0.1\n            shuffling (bool, optional): Whether to shuffle the data before sampling, by default False\n\n        \"\"\"\n\n        super().__init__()\n        self.choices_fraction = choices_fraction\n        self.shuffling = shuffling\n        self.global_indices = None\n        self.sampled_indices = None\n\n    @property\n    def indices(self) -&gt; list:\n        \"\"\"Returns the indices of the data that have been sampled.\n\n        Returns:\n            list: The indices of the data that have been sampled.\n\n        Raises:\n            AssertionError: If the indices have not been generated yet.\n\n        Note:\n            The indices are generated by calling the 'prepare_input_data' or 'prepare_input_structured_data' functions.\n        Example::\n\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n            &gt;&gt;&gt; sampler = Sampling(choices_fraction=0.5, shuffling=True)\n            &gt;&gt;&gt; sampler.prepare_input_data(data)\n            &gt;&gt;&gt; sampler.indices\n            [0, 1]\n        \"\"\"\n\n        assert self.sampled_indices is not None, (\n            \"The indices still were not generate.\"\n            \"Run prepare_input_data or prepare_input_structured_data for getting them.\"\n        )\n        return sorted(self.sampled_indices.tolist())\n\n    def prepare_input_data(\n        self, data: np.ndarray = None, data_interval: list = None\n    ) -&gt; np.ndarray:\n        \"\"\"Prepare input data for sampling.\n\n        Args:\n            data (np.ndarray, optional): The input data. Default is None.\n            data_interval (list, optional): The interval of data that should be selected. Default is None,\n\n        Returns:\n            numpy.ndarray: The sampled data.\n        Note:\n            The `data_interval` parameter must be a list of two integers, specifying the start and end of the interval.\n         Example::\n\n            &gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n            &gt;&gt;&gt; data_interval = [3, 7]\n            &gt;&gt;&gt; input_data = sampler.prepare_input_data(data, data_interval)\n        \"\"\"\n\n        if data_interval is None:\n            data_interval = [0, data.shape[0]]\n        n_samples = data_interval[1] - data_interval[0]\n\n        self.global_indices = np.arange(start=data_interval[0], stop=data_interval[1])\n\n        n_choices = int(self.choices_fraction * n_samples)\n\n        self.sampled_indices = self.global_indices.copy()\n        if self.shuffling:\n            np.random.shuffle(self.sampled_indices)\n        else:\n            self.sampled_indices = self.sampled_indices\n\n        self.sampled_indices = np.random.choice(self.sampled_indices, n_choices)\n\n        return data[self.sampled_indices]\n\n    def prepare_input_structured_data(\n        self,\n        data: h5py.Dataset = None,\n        data_interval: list = None,\n        batch_size: int = None,\n        dump_path: str = None,\n    ) -&gt; np.recarray:\n        \"\"\"Prepares structured data for further processing.\n\n        Args:\n            data (h5py.Dataset, optional): Structured array to be prepared, the default shape is (n_samples, 1, *other_dimensions)\n            data_interval (list, optional): The interval of the data to be prepared, the default shape is [0, data.shape[0]]\n            batch_size (int, optional): The size of the batches to be processed, defaults to None\n            dump_path (str, optional):  (Default value = None)\n\n        Returns:\n            np.recarray:\n\n        Note:\n            - The features dimensions of the input data should be 1 in NumPy structured arrays.\n            - When using a h5py.Dataset as input, a dump_path must be provided\n        Example::\n\n            &gt;&gt;&gt; data = h5py.File(\"path/to/data.h5\", 'r')['data']\n            &gt;&gt;&gt; data_interval = [0, data.shape[0]]\n            &gt;&gt;&gt; batch_size = 32\n            &gt;&gt;&gt; dump_path = \"path/to/dump.h5\"\n            &gt;&gt;&gt; obj = PrepareInputStructuredData()\n            &gt;&gt;&gt; prepared_data = obj.prepare_input_structured_data(data, data_interval, batch_size, dump_path)\n        \"\"\"\n\n        if data_interval is None:\n            data_interval = [0, data.shape[0]]\n\n        n_samples = data_interval[1] - data_interval[0]\n        self.global_indices = np.arange(start=data_interval[0], stop=data_interval[1])\n\n        n_sampled_preserved = int(self.choices_fraction * n_samples)\n        self.sampled_indices = np.random.choice(\n            self.global_indices, n_sampled_preserved, replace=False\n        )\n\n        if isinstance(data, h5py.Dataset):\n            if isinstance(batch_size, MemorySizeEval):\n                batch_size = batch_size(\n                    max_batches=n_sampled_preserved, shape=data.shape[1:]\n                )\n            else:\n                pass\n\n            assert (\n                dump_path\n            ), \"Using a h5py.Dataset as input data a dump_path must be provided.\"\n\n            fp = h5py.File(dump_path, \"w\")\n            sampled_data = fp.create_dataset(\n                \"data\", shape=(n_sampled_preserved,) + data.shape[1:], dtype=data.dtype\n            )\n\n            # Constructing the normalization  using the reference data\n            batches = indices_batchdomain_constructor(\n                indices=self.sampled_indices, batch_size=batch_size\n            )\n\n            start_ix = 0\n            for batch_id, batch in enumerate(batches):\n                print(\n                    f\"Sampling batch {batch_id+1}/{len(batches)} batch_size={len(batch)}\"\n                )\n                finish_ix = start_ix + len(batch)\n                sampled_data[start_ix:finish_ix] = data[sorted(batch)]\n                start_ix = finish_ix\n\n            if self.shuffling:\n                random.shuffle(sampled_data)\n\n        else:\n            raise Exception(\"Others cases are still not implemented.\")\n\n        return sampled_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.Sampling.indices","title":"<code>indices: list</code>  <code>property</code>","text":"<p>Returns the indices of the data that have been sampled.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The indices of the data that have been sampled.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the indices have not been generated yet.</p> Note <p>The indices are generated by calling the 'prepare_input_data' or 'prepare_input_structured_data' functions.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n&gt;&gt;&gt; sampler = Sampling(choices_fraction=0.5, shuffling=True)\n&gt;&gt;&gt; sampler.prepare_input_data(data)\n&gt;&gt;&gt; sampler.indices\n[0, 1]\n</code></pre>"},{"location":"simulai_io/#simulai.io.Sampling.__init__","title":"<code>__init__(choices_fraction=0.1, shuffling=False)</code>","text":"<p>Initializes the Sampling class.</p> <p>Parameters:</p> Name Type Description Default <code>choices_fraction</code> <code>float</code> <p>The fraction of the dataset to be sampled, by default 0.1</p> <code>0.1</code> <code>shuffling</code> <code>bool</code> <p>Whether to shuffle the data before sampling, by default False</p> <code>False</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(self, choices_fraction: float = 0.1, shuffling: bool = False) -&gt; None:\n    \"\"\"Initializes the Sampling class.\n\n    Args:\n        choices_fraction (float, optional): The fraction of the dataset to be sampled, by default 0.1\n        shuffling (bool, optional): Whether to shuffle the data before sampling, by default False\n\n    \"\"\"\n\n    super().__init__()\n    self.choices_fraction = choices_fraction\n    self.shuffling = shuffling\n    self.global_indices = None\n    self.sampled_indices = None\n</code></pre>"},{"location":"simulai_io/#simulai.io.Sampling.prepare_input_data","title":"<code>prepare_input_data(data=None, data_interval=None)</code>","text":"<p>Prepare input data for sampling.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The input data. Default is None.</p> <code>None</code> <code>data_interval</code> <code>list</code> <p>The interval of data that should be selected. Default is None,</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: The sampled data.</p> <p>Note:     The <code>data_interval</code> parameter must be a list of two integers, specifying the start and end of the interval.  Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n&gt;&gt;&gt; data_interval = [3, 7]\n&gt;&gt;&gt; input_data = sampler.prepare_input_data(data, data_interval)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_data(\n    self, data: np.ndarray = None, data_interval: list = None\n) -&gt; np.ndarray:\n    \"\"\"Prepare input data for sampling.\n\n    Args:\n        data (np.ndarray, optional): The input data. Default is None.\n        data_interval (list, optional): The interval of data that should be selected. Default is None,\n\n    Returns:\n        numpy.ndarray: The sampled data.\n    Note:\n        The `data_interval` parameter must be a list of two integers, specifying the start and end of the interval.\n     Example::\n\n        &gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        &gt;&gt;&gt; data_interval = [3, 7]\n        &gt;&gt;&gt; input_data = sampler.prepare_input_data(data, data_interval)\n    \"\"\"\n\n    if data_interval is None:\n        data_interval = [0, data.shape[0]]\n    n_samples = data_interval[1] - data_interval[0]\n\n    self.global_indices = np.arange(start=data_interval[0], stop=data_interval[1])\n\n    n_choices = int(self.choices_fraction * n_samples)\n\n    self.sampled_indices = self.global_indices.copy()\n    if self.shuffling:\n        np.random.shuffle(self.sampled_indices)\n    else:\n        self.sampled_indices = self.sampled_indices\n\n    self.sampled_indices = np.random.choice(self.sampled_indices, n_choices)\n\n    return data[self.sampled_indices]\n</code></pre>"},{"location":"simulai_io/#simulai.io.Sampling.prepare_input_structured_data","title":"<code>prepare_input_structured_data(data=None, data_interval=None, batch_size=None, dump_path=None)</code>","text":"<p>Prepares structured data for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dataset</code> <p>Structured array to be prepared, the default shape is (n_samples, 1, *other_dimensions)</p> <code>None</code> <code>data_interval</code> <code>list</code> <p>The interval of the data to be prepared, the default shape is [0, data.shape[0]]</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>The size of the batches to be processed, defaults to None</p> <code>None</code> <code>dump_path</code> <code>str</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>recarray</code> <p>np.recarray:</p> Note <ul> <li>The features dimensions of the input data should be 1 in NumPy structured arrays.</li> <li>When using a h5py.Dataset as input, a dump_path must be provided</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = h5py.File(\"path/to/data.h5\", 'r')['data']\n&gt;&gt;&gt; data_interval = [0, data.shape[0]]\n&gt;&gt;&gt; batch_size = 32\n&gt;&gt;&gt; dump_path = \"path/to/dump.h5\"\n&gt;&gt;&gt; obj = PrepareInputStructuredData()\n&gt;&gt;&gt; prepared_data = obj.prepare_input_structured_data(data, data_interval, batch_size, dump_path)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def prepare_input_structured_data(\n    self,\n    data: h5py.Dataset = None,\n    data_interval: list = None,\n    batch_size: int = None,\n    dump_path: str = None,\n) -&gt; np.recarray:\n    \"\"\"Prepares structured data for further processing.\n\n    Args:\n        data (h5py.Dataset, optional): Structured array to be prepared, the default shape is (n_samples, 1, *other_dimensions)\n        data_interval (list, optional): The interval of the data to be prepared, the default shape is [0, data.shape[0]]\n        batch_size (int, optional): The size of the batches to be processed, defaults to None\n        dump_path (str, optional):  (Default value = None)\n\n    Returns:\n        np.recarray:\n\n    Note:\n        - The features dimensions of the input data should be 1 in NumPy structured arrays.\n        - When using a h5py.Dataset as input, a dump_path must be provided\n    Example::\n\n        &gt;&gt;&gt; data = h5py.File(\"path/to/data.h5\", 'r')['data']\n        &gt;&gt;&gt; data_interval = [0, data.shape[0]]\n        &gt;&gt;&gt; batch_size = 32\n        &gt;&gt;&gt; dump_path = \"path/to/dump.h5\"\n        &gt;&gt;&gt; obj = PrepareInputStructuredData()\n        &gt;&gt;&gt; prepared_data = obj.prepare_input_structured_data(data, data_interval, batch_size, dump_path)\n    \"\"\"\n\n    if data_interval is None:\n        data_interval = [0, data.shape[0]]\n\n    n_samples = data_interval[1] - data_interval[0]\n    self.global_indices = np.arange(start=data_interval[0], stop=data_interval[1])\n\n    n_sampled_preserved = int(self.choices_fraction * n_samples)\n    self.sampled_indices = np.random.choice(\n        self.global_indices, n_sampled_preserved, replace=False\n    )\n\n    if isinstance(data, h5py.Dataset):\n        if isinstance(batch_size, MemorySizeEval):\n            batch_size = batch_size(\n                max_batches=n_sampled_preserved, shape=data.shape[1:]\n            )\n        else:\n            pass\n\n        assert (\n            dump_path\n        ), \"Using a h5py.Dataset as input data a dump_path must be provided.\"\n\n        fp = h5py.File(dump_path, \"w\")\n        sampled_data = fp.create_dataset(\n            \"data\", shape=(n_sampled_preserved,) + data.shape[1:], dtype=data.dtype\n        )\n\n        # Constructing the normalization  using the reference data\n        batches = indices_batchdomain_constructor(\n            indices=self.sampled_indices, batch_size=batch_size\n        )\n\n        start_ix = 0\n        for batch_id, batch in enumerate(batches):\n            print(\n                f\"Sampling batch {batch_id+1}/{len(batches)} batch_size={len(batch)}\"\n            )\n            finish_ix = start_ix + len(batch)\n            sampled_data[start_ix:finish_ix] = data[sorted(batch)]\n            start_ix = finish_ix\n\n        if self.shuffling:\n            random.shuffle(sampled_data)\n\n    else:\n        raise Exception(\"Others cases are still not implemented.\")\n\n    return sampled_data\n</code></pre>"},{"location":"simulai_io/#movingwindow","title":"MovingWindow","text":"<p>MovingWindow is applied over a time-series array (2D array), and it is used for creating the necessary augmented data used for LSTM networks, replicating the training windows for each sample in the dataset.</p> <p>See a graphical example:</p> <p>Example::</p> <pre><code>batch n\n---------|---\nhistory  | horizon\n\n    batch n+1\n    ---------|---\n    history  | horizon\n----\nskip\n</code></pre> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n&gt;&gt;&gt; window = MovingWindow(history_size=3, horizon_size=1)\n&gt;&gt;&gt; window.transform(data)\narray([[1, 2, 3],\n       [2, 3, 4],\n       [3, 4, 5],\n       [4, 5, 6],\n       [5, 6, 7],\n       [6, 7, 8],\n       [7, 8, 9],\n       [8, 9, 10]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>class MovingWindow:\n    r\"\"\"MovingWindow is applied over a time-series array (2D array), and it is used for\n    creating the necessary augmented data used for LSTM networks, replicating the training\n    windows for each sample in the dataset.\n\n    See a graphical example:\n\n    Example::\n\n        batch n\n        ---------|---\n        history  | horizon\n\n            batch n+1\n            ---------|---\n            history  | horizon\n        ----\n        skip\n\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        &gt;&gt;&gt; window = MovingWindow(history_size=3, horizon_size=1)\n        &gt;&gt;&gt; window.transform(data)\n        array([[1, 2, 3],\n               [2, 3, 4],\n               [3, 4, 5],\n               [4, 5, 6],\n               [5, 6, 7],\n               [6, 7, 8],\n               [7, 8, 9],\n               [8, 9, 10]])\n    \"\"\"\n\n    def __init__(\n        self,\n        history_size: int = None,\n        skip_size: int = 1,\n        horizon_size: int = None,\n        full_output: bool = True,\n    ) -&gt; None:\n        r\"\"\"Initializes the MovingWindow class\n\n        Args:\n            history_size (int, optional): the size of the history window, by default None\n            skip_size (int, optional): the number of steps to skip between windows, by default 1\n            horizon_size (int, optional): the size of the horizon window, by default None\n            full_output (bool, optional): flag to use the full output or only the last item, by default True\n\n        \"\"\"\n        self.history_size = history_size\n        self.skip_size = skip_size\n        self.horizon_size = horizon_size\n        self.full_output = full_output\n\n        if self.full_output == True:\n            self.process_batch = self.bypass\n        else:\n            self.process_batch = self.get_last_item\n\n        # Verifying if history and horizon sizes was provided\n        assert (\n            history_size\n        ), f\"A value for history_size must be provided, not {history_size}\"\n        assert (\n            horizon_size\n        ), f\"A value for horizon_size must be provided, not {horizon_size}\"\n\n    def transform(self, time_series: np.ndarray) -&gt; np.ndarray:\n        r\"\"\"Applies the moving window over the time_series array.\n\n        Args:\n            time_series (np.ndarray):\n\n        Returns:\n            np.ndarray: the transformed array with the windows.\n\n        \"\"\"\n        return np.ndarray(time_series)\n\n    def bypass(self, batch: np.ndarray) -&gt; np.ndarray:\n        r\"\"\"Does nothing, returns the input batch.\n\n        Args:\n            batch (np.ndarray):\n\n        Returns:\n            np.ndarray: the input array\n\n        \"\"\"\n        return batch\n\n    def get_last_item(self, batch: np.ndarray) -&gt; np.ndarray:\n        r\"\"\"Get the last item of a batch\n\n        Args:\n            batch (np.ndarray):\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            - This method is used internally by the MovingWindow class\n        Example::\n\n            &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n            &gt;&gt;&gt; mw.get_last_item(data)\n            array([[7, 8, 9]])\n        \"\"\"\n\n        return batch[-1:]\n\n    def __call__(\n        self, input_data: np.ndarray = None, output_data: np.ndarray = None\n    ) -&gt; Tuple[np.ndarray, np.ndarray]:\n        r\"\"\"Apply Moving Window over the input data\n\n        Args:\n            input_data (np.ndarray, optional): 2D array (time-series) to be used for constructing the history size (Default value = None)\n            output_data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            Tuple of np.ndarray: The tuple contains two arrays with shapes (n_samples, n_history, n_features) and\n\n        Note:\n            - It is expected that the input_data and output_data have the same shape\n            - This method is used internally by the MovingWindow class\n        Example::\n\n            &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n            &gt;&gt;&gt; mw = MovingWindow(history_size=2, horizon_size=2, skip_size=1)\n            &gt;&gt;&gt; input_data, output_data = mw(data, data)\n            &gt;&gt;&gt; input_data\n            array([[[1, 2, 3],\n                    [4, 5, 6]],\n                   [[4, 5, 6],\n                    [7, 8, 9]],\n                   [[7, 8, 9],\n                    [10, 11, 12]]])\n            &gt;&gt;&gt; output_data\n            array([[[ 7,  8,  9],\n                    [10, 11, 12]],\n                   [[10, 11, 12],\n                    [13, 14, 15]]])\n        \"\"\"\n\n        # It is expected series_data to be a set of time-series with shape\n        # (n_timesteps, n_variables)\n\n        input_batches_list = list()\n        output_batches_list = list()\n        data_size = input_data.shape[0]\n\n        assert input_data.shape[0] == output_data.shape[0]\n\n        center = self.history_size\n\n        # Loop for covering the entire time-series dataset constructing the\n        # training windows\n        while center + self.horizon_size &lt;= data_size:\n            input_batch = input_data[center - self.history_size : center, :]\n            output_batch = output_data[center : center + self.horizon_size, :]\n\n            input_batches_list.append(input_batch)\n            output_batches_list.append(self.process_batch(batch=output_batch))\n\n            center += self.skip_size\n\n        input_data = np.stack(input_batches_list, 0)\n        output_data = np.stack(output_batches_list, 0)\n\n        return input_data, output_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.MovingWindow.__call__","title":"<code>__call__(input_data=None, output_data=None)</code>","text":"<p>Apply Moving Window over the input data</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ndarray</code> <p>2D array (time-series) to be used for constructing the history size (Default value = None)</p> <code>None</code> <code>output_data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of np.ndarray: The tuple contains two arrays with shapes (n_samples, n_history, n_features) and</p> Note <ul> <li>It is expected that the input_data and output_data have the same shape</li> <li>This method is used internally by the MovingWindow class</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n&gt;&gt;&gt; mw = MovingWindow(history_size=2, horizon_size=2, skip_size=1)\n&gt;&gt;&gt; input_data, output_data = mw(data, data)\n&gt;&gt;&gt; input_data\narray([[[1, 2, 3],\n        [4, 5, 6]],\n       [[4, 5, 6],\n        [7, 8, 9]],\n       [[7, 8, 9],\n        [10, 11, 12]]])\n&gt;&gt;&gt; output_data\narray([[[ 7,  8,  9],\n        [10, 11, 12]],\n       [[10, 11, 12],\n        [13, 14, 15]]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def __call__(\n    self, input_data: np.ndarray = None, output_data: np.ndarray = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    r\"\"\"Apply Moving Window over the input data\n\n    Args:\n        input_data (np.ndarray, optional): 2D array (time-series) to be used for constructing the history size (Default value = None)\n        output_data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        Tuple of np.ndarray: The tuple contains two arrays with shapes (n_samples, n_history, n_features) and\n\n    Note:\n        - It is expected that the input_data and output_data have the same shape\n        - This method is used internally by the MovingWindow class\n    Example::\n\n        &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n        &gt;&gt;&gt; mw = MovingWindow(history_size=2, horizon_size=2, skip_size=1)\n        &gt;&gt;&gt; input_data, output_data = mw(data, data)\n        &gt;&gt;&gt; input_data\n        array([[[1, 2, 3],\n                [4, 5, 6]],\n               [[4, 5, 6],\n                [7, 8, 9]],\n               [[7, 8, 9],\n                [10, 11, 12]]])\n        &gt;&gt;&gt; output_data\n        array([[[ 7,  8,  9],\n                [10, 11, 12]],\n               [[10, 11, 12],\n                [13, 14, 15]]])\n    \"\"\"\n\n    # It is expected series_data to be a set of time-series with shape\n    # (n_timesteps, n_variables)\n\n    input_batches_list = list()\n    output_batches_list = list()\n    data_size = input_data.shape[0]\n\n    assert input_data.shape[0] == output_data.shape[0]\n\n    center = self.history_size\n\n    # Loop for covering the entire time-series dataset constructing the\n    # training windows\n    while center + self.horizon_size &lt;= data_size:\n        input_batch = input_data[center - self.history_size : center, :]\n        output_batch = output_data[center : center + self.horizon_size, :]\n\n        input_batches_list.append(input_batch)\n        output_batches_list.append(self.process_batch(batch=output_batch))\n\n        center += self.skip_size\n\n    input_data = np.stack(input_batches_list, 0)\n    output_data = np.stack(output_batches_list, 0)\n\n    return input_data, output_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.MovingWindow.__init__","title":"<code>__init__(history_size=None, skip_size=1, horizon_size=None, full_output=True)</code>","text":"<p>Initializes the MovingWindow class</p> <p>Parameters:</p> Name Type Description Default <code>history_size</code> <code>int</code> <p>the size of the history window, by default None</p> <code>None</code> <code>skip_size</code> <code>int</code> <p>the number of steps to skip between windows, by default 1</p> <code>1</code> <code>horizon_size</code> <code>int</code> <p>the size of the horizon window, by default None</p> <code>None</code> <code>full_output</code> <code>bool</code> <p>flag to use the full output or only the last item, by default True</p> <code>True</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(\n    self,\n    history_size: int = None,\n    skip_size: int = 1,\n    horizon_size: int = None,\n    full_output: bool = True,\n) -&gt; None:\n    r\"\"\"Initializes the MovingWindow class\n\n    Args:\n        history_size (int, optional): the size of the history window, by default None\n        skip_size (int, optional): the number of steps to skip between windows, by default 1\n        horizon_size (int, optional): the size of the horizon window, by default None\n        full_output (bool, optional): flag to use the full output or only the last item, by default True\n\n    \"\"\"\n    self.history_size = history_size\n    self.skip_size = skip_size\n    self.horizon_size = horizon_size\n    self.full_output = full_output\n\n    if self.full_output == True:\n        self.process_batch = self.bypass\n    else:\n        self.process_batch = self.get_last_item\n\n    # Verifying if history and horizon sizes was provided\n    assert (\n        history_size\n    ), f\"A value for history_size must be provided, not {history_size}\"\n    assert (\n        horizon_size\n    ), f\"A value for horizon_size must be provided, not {horizon_size}\"\n</code></pre>"},{"location":"simulai_io/#simulai.io.MovingWindow.bypass","title":"<code>bypass(batch)</code>","text":"<p>Does nothing, returns the input batch.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the input array</p> Source code in <code>simulai/io.py</code> <pre><code>def bypass(self, batch: np.ndarray) -&gt; np.ndarray:\n    r\"\"\"Does nothing, returns the input batch.\n\n    Args:\n        batch (np.ndarray):\n\n    Returns:\n        np.ndarray: the input array\n\n    \"\"\"\n    return batch\n</code></pre>"},{"location":"simulai_io/#simulai.io.MovingWindow.get_last_item","title":"<code>get_last_item(batch)</code>","text":"<p>Get the last item of a batch</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <ul> <li>This method is used internally by the MovingWindow class</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n&gt;&gt;&gt; mw.get_last_item(data)\narray([[7, 8, 9]])\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def get_last_item(self, batch: np.ndarray) -&gt; np.ndarray:\n    r\"\"\"Get the last item of a batch\n\n    Args:\n        batch (np.ndarray):\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        - This method is used internally by the MovingWindow class\n    Example::\n\n        &gt;&gt;&gt; data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        &gt;&gt;&gt; mw.get_last_item(data)\n        array([[7, 8, 9]])\n    \"\"\"\n\n    return batch[-1:]\n</code></pre>"},{"location":"simulai_io/#simulai.io.MovingWindow.transform","title":"<code>transform(time_series)</code>","text":"<p>Applies the moving window over the time_series array.</p> <p>Parameters:</p> Name Type Description Default <code>time_series</code> <code>ndarray</code> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the transformed array with the windows.</p> Source code in <code>simulai/io.py</code> <pre><code>def transform(self, time_series: np.ndarray) -&gt; np.ndarray:\n    r\"\"\"Applies the moving window over the time_series array.\n\n    Args:\n        time_series (np.ndarray):\n\n    Returns:\n        np.ndarray: the transformed array with the windows.\n\n    \"\"\"\n    return np.ndarray(time_series)\n</code></pre>"},{"location":"simulai_io/#slidingwindow","title":"SlidingWindow","text":"<p>SlidingWindow is applied over a time-series array (2D array), and it is used for creating the necessary augmented data used for LSTM networks, replicating the training windows for each sample in the dataset. The difference between SlidingWindow and MovingWindow is that here there is no intersection between two sequential batches</p> <p>Attributes:</p> Name Type Description <code>history_size</code> <p>int The number of history samples to include in each window.</p> <code>skip_size</code> <p>int The number of samples to skip between each window.</p> <p>Note:     - The difference between SlidingWindow and MovingWindow is that here there is no intersection between two sequential batches.</p> <p>See a graphical example:</p> <p>Example::</p> <pre><code>batch n\n---------|---\nhistory  | horizon\n\n                batch n+1\n                ---------|---\n                    history  | horizon\n</code></pre> <p>Example::</p> <pre><code>&gt;&gt;&gt; window = SlidingWindow(history_size=3, skip_size=1)\n&gt;&gt;&gt; time_series = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n&gt;&gt;&gt; windows = window.apply(time_series)\n&gt;&gt;&gt; windows\n[[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>class SlidingWindow:\n    r\"\"\"SlidingWindow is applied over a time-series array (2D array), and it is used for\n    creating the necessary augmented data used for LSTM networks, replicating the training\n    windows for each sample in the dataset. The difference between SlidingWindow and MovingWindow\n    is that here there is no intersection between two sequential batches\n\n    Attributes:\n        history_size : int\n            The number of history samples to include in each window.\n        skip_size : int\n            The number of samples to skip between each window.\n    Note:\n        - The difference between SlidingWindow and MovingWindow is that here there is no intersection between two sequential batches.\n\n    See a graphical example:\n\n    Example::\n\n        batch n\n        ---------|---\n        history  | horizon\n\n                        batch n+1\n                        ---------|---\n                            history  | horizon\n\n    Example::\n\n        &gt;&gt;&gt; window = SlidingWindow(history_size=3, skip_size=1)\n        &gt;&gt;&gt; time_series = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n        &gt;&gt;&gt; windows = window.apply(time_series)\n        &gt;&gt;&gt; windows\n        [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]\n    \"\"\"\n\n    def __init__(self, history_size: int = None, skip_size: int = None) -&gt; None:\n        r\"\"\"Initialize the SlidingWindow object.\n\n        Args:\n            history_size (int, optional): The number of history samples to include in each window. (Default value = None)\n            skip_size (int, optional): The number of samples to skip between each window. (Default value = None)\n\n        \"\"\"\n\n        self.history_size = history_size\n        self.skip_size = skip_size\n\n        # Verifying if history and horizon sizes was provided\n        assert (\n            history_size\n        ), f\"A value for history_size must be provided, not {history_size}\"\n        assert skip_size, f\"A value for horizon_size must be provided, not {skip_size}\"\n\n    def apply(self, time_series: List[int]) -&gt; List[List[int]]:\n        r\"\"\"Applies the sliding window to the given time series.\n\n        Args:\n            time_series (List[int]):\n\n        Returns:\n            List[List[int]]:\n        Example::\n\n            &gt;&gt;&gt; window = SlidingWindow(history_size=3, skip_size=1)\n            &gt;&gt;&gt; time_series = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n            &gt;&gt;&gt; windows = window.apply(time_series)\n            &gt;&gt;&gt; windows\n            [[[1, 2, 3], [4, 5, 6]], [[4, 5, 6], [7, 8, 9]], [[7, 8, 9], [10, 11, 12]]]\n        \"\"\"\n\n        windowed_samples = []\n        for i in range(0, len(time_series) - self.history_size - self.skip_size + 1):\n            window = time_series[i : i + self.history_size + self.skip_size]\n            windowed_samples.append(window)\n        return windowed_samples\n\n    def __call__(\n        self, input_data: np.ndarray = None, output_data: np.ndarray = None\n    ) -&gt; Tuple[np.ndarray, np.ndarray]:\n        r\"\"\"Applies a sliding window operation on the given time series and returns the windowed samples.\n\n        Args:\n            input_data (np.ndarray, optional): 2D array (time-series) to be used for constructing the history size (Default value = None)\n            output_data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]: tuple of np.ndarray with shapes (n_samples, n_history, n_features) and (n_samples, n_horizon, n_features)\n\n        Note:\n            - history_size and horizon_size should be positive integers\n            - history_size should be less than the length of input_data\n            - input_data and output_data should have the same number of rows\n        Example::\n\n            &gt;&gt;&gt; data = np.random.rand(10,3)\n            &gt;&gt;&gt; history_size = 3\n            &gt;&gt;&gt; horizon_size = 2\n            &gt;&gt;&gt; window = Window(history_size, horizon_size)\n            &gt;&gt;&gt; input_data, output_data = window(data)\n            &gt;&gt;&gt; input_data.shape\n            (4, 3, 3)\n            &gt;&gt;&gt; output_data.shape\n            (4, 2, 3)\n        \"\"\"\n\n        # It is expected series_data to be a set of time-series with shape\n        # (n_timesteps, n_variables)\n\n        input_batches_list = list()\n        output_batches_list = list()\n        data_size = input_data.shape[0]\n\n        assert input_data.shape[0] == output_data.shape[0]\n\n        center = self.history_size\n\n        # Loop for covering the entire time-series dataset constructing the\n        # training windows\n        while center + self.skip_size &lt;= data_size:\n            input_batch = input_data[center - self.history_size : center, :]\n            output_batch = output_data[\n                center - self.history_size + self.skip_size : center + self.skip_size, :\n            ]\n\n            input_batches_list.append(input_batch)\n            output_batches_list.append(output_batch)\n\n            center += self.skip_size\n\n        input_data = np.stack(input_batches_list, 0)\n        output_data = np.stack(output_batches_list, 0)\n\n        return input_data, output_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.SlidingWindow.__call__","title":"<code>__call__(input_data=None, output_data=None)</code>","text":"<p>Applies a sliding window operation on the given time series and returns the windowed samples.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ndarray</code> <p>2D array (time-series) to be used for constructing the history size (Default value = None)</p> <code>None</code> <code>output_data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: tuple of np.ndarray with shapes (n_samples, n_history, n_features) and (n_samples, n_horizon, n_features)</p> Note <ul> <li>history_size and horizon_size should be positive integers</li> <li>history_size should be less than the length of input_data</li> <li>input_data and output_data should have the same number of rows</li> </ul> <p>Example::</p> <pre><code>&gt;&gt;&gt; data = np.random.rand(10,3)\n&gt;&gt;&gt; history_size = 3\n&gt;&gt;&gt; horizon_size = 2\n&gt;&gt;&gt; window = Window(history_size, horizon_size)\n&gt;&gt;&gt; input_data, output_data = window(data)\n&gt;&gt;&gt; input_data.shape\n(4, 3, 3)\n&gt;&gt;&gt; output_data.shape\n(4, 2, 3)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def __call__(\n    self, input_data: np.ndarray = None, output_data: np.ndarray = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    r\"\"\"Applies a sliding window operation on the given time series and returns the windowed samples.\n\n    Args:\n        input_data (np.ndarray, optional): 2D array (time-series) to be used for constructing the history size (Default value = None)\n        output_data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: tuple of np.ndarray with shapes (n_samples, n_history, n_features) and (n_samples, n_horizon, n_features)\n\n    Note:\n        - history_size and horizon_size should be positive integers\n        - history_size should be less than the length of input_data\n        - input_data and output_data should have the same number of rows\n    Example::\n\n        &gt;&gt;&gt; data = np.random.rand(10,3)\n        &gt;&gt;&gt; history_size = 3\n        &gt;&gt;&gt; horizon_size = 2\n        &gt;&gt;&gt; window = Window(history_size, horizon_size)\n        &gt;&gt;&gt; input_data, output_data = window(data)\n        &gt;&gt;&gt; input_data.shape\n        (4, 3, 3)\n        &gt;&gt;&gt; output_data.shape\n        (4, 2, 3)\n    \"\"\"\n\n    # It is expected series_data to be a set of time-series with shape\n    # (n_timesteps, n_variables)\n\n    input_batches_list = list()\n    output_batches_list = list()\n    data_size = input_data.shape[0]\n\n    assert input_data.shape[0] == output_data.shape[0]\n\n    center = self.history_size\n\n    # Loop for covering the entire time-series dataset constructing the\n    # training windows\n    while center + self.skip_size &lt;= data_size:\n        input_batch = input_data[center - self.history_size : center, :]\n        output_batch = output_data[\n            center - self.history_size + self.skip_size : center + self.skip_size, :\n        ]\n\n        input_batches_list.append(input_batch)\n        output_batches_list.append(output_batch)\n\n        center += self.skip_size\n\n    input_data = np.stack(input_batches_list, 0)\n    output_data = np.stack(output_batches_list, 0)\n\n    return input_data, output_data\n</code></pre>"},{"location":"simulai_io/#simulai.io.SlidingWindow.__init__","title":"<code>__init__(history_size=None, skip_size=None)</code>","text":"<p>Initialize the SlidingWindow object.</p> <p>Parameters:</p> Name Type Description Default <code>history_size</code> <code>int</code> <p>The number of history samples to include in each window. (Default value = None)</p> <code>None</code> <code>skip_size</code> <code>int</code> <p>The number of samples to skip between each window. (Default value = None)</p> <code>None</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(self, history_size: int = None, skip_size: int = None) -&gt; None:\n    r\"\"\"Initialize the SlidingWindow object.\n\n    Args:\n        history_size (int, optional): The number of history samples to include in each window. (Default value = None)\n        skip_size (int, optional): The number of samples to skip between each window. (Default value = None)\n\n    \"\"\"\n\n    self.history_size = history_size\n    self.skip_size = skip_size\n\n    # Verifying if history and horizon sizes was provided\n    assert (\n        history_size\n    ), f\"A value for history_size must be provided, not {history_size}\"\n    assert skip_size, f\"A value for horizon_size must be provided, not {skip_size}\"\n</code></pre>"},{"location":"simulai_io/#simulai.io.SlidingWindow.apply","title":"<code>apply(time_series)</code>","text":"<p>Applies the sliding window to the given time series.</p> <p>Parameters:</p> Name Type Description Default <code>time_series</code> <code>List[int]</code> required <p>Returns:</p> Type Description <code>List[List[int]]</code> <p>List[List[int]]:</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; window = SlidingWindow(history_size=3, skip_size=1)\n&gt;&gt;&gt; time_series = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n&gt;&gt;&gt; windows = window.apply(time_series)\n&gt;&gt;&gt; windows\n[[[1, 2, 3], [4, 5, 6]], [[4, 5, 6], [7, 8, 9]], [[7, 8, 9], [10, 11, 12]]]\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def apply(self, time_series: List[int]) -&gt; List[List[int]]:\n    r\"\"\"Applies the sliding window to the given time series.\n\n    Args:\n        time_series (List[int]):\n\n    Returns:\n        List[List[int]]:\n    Example::\n\n        &gt;&gt;&gt; window = SlidingWindow(history_size=3, skip_size=1)\n        &gt;&gt;&gt; time_series = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n        &gt;&gt;&gt; windows = window.apply(time_series)\n        &gt;&gt;&gt; windows\n        [[[1, 2, 3], [4, 5, 6]], [[4, 5, 6], [7, 8, 9]], [[7, 8, 9], [10, 11, 12]]]\n    \"\"\"\n\n    windowed_samples = []\n    for i in range(0, len(time_series) - self.history_size - self.skip_size + 1):\n        window = time_series[i : i + self.history_size + self.skip_size]\n        windowed_samples.append(window)\n    return windowed_samples\n</code></pre>"},{"location":"simulai_io/#intersectingbatches","title":"IntersectingBatches","text":"<p>IntersectingBatches is a class that is applied over a time-series array (2D array) to create batches of input data for training or testing purposes.</p> Source code in <code>simulai/io.py</code> <pre><code>class IntersectingBatches:\n    r\"\"\"IntersectingBatches is a class that is applied over a time-series array (2D array) to create batches of input data for training or testing purposes.\"\"\"\n\n    def __init__(\n        self, skip_size: int = 1, batch_size: int = None, full: bool = True\n    ) -&gt; None:\n        r\"\"\"Initializes the IntersectingBatches class\n\n        Args:\n            skip_size (int, optional): Number of samples to skip between two windows. (Default value = 1)\n            batch_size (int, optional): Number of samples to use in each batch. (Default value = None)\n            full (bool, optional): Whether to include the last batch or not, even if it's not full. (Default value = True)\n\n        \"\"\"\n        assert (\n            batch_size\n        ), f\"A value for horizon_size must be provided, not {batch_size}\"\n\n        self.skip_size = skip_size\n        self.batch_size = batch_size\n        self.full = full\n\n    def get_indices(self, dim: int = None) -&gt; np.ndarray:\n        r\"\"\"It gets just the indices of the shifting\n\n        Args:\n            dim (int, optional): total dimension (Default value = None)\n\n        Returns:\n            np.ndarray: the shifted indices\n\n        \"\"\"\n        center = 0\n        indices = list()\n        indices_m = list()\n\n        # Loop for covering the entire time-series dataset constructing the\n        # training windows\n        while center + self.batch_size &lt; dim:\n            index = center + self.batch_size\n\n            indices.append(center)\n            indices_m.append(index)\n\n            center += self.skip_size\n\n        return np.array(indices), np.array(indices_m)\n\n    def __call__(self, input_data: np.ndarray = None) -&gt; Union[list, np.ndarray]:\n        r\"\"\"Applies the batching strategy to the input data.\n\n        Args:\n            input_data (np.ndarray, optional):  (Default value = None)\n\n        Returns:\n            Union[list, np.ndarray]: A list of batches or a single batch if `full` attribute is set to False.\n        Note:\n            - If the `full` attribute is set to True, the last batch will be included even if it's not full.\n        Example::\n\n            &gt;&gt;&gt; input_data = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n            &gt;&gt;&gt; batches = IntersectingBatches(skip_size=1, batch_size=2)\n            &gt;&gt;&gt; batches(input_data)\n            [array([[1, 2, 3],\n                [4, 5, 6]]),\n            array([[4, 5, 6],\n                [7, 8, 9]]),\n            array([[ 7,  8,  9],\n                [10, 11, 12]])]\n        \"\"\"\n\n        input_batches_list = list()\n        data_size = input_data.shape[0]\n        center = 0\n\n        # Loop for covering the entire time-series dataset constructing the\n        # training windows\n        while center + self.batch_size &lt;= data_size:\n            input_batch = input_data[center : center + self.batch_size]\n\n            input_batches_list.append(input_batch)\n\n            center += self.skip_size\n\n        if self.full == True:\n            return input_batches_list\n        else:\n            return np.vstack([item[-1] for item in input_batches_list])\n</code></pre>"},{"location":"simulai_io/#simulai.io.IntersectingBatches.__call__","title":"<code>__call__(input_data=None)</code>","text":"<p>Applies the batching strategy to the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ndarray</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[list, ndarray]</code> <p>Union[list, np.ndarray]: A list of batches or a single batch if <code>full</code> attribute is set to False.</p> <p>Note:     - If the <code>full</code> attribute is set to True, the last batch will be included even if it's not full. Example::</p> <pre><code>&gt;&gt;&gt; input_data = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n&gt;&gt;&gt; batches = IntersectingBatches(skip_size=1, batch_size=2)\n&gt;&gt;&gt; batches(input_data)\n[array([[1, 2, 3],\n    [4, 5, 6]]),\narray([[4, 5, 6],\n    [7, 8, 9]]),\narray([[ 7,  8,  9],\n    [10, 11, 12]])]\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def __call__(self, input_data: np.ndarray = None) -&gt; Union[list, np.ndarray]:\n    r\"\"\"Applies the batching strategy to the input data.\n\n    Args:\n        input_data (np.ndarray, optional):  (Default value = None)\n\n    Returns:\n        Union[list, np.ndarray]: A list of batches or a single batch if `full` attribute is set to False.\n    Note:\n        - If the `full` attribute is set to True, the last batch will be included even if it's not full.\n    Example::\n\n        &gt;&gt;&gt; input_data = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n        &gt;&gt;&gt; batches = IntersectingBatches(skip_size=1, batch_size=2)\n        &gt;&gt;&gt; batches(input_data)\n        [array([[1, 2, 3],\n            [4, 5, 6]]),\n        array([[4, 5, 6],\n            [7, 8, 9]]),\n        array([[ 7,  8,  9],\n            [10, 11, 12]])]\n    \"\"\"\n\n    input_batches_list = list()\n    data_size = input_data.shape[0]\n    center = 0\n\n    # Loop for covering the entire time-series dataset constructing the\n    # training windows\n    while center + self.batch_size &lt;= data_size:\n        input_batch = input_data[center : center + self.batch_size]\n\n        input_batches_list.append(input_batch)\n\n        center += self.skip_size\n\n    if self.full == True:\n        return input_batches_list\n    else:\n        return np.vstack([item[-1] for item in input_batches_list])\n</code></pre>"},{"location":"simulai_io/#simulai.io.IntersectingBatches.__init__","title":"<code>__init__(skip_size=1, batch_size=None, full=True)</code>","text":"<p>Initializes the IntersectingBatches class</p> <p>Parameters:</p> Name Type Description Default <code>skip_size</code> <code>int</code> <p>Number of samples to skip between two windows. (Default value = 1)</p> <code>1</code> <code>batch_size</code> <code>int</code> <p>Number of samples to use in each batch. (Default value = None)</p> <code>None</code> <code>full</code> <code>bool</code> <p>Whether to include the last batch or not, even if it's not full. (Default value = True)</p> <code>True</code> Source code in <code>simulai/io.py</code> <pre><code>def __init__(\n    self, skip_size: int = 1, batch_size: int = None, full: bool = True\n) -&gt; None:\n    r\"\"\"Initializes the IntersectingBatches class\n\n    Args:\n        skip_size (int, optional): Number of samples to skip between two windows. (Default value = 1)\n        batch_size (int, optional): Number of samples to use in each batch. (Default value = None)\n        full (bool, optional): Whether to include the last batch or not, even if it's not full. (Default value = True)\n\n    \"\"\"\n    assert (\n        batch_size\n    ), f\"A value for horizon_size must be provided, not {batch_size}\"\n\n    self.skip_size = skip_size\n    self.batch_size = batch_size\n    self.full = full\n</code></pre>"},{"location":"simulai_io/#simulai.io.IntersectingBatches.get_indices","title":"<code>get_indices(dim=None)</code>","text":"<p>It gets just the indices of the shifting</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>total dimension (Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the shifted indices</p> Source code in <code>simulai/io.py</code> <pre><code>def get_indices(self, dim: int = None) -&gt; np.ndarray:\n    r\"\"\"It gets just the indices of the shifting\n\n    Args:\n        dim (int, optional): total dimension (Default value = None)\n\n    Returns:\n        np.ndarray: the shifted indices\n\n    \"\"\"\n    center = 0\n    indices = list()\n    indices_m = list()\n\n    # Loop for covering the entire time-series dataset constructing the\n    # training windows\n    while center + self.batch_size &lt; dim:\n        index = center + self.batch_size\n\n        indices.append(center)\n        indices_m.append(index)\n\n        center += self.skip_size\n\n    return np.array(indices), np.array(indices_m)\n</code></pre>"},{"location":"simulai_io/#batchwiseextrapolation","title":"BatchwiseExtrapolation","text":"<p>BatchwiseExtraplation uses a time-series regression model and inputs as generated by MovingWindow to continuously extrapolate a dataset.</p> <p>Attributes:</p> Name Type Description <code>time_id</code> <p>int</p> <p>Examples::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; model = LinearRegression()\n&gt;&gt;&gt; op = lambda state: model.predict(state)\n&gt;&gt;&gt; auxiliary_data = np.random.rand(100, 10)\n&gt;&gt;&gt; batchwise_extrapolation = BatchwiseExtrapolation(op=op, auxiliary_data=auxiliary_data)\n&gt;&gt;&gt; init_state = np.random.rand(1, 10, 20)\n&gt;&gt;&gt; history_size = 3\n&gt;&gt;&gt; horizon_size = 2\n&gt;&gt;&gt; testing_data_size = 10\n&gt;&gt;&gt; extrapolation_dataset = batchwise_extrapolation(init_state, history_size, horizon_size, testing_data_size)\n&gt;&gt;&gt; extrapolation_dataset.shape\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>class BatchwiseExtrapolation:\n    r\"\"\"BatchwiseExtraplation uses a time-series regression model and inputs as generated by\n    MovingWindow to continuously extrapolate a dataset.\n\n    Attributes:\n        time_id : int\n    Examples::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; model = LinearRegression()\n        &gt;&gt;&gt; op = lambda state: model.predict(state)\n        &gt;&gt;&gt; auxiliary_data = np.random.rand(100, 10)\n        &gt;&gt;&gt; batchwise_extrapolation = BatchwiseExtrapolation(op=op, auxiliary_data=auxiliary_data)\n        &gt;&gt;&gt; init_state = np.random.rand(1, 10, 20)\n        &gt;&gt;&gt; history_size = 3\n        &gt;&gt;&gt; horizon_size = 2\n        &gt;&gt;&gt; testing_data_size = 10\n        &gt;&gt;&gt; extrapolation_dataset = batchwise_extrapolation(init_state, history_size, horizon_size, testing_data_size)\n        &gt;&gt;&gt; extrapolation_dataset.shape\n    \"\"\"\n\n    def __init__(self, op: callable = None, auxiliary_data: np.ndarray = None) -&gt; None:\n        self.op = op\n        self.auxiliary_data = auxiliary_data\n        self.time_id = 0\n\n    def _simple_extrapolation(\n        self, extrapolation_dataset: np.ndarray, history_size: int = 0\n    ) -&gt; np.ndarray:\n        r\"\"\"Given the current extrapolation dataset, use the last history_size number of rows to create the next state of the dataset.\n\n        Args:\n            extrapolation_dataset (np.ndarray): The current state of the extrapolation dataset.\n            history_size (int, optional):  (Default value = 0)\n\n        Returns:\n            np.ndarray: The next state of the extrapolation dataset.\n\n        \"\"\"\n        return extrapolation_dataset[None, -history_size:, :]\n\n    def _forcing_extrapolation(\n        self, extrapolation_dataset: np.ndarray, history_size: int = 0\n    ) -&gt; np.ndarray:\n        return np.hstack(\n            [\n                extrapolation_dataset[-history_size:, :],\n                self.auxiliary_data[self.time_id - history_size : self.time_id, :],\n            ]\n        )[None, :, :]\n\n    def __call__(\n        self,\n        init_state: np.ndarray = None,\n        history_size: int = None,\n        horizon_size: int = None,\n        testing_data_size: int = None,\n    ) -&gt; np.ndarray:\n        r\"\"\"A function that performs the extrapolation of the time series.\n\n        Args:\n            init_state (np.ndarray, optional): initial state of the time series. It should have the shape (batch_size, history_size, n_series) (Default value = None)\n            history_size (int, optional): the size of the history window used in the extrapolation. (Default value = None)\n            horizon_size (int, optional): the size of the horizon window used in the extrapolation. (Default value = None)\n            testing_data_size (int, optional):  (Default value = None)\n\n        Returns:\n            np.ndarray:\n\n        Note:\n            The number of series in the initial state must be equal to the number of series in the auxiliary data, if it is provided.\n        Example::\n\n            &gt;&gt;&gt; model = BatchwiseExtrapolation()\n            #Init state of the time series\n            &gt;&gt;&gt; init_state = np.random.random((1,20,3))\n            &gt;&gt;&gt; history_size = 10\n            &gt;&gt;&gt; horizon_size = 5\n            &gt;&gt;&gt; testing_data_size = 50\n            #Calling the function\n            &gt;&gt;&gt; output = model(init_state, history_size, horizon_size, testing_data_size)\n            &gt;&gt;&gt; print(output.shape)\n            #(50,3)\n        \"\"\"\n\n        if isinstance(self.auxiliary_data, np.ndarray):\n            n_series = self.auxiliary_data.shape[-1]\n        else:\n            n_series = 0\n\n        current_state = init_state\n        extrapolation_dataset = init_state[0, :, n_series:]\n        self.time_id = history_size\n\n        if isinstance(self.auxiliary_data, np.ndarray):\n            assert (\n                self.auxiliary_data.shape[-1] + n_series == init_state.shape[-1]\n            ), \"Number of series in the initial state must be {}\".format(\n                self.auxiliary_data.shape[-1]\n            )\n\n            current_state_constructor = self._forcing_extrapolation\n\n        else:\n            current_state_constructor = self._simple_extrapolation\n\n        while (\n            extrapolation_dataset.shape[0] - history_size + horizon_size\n            &lt;= testing_data_size\n        ):\n            extrapolation = self.op(current_state)\n            extrapolation_dataset = np.concatenate(\n                [extrapolation_dataset, extrapolation[0]], 0\n            )\n            current_state = current_state_constructor(\n                extrapolation_dataset, history_size=history_size\n            )\n\n            log_str = \"Extrapolation {}\".format(self.time_id + 1 - history_size)\n            sys.stdout.write(\"\\r\" + log_str)\n            sys.stdout.flush()\n\n            self.time_id += horizon_size\n\n        extrapolation_dataset = extrapolation_dataset[history_size:, :]\n\n        return extrapolation_dataset\n</code></pre>"},{"location":"simulai_io/#simulai.io.BatchwiseExtrapolation.__call__","title":"<code>__call__(init_state=None, history_size=None, horizon_size=None, testing_data_size=None)</code>","text":"<p>A function that performs the extrapolation of the time series.</p> <p>Parameters:</p> Name Type Description Default <code>init_state</code> <code>ndarray</code> <p>initial state of the time series. It should have the shape (batch_size, history_size, n_series) (Default value = None)</p> <code>None</code> <code>history_size</code> <code>int</code> <p>the size of the history window used in the extrapolation. (Default value = None)</p> <code>None</code> <code>horizon_size</code> <code>int</code> <p>the size of the horizon window used in the extrapolation. (Default value = None)</p> <code>None</code> <code>testing_data_size</code> <code>int</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:</p> Note <p>The number of series in the initial state must be equal to the number of series in the auxiliary data, if it is provided.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; model = BatchwiseExtrapolation()\n#Init state of the time series\n&gt;&gt;&gt; init_state = np.random.random((1,20,3))\n&gt;&gt;&gt; history_size = 10\n&gt;&gt;&gt; horizon_size = 5\n&gt;&gt;&gt; testing_data_size = 50\n#Calling the function\n&gt;&gt;&gt; output = model(init_state, history_size, horizon_size, testing_data_size)\n&gt;&gt;&gt; print(output.shape)\n#(50,3)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def __call__(\n    self,\n    init_state: np.ndarray = None,\n    history_size: int = None,\n    horizon_size: int = None,\n    testing_data_size: int = None,\n) -&gt; np.ndarray:\n    r\"\"\"A function that performs the extrapolation of the time series.\n\n    Args:\n        init_state (np.ndarray, optional): initial state of the time series. It should have the shape (batch_size, history_size, n_series) (Default value = None)\n        history_size (int, optional): the size of the history window used in the extrapolation. (Default value = None)\n        horizon_size (int, optional): the size of the horizon window used in the extrapolation. (Default value = None)\n        testing_data_size (int, optional):  (Default value = None)\n\n    Returns:\n        np.ndarray:\n\n    Note:\n        The number of series in the initial state must be equal to the number of series in the auxiliary data, if it is provided.\n    Example::\n\n        &gt;&gt;&gt; model = BatchwiseExtrapolation()\n        #Init state of the time series\n        &gt;&gt;&gt; init_state = np.random.random((1,20,3))\n        &gt;&gt;&gt; history_size = 10\n        &gt;&gt;&gt; horizon_size = 5\n        &gt;&gt;&gt; testing_data_size = 50\n        #Calling the function\n        &gt;&gt;&gt; output = model(init_state, history_size, horizon_size, testing_data_size)\n        &gt;&gt;&gt; print(output.shape)\n        #(50,3)\n    \"\"\"\n\n    if isinstance(self.auxiliary_data, np.ndarray):\n        n_series = self.auxiliary_data.shape[-1]\n    else:\n        n_series = 0\n\n    current_state = init_state\n    extrapolation_dataset = init_state[0, :, n_series:]\n    self.time_id = history_size\n\n    if isinstance(self.auxiliary_data, np.ndarray):\n        assert (\n            self.auxiliary_data.shape[-1] + n_series == init_state.shape[-1]\n        ), \"Number of series in the initial state must be {}\".format(\n            self.auxiliary_data.shape[-1]\n        )\n\n        current_state_constructor = self._forcing_extrapolation\n\n    else:\n        current_state_constructor = self._simple_extrapolation\n\n    while (\n        extrapolation_dataset.shape[0] - history_size + horizon_size\n        &lt;= testing_data_size\n    ):\n        extrapolation = self.op(current_state)\n        extrapolation_dataset = np.concatenate(\n            [extrapolation_dataset, extrapolation[0]], 0\n        )\n        current_state = current_state_constructor(\n            extrapolation_dataset, history_size=history_size\n        )\n\n        log_str = \"Extrapolation {}\".format(self.time_id + 1 - history_size)\n        sys.stdout.write(\"\\r\" + log_str)\n        sys.stdout.flush()\n\n        self.time_id += horizon_size\n\n    extrapolation_dataset = extrapolation_dataset[history_size:, :]\n\n    return extrapolation_dataset\n</code></pre>"},{"location":"simulai_io/#batchcopy","title":"BatchCopy","text":"<p>A class for copying data in batches and applying a transformation function.</p> Source code in <code>simulai/io.py</code> <pre><code>class BatchCopy:\n    r\"\"\"A class for copying data in batches and applying a transformation function.\"\"\"\n\n    def __init__(self, channels_last: bool = False) -&gt; None:\n        self.channels_last = channels_last\n\n    def _single_copy(\n        self,\n        data: h5py.Dataset = None,\n        data_interval: list = None,\n        batch_size: int = None,\n        dump_path: str = None,\n        transformation: callable = lambda data: data,\n    ) -&gt; h5py.Dataset:\n        r\"\"\"Copy data from a single h5py.Dataset to another h5py.Dataset in batches.\n\n        Args:\n            data (h5py.Dataset, optional):  (Default value = None)\n            data_interval (list, optional): The interval of the data to be copied. (Default value = None)\n            batch_size (int, optional): The size of the batch to be copied. (Default value = None)\n            dump_path (str, optional): The path where the new h5py.Dataset will be saved. (Default value = None)\n            transformation (callable, optional):  (Default value = lambda data: data)\n\n        Returns:\n            h5py.Dataset: The new h5py.Dataset after the copy process.\n\n        Note:\n            - Copy data from data_file.h5/data to data_copy.h5/data with a batch size of 1000:\n            - The input must be an h5py.Dataset.\n        Example::\n\n            &gt;&gt;&gt; data = h5py.File(\"data_file.h5\", \"r\")\n            &gt;&gt;&gt; batch_copy = BatchCopy()\n            &gt;&gt;&gt; dset = batch_copy._single_copy(data=data[\"data\"], data_interval=[0, 100000], batch_size=1000, dump_path=\"data_copy.h5\")\n        \"\"\"\n\n        assert isinstance(data, h5py.Dataset), \"The input must be h5py.Dataset\"\n\n        variables_list = data.dtype.names\n        data_shape = (data_interval[1] - data_interval[0],) + data.shape[1:]\n\n        data_file = h5py.File(dump_path, \"w\")\n        dtype = [(var, \"&lt;f8\") for var in variables_list]\n\n        dset = data_file.create_dataset(\"data\", shape=data_shape, dtype=dtype)\n\n        if isinstance(batch_size, MemorySizeEval):\n            n_samples = data_interval[1] - data_interval[0]\n            batch_size = batch_size(max_batches=n_samples, shape=data.shape[1:])\n        else:\n            pass\n\n        # Constructing the normalization  using the reference data\n        batches = batchdomain_constructor(data_interval, batch_size)\n        dset_batches = batchdomain_constructor([0, dset.shape[0]], batch_size)\n\n        variables_names = data.dtype.names\n\n        n_variables = len(data.dtype.names)\n\n        for batch_id, (batch, d_batch) in enumerate(zip(batches, dset_batches)):\n            print(\n                f\"Copying batch {batch_id+1}/{len(batches)} batch_size={batch[1]-batch[0]}\"\n            )\n\n            # The variables dimension is the last one\n            if self.channels_last:\n                # TODO this is a restrictive way of doing it. It must be more flexible.\n                # .transpose((0, 4, 2, 3, 1))\n                chunk_data = data[slice(*batch)].view((float, len(data.dtype.names)))\n            # The variables dimension is the second one\n            else:\n                chunk_data = data[slice(*batch)].view((float, len(data.dtype.names)))\n\n            chunk_data = np.core.records.fromarrays(\n                np.split(chunk_data[...], n_variables, axis=-1),\n                names=variables_names,\n                formats=\",\".join(len(variables_names) * [\"f8\"]),\n            )\n\n            if len(chunk_data.shape) &gt; len(dset.shape):\n                chunk_data = np.squeeze(chunk_data, axis=-1)\n            else:\n                pass\n\n            dset[slice(*d_batch)] = transformation(chunk_data[...])\n\n        return dset\n\n    def _multiple_copy(\n        self,\n        data: list = None,\n        data_interval: list = None,\n        batch_size: int = None,\n        dump_path: str = None,\n        transformation: callable = lambda data: data,\n    ) -&gt; h5py.Dataset:\n        r\"\"\"Copy and concatenate multiple h5py.Dataset objects into a single h5py.Dataset object.\n\n        Args:\n            data (list, optional): A list of h5py.Dataset objects to be concatenated. (Default value = None)\n            data_interval (list, optional): A list of two integers indicating the start and end index of the data to be concatenated. (Default value = None)\n            batch_size (int, optional): The number of samples to be processed at a time. (Default value = None)\n            dump_path (str, optional): The file path where the concatenated h5py.Dataset object will be saved. (Default value = None)\n            transformation (callable, optional):  (Default value = lambda data: data)\n\n        Returns:\n            h5py.Dataset: The concatenated h5py.Dataset object.\n\n        \"\"\"\n\n        assert all(\n            [isinstance(di, h5py.Dataset) for di in data]\n        ), \"All inputs must be h5py.Dataset\"\n\n        variables_list = sum([list(di.dtype.names) for di in data], [])\n        data_shape = (data_interval[1] - data_interval[0],) + data[0].shape[1:]\n\n        data_file = h5py.File(dump_path, \"w\")\n        dtype = [(var, \"&lt;f8\") for var in variables_list]\n\n        dset = data_file.create_dataset(\"data\", shape=data_shape, dtype=dtype)\n\n        if isinstance(batch_size, MemorySizeEval):\n            n_samples = data_interval[1] - data_interval[0]\n            batch_size = batch_size(max_batches=n_samples, shape=data.shape[1:])\n        else:\n            pass\n\n        # Constructing the normalization  using the reference data\n        batches = batchdomain_constructor(data_interval, batch_size)\n        dset_batches = batchdomain_constructor([0, dset.shape[0]], batch_size)\n\n        variables_names = sum([list(di.dtype.names) for di in data], [])\n\n        n_variables = sum([len(di.dtype.names) for di in data])\n\n        for batch_id, (batch, d_batch) in enumerate(zip(batches, dset_batches)):\n            print(\n                f\"Copying and concatenating the batches {batch_id+1}/{len(batches)} batch_size={batch[1] - batch[0]}\"\n            )\n\n            # The variables dimension is the last one\n            if self.channels_last:\n                # TODO this is a restrictive way of doing it. It must be more flexible.\n                chunk_data = np.stack(\n                    [\n                        di[slice(*batch)]\n                        .view((float, len(di.dtype.names)))\n                        .transpose((0, 4, 2, 3, 1))\n                        for di in data\n                    ],\n                    axis=-1,\n                )\n            # The variables dimension is the second one\n            else:\n                chunk_data = np.stack(\n                    [\n                        di[slice(*batch)].view((float, len(di.dtype.names)))\n                        for di in data\n                    ],\n                    axis=-1,\n                )\n\n            chunk_data = np.core.records.fromarrays(\n                np.split(chunk_data[...], n_variables, axis=-1),\n                names=variables_names,\n                formats=\",\".join(len(variables_names) * [\"f8\"]),\n            )\n\n            if len(chunk_data.shape) &gt; len(dset.shape):\n                chunk_data = np.squeeze(chunk_data, axis=-1)\n            else:\n                pass\n\n            dset[slice(*d_batch)] = transformation(chunk_data[...])\n\n        return dset\n\n    def copy(\n        self,\n        data: h5py.Dataset = None,\n        data_interval: list = None,\n        batch_size: int = None,\n        dump_path: str = None,\n        transformation: callable = lambda data: data,\n    ) -&gt; h5py.Dataset:\n        r\"\"\"Copies the data from h5py.Dataset to a new h5py.Dataset file.\n        It allows to apply a transformation function to the data.\n\n        Args:\n            data (h5py.Dataset, optional): input data to be copied (Default value = None)\n            data_interval (list, optional): the range of the data to be copied (Default value = None)\n            batch_size (int, optional): the size of the batches to be used to copy the data (Default value = None)\n            dump_path (str, optional): the path of the file where the data will be copied (Default value = None)\n            transformation (callable, optional):  (Default value = lambda data: data)\n\n        Returns:\n            h5py.Dataset: The copied data\n        Note:\n            - If the data is a list of h5py.Dataset, it will call the `_multiple_copy` function.\n        Example::\n\n            &gt;&gt;&gt; data = h5py.File('data.h5', 'r')\n            &gt;&gt;&gt; data_interval = [0, 100]\n            &gt;&gt;&gt; batch_size = 1000\n            &gt;&gt;&gt; dump_path = 'copied_data.h5'\n            &gt;&gt;&gt; transformation = lambda x: x*2\n            &gt;&gt;&gt; copied_data = copy(data, data_interval, batch_size, dump_path, transformation)\n        \"\"\"\n\n        if isinstance(data, list):\n            return self._multiple_copy(\n                data=data,\n                data_interval=data_interval,\n                batch_size=batch_size,\n                dump_path=dump_path,\n                transformation=transformation,\n            )\n\n        else:\n            return self._single_copy(\n                data=data,\n                data_interval=data_interval,\n                batch_size=batch_size,\n                dump_path=dump_path,\n                transformation=transformation,\n            )\n</code></pre>"},{"location":"simulai_io/#simulai.io.BatchCopy.copy","title":"<code>copy(data=None, data_interval=None, batch_size=None, dump_path=None, transformation=lambda : data)</code>","text":"<p>Copies the data from h5py.Dataset to a new h5py.Dataset file. It allows to apply a transformation function to the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dataset</code> <p>input data to be copied (Default value = None)</p> <code>None</code> <code>data_interval</code> <code>list</code> <p>the range of the data to be copied (Default value = None)</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>the size of the batches to be used to copy the data (Default value = None)</p> <code>None</code> <code>dump_path</code> <code>str</code> <p>the path of the file where the data will be copied (Default value = None)</p> <code>None</code> <code>transformation</code> <code>callable</code> <p>(Default value = lambda data: data)</p> <code>lambda : data</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>h5py.Dataset: The copied data</p> <p>Note:     - If the data is a list of h5py.Dataset, it will call the <code>_multiple_copy</code> function. Example::</p> <pre><code>&gt;&gt;&gt; data = h5py.File('data.h5', 'r')\n&gt;&gt;&gt; data_interval = [0, 100]\n&gt;&gt;&gt; batch_size = 1000\n&gt;&gt;&gt; dump_path = 'copied_data.h5'\n&gt;&gt;&gt; transformation = lambda x: x*2\n&gt;&gt;&gt; copied_data = copy(data, data_interval, batch_size, dump_path, transformation)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>def copy(\n    self,\n    data: h5py.Dataset = None,\n    data_interval: list = None,\n    batch_size: int = None,\n    dump_path: str = None,\n    transformation: callable = lambda data: data,\n) -&gt; h5py.Dataset:\n    r\"\"\"Copies the data from h5py.Dataset to a new h5py.Dataset file.\n    It allows to apply a transformation function to the data.\n\n    Args:\n        data (h5py.Dataset, optional): input data to be copied (Default value = None)\n        data_interval (list, optional): the range of the data to be copied (Default value = None)\n        batch_size (int, optional): the size of the batches to be used to copy the data (Default value = None)\n        dump_path (str, optional): the path of the file where the data will be copied (Default value = None)\n        transformation (callable, optional):  (Default value = lambda data: data)\n\n    Returns:\n        h5py.Dataset: The copied data\n    Note:\n        - If the data is a list of h5py.Dataset, it will call the `_multiple_copy` function.\n    Example::\n\n        &gt;&gt;&gt; data = h5py.File('data.h5', 'r')\n        &gt;&gt;&gt; data_interval = [0, 100]\n        &gt;&gt;&gt; batch_size = 1000\n        &gt;&gt;&gt; dump_path = 'copied_data.h5'\n        &gt;&gt;&gt; transformation = lambda x: x*2\n        &gt;&gt;&gt; copied_data = copy(data, data_interval, batch_size, dump_path, transformation)\n    \"\"\"\n\n    if isinstance(data, list):\n        return self._multiple_copy(\n            data=data,\n            data_interval=data_interval,\n            batch_size=batch_size,\n            dump_path=dump_path,\n            transformation=transformation,\n        )\n\n    else:\n        return self._single_copy(\n            data=data,\n            data_interval=data_interval,\n            batch_size=batch_size,\n            dump_path=dump_path,\n            transformation=transformation,\n        )\n</code></pre>"},{"location":"simulai_io/#maketensor","title":"MakeTensor","text":"<p>This class is used to make torch tensors from numpy arrays or dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>input_names</code> <code>List[str]</code> <p>list of input names.</p> <code>None</code> <code>output_names</code> <code>List[str]</code> <p>list of output names.</p> <code>None</code> Note <ul> <li>input_tensors will be a list of tensors in case of numpy array and dictionary inputs.</li> <li>The input_data should be numpy array with shape (batch_size, features_size) or dictionary with keys from input_names and values with shape (batch_size, features_size) if input_names and output_names are provided.</li> <li>The input_data will be converted to float32 dtype.</li> <li>The input_data will be put on the device specified by the device parameter, which defaults to 'cpu'.</li> <li>If input_data is None, it will raise an exception.</li> </ul> <p>Example::</p> <pre><code># Creating a MakeTensor object with input and output names\n\n# Converting numpy array to torch tensor\n\n# Converting dictionary to torch tensors\n\n&gt;&gt;&gt; mt = MakeTensor(input_names=[\"input_1\", \"input_2\"], output_names=[\"output\"])\n\n&gt;&gt;&gt; input_data = np.random.randn(10, 3)\n&gt;&gt;&gt; input_tensors = mt(input_data)\n\n&gt;&gt;&gt; input_data = {\"input_1\": np.random.randn(10, 3), \"input_2\": np.random.randn(10, 4)}\n&gt;&gt;&gt; input_tensors = mt(input_data)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>class MakeTensor:\n    r\"\"\"This class is used to make torch tensors from numpy arrays or dictionaries.\n\n    Args:\n        input_names (List[str]): list of input names.\n        output_names (List[str]): list of output names.\n\n    Note:\n        - input_tensors will be a list of tensors in case of numpy array and dictionary inputs.\n        - The input_data should be numpy array with shape (batch_size, features_size) or dictionary with keys from input_names and values with shape (batch_size, features_size) if input_names and output_names are provided.\n        - The input_data will be converted to float32 dtype.\n        - The input_data will be put on the device specified by the device parameter, which defaults to 'cpu'.\n        - If input_data is None, it will raise an exception.\n    Example::\n\n        # Creating a MakeTensor object with input and output names\n\n        # Converting numpy array to torch tensor\n\n        # Converting dictionary to torch tensors\n\n        &gt;&gt;&gt; mt = MakeTensor(input_names=[\"input_1\", \"input_2\"], output_names=[\"output\"])\n\n        &gt;&gt;&gt; input_data = np.random.randn(10, 3)\n        &gt;&gt;&gt; input_tensors = mt(input_data)\n\n        &gt;&gt;&gt; input_data = {\"input_1\": np.random.randn(10, 3), \"input_2\": np.random.randn(10, 4)}\n        &gt;&gt;&gt; input_tensors = mt(input_data)\n    \"\"\"\n\n    def __init__(self, input_names=None, output_names=None):\n        self.input_names = input_names\n        self.output_names = output_names\n\n    def _make_tensor(\n        self, input_data: np.ndarray = None, device: str = \"cpu\"\n    ) -&gt; List[torch.Tensor]:\n        r\"\"\"Convert input_data to a list of torch tensors.\n\n        Args:\n            input_data (np.ndarray, optional):  (Default value = None)\n            device (str, optional):  (Default value = \"cpu\")\n\n        Returns:\n            List[torch.Tensor]: list of tensors.\n\n        \"\"\"\n        inputs_list = list(torch.split(input_data, 1, dim=-1))\n\n        for vv, var in enumerate(inputs_list):\n            var.requires_grad = True\n            var = var.to(device)\n            inputs_list[vv] = var\n            # var = var[..., None]\n\n        return inputs_list\n\n    def _make_tensor_dict(self, input_data: dict = None, device: str = \"cpu\") -&gt; dict:\n        r\"\"\"Convert input_data to a dictionary of torch tensors.\n\n        Args:\n            input_data (dict, optional):  (Default value = None)\n            device (str, optional):  (Default value = \"cpu\")\n\n        Returns:\n            dict: dictionary of tensors.\n\n        \"\"\"\n        inputs_dict = dict()\n\n        for key, item in input_data.items():\n            item.requires_grad = True\n            item = item.to(device)\n            inputs_dict[key] = item\n\n        return inputs_dict\n\n    def __call__(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor, Dict[str, np.ndarray]] = None,\n        device: str = \"cpu\",\n    ) -&gt; List[torch.Tensor]:\n        r\"\"\"Make tensors from input_data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor, Dict[str, np.ndarray]], optional): input data to be converted. (Default value = None)\n            device (str, optional):  (Default value = \"cpu\")\n\n        Returns:\n            Union[List[torch.Tensor], dict]:\n\n        Raises:\n            - Exception:\n\n\n        \"\"\"\n\n        if type(input_data) == np.ndarray:\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n            inputs_list = self._make_tensor(input_data=input_data, device=device)\n\n            return inputs_list\n\n        if type(input_data) == torch.Tensor:\n            inputs_list = self._make_tensor(input_data=input_data, device=device)\n\n            return inputs_list\n\n        elif type(input_data) == dict:\n            inputs_list = self._make_tensor_dict(input_data=input_data, device=device)\n\n            return inputs_list\n\n        else:\n            raise Exception(\n                f\"The type {type(input_data)} for input_data is not supported.\"\n            )\n</code></pre>"},{"location":"simulai_io/#simulai.io.MakeTensor.__call__","title":"<code>__call__(input_data=None, device='cpu')</code>","text":"<p>Make tensors from input_data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor, Dict[str, ndarray]]</code> <p>input data to be converted. (Default value = None)</p> <code>None</code> <code>device</code> <code>str</code> <p>(Default value = \"cpu\")</p> <code>'cpu'</code> <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>Union[List[torch.Tensor], dict]:</p> <p>Raises:</p> Type Description <code>-Exception</code> Source code in <code>simulai/io.py</code> <pre><code>def __call__(\n    self,\n    input_data: Union[np.ndarray, torch.Tensor, Dict[str, np.ndarray]] = None,\n    device: str = \"cpu\",\n) -&gt; List[torch.Tensor]:\n    r\"\"\"Make tensors from input_data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor, Dict[str, np.ndarray]], optional): input data to be converted. (Default value = None)\n        device (str, optional):  (Default value = \"cpu\")\n\n    Returns:\n        Union[List[torch.Tensor], dict]:\n\n    Raises:\n        - Exception:\n\n\n    \"\"\"\n\n    if type(input_data) == np.ndarray:\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        inputs_list = self._make_tensor(input_data=input_data, device=device)\n\n        return inputs_list\n\n    if type(input_data) == torch.Tensor:\n        inputs_list = self._make_tensor(input_data=input_data, device=device)\n\n        return inputs_list\n\n    elif type(input_data) == dict:\n        inputs_list = self._make_tensor_dict(input_data=input_data, device=device)\n\n        return inputs_list\n\n    else:\n        raise Exception(\n            f\"The type {type(input_data)} for input_data is not supported.\"\n        )\n</code></pre>"},{"location":"simulai_io/#gaussiannoise","title":"GaussianNoise","text":"<p>             Bases: <code>Dataset</code></p> <p>GaussianNoise(stddev=0.01, input_data=None) A dataset that applies Gaussian noise to input data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; input_data = np.random.rand(100,100)\n&gt;&gt;&gt; dataset = GaussianNoise(stddev=0.05, input_data=input_data)\n&gt;&gt;&gt; dataset.size()\n(100, 100)\n</code></pre> Source code in <code>simulai/io.py</code> <pre><code>class GaussianNoise(Dataset):\n    r\"\"\"GaussianNoise(stddev=0.01, input_data=None)\n    A dataset that applies Gaussian noise to input data.\n\n    Example::\n\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; input_data = np.random.rand(100,100)\n        &gt;&gt;&gt; dataset = GaussianNoise(stddev=0.05, input_data=input_data)\n        &gt;&gt;&gt; dataset.size()\n        (100, 100)\n    \"\"\"\n\n    def __init__(\n        self, stddev: float = 0.01, input_data: Union[np.ndarray, Tensor] = None\n    ):\n        super(Dataset, self).__init__()\n\n        self.stddev = stddev\n\n        if isinstance(input_data, np.ndarray):\n            input_data_ = torch.from_numpy(input_data.astype(\"float32\"))\n        else:\n            input_data_ = input_data\n\n        self.input_data = input_data_\n\n        self.data_shape = tuple(self.input_data.shape)\n\n    def size(self):\n        return self.data_shape\n\n    def __call__(self):\n        return (1 + self.stddev * torch.randn(*self.data_shape)) * self.input_data\n</code></pre>"},{"location":"simulai_models/","title":"simulai.models","text":""},{"location":"simulai_models/#transformer","title":"Transformer","text":"<p>             Bases: <code>NetworkTemplate</code></p> Source code in <code>simulai/models/_pytorch_models/_transformer.py</code> <pre><code>class Transformer(NetworkTemplate):\n    def __init__(\n        self,\n        num_heads_encoder: int = 1,\n        num_heads_decoder: int = 1,\n        embed_dim_encoder: int = Union[int, Tuple],\n        embed_dim_decoder: int = Union[int, Tuple],\n        encoder_activation: Union[str, torch.nn.Module] = \"relu\",\n        decoder_activation: Union[str, torch.nn.Module] = \"relu\",\n        encoder_mlp_layer_config: dict = None,\n        decoder_mlp_layer_config: dict = None,\n        number_of_encoders: int = 1,\n        number_of_decoders: int = 1,\n    ) -&gt; None:\n        r\"\"\"A classical encoder-decoder transformer:\n\n        Graphical example:\n\n        Example::\n\n             U -&gt; ( Encoder_1 -&gt; Encoder_2 -&gt; ... -&gt; Encoder_N ) -&gt; u_e\n\n            (u_e, U) -&gt; ( Decoder_1 -&gt; Decoder_2 -&gt; ... Decoder_N ) -&gt; V\n\n        Args:\n            num_heads_encoder (int, optional): The number of heads for the self-attention layer of the encoder. (Default value = 1)\n            num_heads_decoder (int, optional): The number of heads for the self-attention layer of the decoder. (Default value = 1)\n            embed_dim_encoder (int, optional): The dimension of the embedding for the encoder. (Default value = Union[int, Tuple])\n            embed_dim_decoder (int, optional): The dimension of the embedding for the decoder. (Default value = Union[int, Tuple])\n            encoder_activation (Union[str, torch.nn.Module], optional): The activation to be used in all the encoder layers. (Default value = 'relu')\n            decoder_activation (Union[str, torch.nn.Module], optional): The activation to be used in all the decoder layers. (Default value = 'relu')\n            encoder_mlp_layer_config (dict, optional): A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)\n            decoder_mlp_layer_config (dict, optional): A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)\n            number_of_encoders (int, optional): The number of encoders to be used. (Default value = 1)\n            number_of_decoders (int, optional): The number of decoders to be used. (Default value = 1)\n\n        \"\"\"\n\n        super(Transformer, self).__init__()\n\n        self.num_heads_encoder = num_heads_encoder\n        self.num_heads_decoder = num_heads_decoder\n\n        self.embed_dim_encoder = embed_dim_encoder\n        self.embed_dim_decoder = embed_dim_decoder\n\n        self.encoder_mlp_layer_dict = encoder_mlp_layer_config\n        self.decoder_mlp_layer_dict = decoder_mlp_layer_config\n\n        self.number_of_encoders = number_of_encoders\n        self.number_of_decoders = number_of_encoders\n\n        self.encoder_activation = encoder_activation\n        self.decoder_activation = decoder_activation\n\n        self.encoder_mlp_layers_list = list()\n        self.decoder_mlp_layers_list = list()\n\n        # Creating independent copies for the MLP layers which will be used\n        # by the multiple encoders/decoders.\n        for e in range(self.number_of_encoders):\n            self.encoder_mlp_layers_list.append(\n                DenseNetwork(**self.encoder_mlp_layer_dict)\n            )\n\n        for d in range(self.number_of_decoders):\n            self.decoder_mlp_layers_list.append(\n                DenseNetwork(**self.decoder_mlp_layer_dict)\n            )\n\n        # Defining the encoder architecture\n        self.EncoderStage = torch.nn.Sequential(\n            *[\n                BasicEncoder(\n                    num_heads=self.num_heads_encoder,\n                    activation=self.encoder_activation,\n                    mlp_layer=self.encoder_mlp_layers_list[e],\n                    embed_dim=self.embed_dim_encoder,\n                )\n                for e in range(self.number_of_encoders)\n            ]\n        )\n\n        # Defining the decoder architecture\n        self.DecoderStage = torch.nn.ModuleList(\n            [\n                BasicDecoder(\n                    num_heads=self.num_heads_decoder,\n                    activation=self.decoder_activation,\n                    mlp_layer=self.decoder_mlp_layers_list[d],\n                    embed_dim=self.embed_dim_decoder,\n                )\n                for d in range(self.number_of_decoders)\n            ]\n        )\n\n        self.weights = list()\n\n        for e, encoder_e in enumerate(self.EncoderStage):\n            self.weights += encoder_e.weights\n            self.add_module(f\"encoder_{e}\", encoder_e)\n\n        for d, decoder_d in enumerate(self.DecoderStage):\n            self.weights += decoder_d.weights\n            self.add_module(f\"decoder_{d}\", decoder_d)\n\n    @as_tensor\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input dataset. (Default value = None)\n\n        Returns:\n            torch.Tensor: The transformer output.\n\n        \"\"\"\n\n        encoder_output = self.EncoderStage(input_data)\n\n        current_input = input_data\n        for decoder in self.DecoderStage:\n            output = decoder(input_data=current_input, encoder_output=encoder_output)\n            current_input = output\n\n        return output\n\n    def summary(self):\n        \"\"\"It prints a general view of the architecture.\"\"\"\n\n        print(self)\n</code></pre>"},{"location":"simulai_models/#simulai.models.Transformer.__init__","title":"<code>__init__(num_heads_encoder=1, num_heads_decoder=1, embed_dim_encoder=Union[int, Tuple], embed_dim_decoder=Union[int, Tuple], encoder_activation='relu', decoder_activation='relu', encoder_mlp_layer_config=None, decoder_mlp_layer_config=None, number_of_encoders=1, number_of_decoders=1)</code>","text":"<p>A classical encoder-decoder transformer:</p> <p>Graphical example:</p> <p>Example::</p> <pre><code> U -&gt; ( Encoder_1 -&gt; Encoder_2 -&gt; ... -&gt; Encoder_N ) -&gt; u_e\n\n(u_e, U) -&gt; ( Decoder_1 -&gt; Decoder_2 -&gt; ... Decoder_N ) -&gt; V\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>num_heads_encoder</code> <code>int</code> <p>The number of heads for the self-attention layer of the encoder. (Default value = 1)</p> <code>1</code> <code>num_heads_decoder</code> <code>int</code> <p>The number of heads for the self-attention layer of the decoder. (Default value = 1)</p> <code>1</code> <code>embed_dim_encoder</code> <code>int</code> <p>The dimension of the embedding for the encoder. (Default value = Union[int, Tuple])</p> <code>Union[int, Tuple]</code> <code>embed_dim_decoder</code> <code>int</code> <p>The dimension of the embedding for the decoder. (Default value = Union[int, Tuple])</p> <code>Union[int, Tuple]</code> <code>encoder_activation</code> <code>Union[str, Module]</code> <p>The activation to be used in all the encoder layers. (Default value = 'relu')</p> <code>'relu'</code> <code>decoder_activation</code> <code>Union[str, Module]</code> <p>The activation to be used in all the decoder layers. (Default value = 'relu')</p> <code>'relu'</code> <code>encoder_mlp_layer_config</code> <code>dict</code> <p>A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)</p> <code>None</code> <code>decoder_mlp_layer_config</code> <code>dict</code> <p>A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)</p> <code>None</code> <code>number_of_encoders</code> <code>int</code> <p>The number of encoders to be used. (Default value = 1)</p> <code>1</code> <code>number_of_decoders</code> <code>int</code> <p>The number of decoders to be used. (Default value = 1)</p> <code>1</code> Source code in <code>simulai/models/_pytorch_models/_transformer.py</code> <pre><code>def __init__(\n    self,\n    num_heads_encoder: int = 1,\n    num_heads_decoder: int = 1,\n    embed_dim_encoder: int = Union[int, Tuple],\n    embed_dim_decoder: int = Union[int, Tuple],\n    encoder_activation: Union[str, torch.nn.Module] = \"relu\",\n    decoder_activation: Union[str, torch.nn.Module] = \"relu\",\n    encoder_mlp_layer_config: dict = None,\n    decoder_mlp_layer_config: dict = None,\n    number_of_encoders: int = 1,\n    number_of_decoders: int = 1,\n) -&gt; None:\n    r\"\"\"A classical encoder-decoder transformer:\n\n    Graphical example:\n\n    Example::\n\n         U -&gt; ( Encoder_1 -&gt; Encoder_2 -&gt; ... -&gt; Encoder_N ) -&gt; u_e\n\n        (u_e, U) -&gt; ( Decoder_1 -&gt; Decoder_2 -&gt; ... Decoder_N ) -&gt; V\n\n    Args:\n        num_heads_encoder (int, optional): The number of heads for the self-attention layer of the encoder. (Default value = 1)\n        num_heads_decoder (int, optional): The number of heads for the self-attention layer of the decoder. (Default value = 1)\n        embed_dim_encoder (int, optional): The dimension of the embedding for the encoder. (Default value = Union[int, Tuple])\n        embed_dim_decoder (int, optional): The dimension of the embedding for the decoder. (Default value = Union[int, Tuple])\n        encoder_activation (Union[str, torch.nn.Module], optional): The activation to be used in all the encoder layers. (Default value = 'relu')\n        decoder_activation (Union[str, torch.nn.Module], optional): The activation to be used in all the decoder layers. (Default value = 'relu')\n        encoder_mlp_layer_config (dict, optional): A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)\n        decoder_mlp_layer_config (dict, optional): A configuration dictionary to instantiate the encoder MLP layer.weights (Default value = None)\n        number_of_encoders (int, optional): The number of encoders to be used. (Default value = 1)\n        number_of_decoders (int, optional): The number of decoders to be used. (Default value = 1)\n\n    \"\"\"\n\n    super(Transformer, self).__init__()\n\n    self.num_heads_encoder = num_heads_encoder\n    self.num_heads_decoder = num_heads_decoder\n\n    self.embed_dim_encoder = embed_dim_encoder\n    self.embed_dim_decoder = embed_dim_decoder\n\n    self.encoder_mlp_layer_dict = encoder_mlp_layer_config\n    self.decoder_mlp_layer_dict = decoder_mlp_layer_config\n\n    self.number_of_encoders = number_of_encoders\n    self.number_of_decoders = number_of_encoders\n\n    self.encoder_activation = encoder_activation\n    self.decoder_activation = decoder_activation\n\n    self.encoder_mlp_layers_list = list()\n    self.decoder_mlp_layers_list = list()\n\n    # Creating independent copies for the MLP layers which will be used\n    # by the multiple encoders/decoders.\n    for e in range(self.number_of_encoders):\n        self.encoder_mlp_layers_list.append(\n            DenseNetwork(**self.encoder_mlp_layer_dict)\n        )\n\n    for d in range(self.number_of_decoders):\n        self.decoder_mlp_layers_list.append(\n            DenseNetwork(**self.decoder_mlp_layer_dict)\n        )\n\n    # Defining the encoder architecture\n    self.EncoderStage = torch.nn.Sequential(\n        *[\n            BasicEncoder(\n                num_heads=self.num_heads_encoder,\n                activation=self.encoder_activation,\n                mlp_layer=self.encoder_mlp_layers_list[e],\n                embed_dim=self.embed_dim_encoder,\n            )\n            for e in range(self.number_of_encoders)\n        ]\n    )\n\n    # Defining the decoder architecture\n    self.DecoderStage = torch.nn.ModuleList(\n        [\n            BasicDecoder(\n                num_heads=self.num_heads_decoder,\n                activation=self.decoder_activation,\n                mlp_layer=self.decoder_mlp_layers_list[d],\n                embed_dim=self.embed_dim_decoder,\n            )\n            for d in range(self.number_of_decoders)\n        ]\n    )\n\n    self.weights = list()\n\n    for e, encoder_e in enumerate(self.EncoderStage):\n        self.weights += encoder_e.weights\n        self.add_module(f\"encoder_{e}\", encoder_e)\n\n    for d, decoder_d in enumerate(self.DecoderStage):\n        self.weights += decoder_d.weights\n        self.add_module(f\"decoder_{d}\", decoder_d)\n</code></pre>"},{"location":"simulai_models/#simulai.models.Transformer.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>The input dataset. (Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The transformer output.</p> Source code in <code>simulai/models/_pytorch_models/_transformer.py</code> <pre><code>@as_tensor\ndef forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): The input dataset. (Default value = None)\n\n    Returns:\n        torch.Tensor: The transformer output.\n\n    \"\"\"\n\n    encoder_output = self.EncoderStage(input_data)\n\n    current_input = input_data\n    for decoder in self.DecoderStage:\n        output = decoder(input_data=current_input, encoder_output=encoder_output)\n        current_input = output\n\n    return output\n</code></pre>"},{"location":"simulai_models/#simulai.models.Transformer.summary","title":"<code>summary()</code>","text":"<p>It prints a general view of the architecture.</p> Source code in <code>simulai/models/_pytorch_models/_transformer.py</code> <pre><code>def summary(self):\n    \"\"\"It prints a general view of the architecture.\"\"\"\n\n    print(self)\n</code></pre>"},{"location":"simulai_models/#u-net","title":"U-Net","text":"<p>             Bases: <code>NetworkTemplate</code></p> Source code in <code>simulai/models/_pytorch_models/_unet.py</code> <pre><code>class UNet(NetworkTemplate):\n    def __init__(\n        self,\n        layers_config: Dict = None,\n        intermediary_outputs_indices: List[int] = None,\n        intermediary_inputs_indices: List[int] = None,\n        encoder_extra_args: Dict = dict(),\n        decoder_extra_args: Dict = dict(),\n    ) -&gt; None:\n        \"\"\"U-Net.\n\n        Args:\n            layers_config (Dict, optional): A dictionary containing the complete configuration for the\n            U-Net encoder and decoder. (Default value = None)\n            intermediary_outputs_indices (List[int], optional): A list of indices for indicating the encoder outputs. (Default value = None)\n            intermediary_inputs_indices (List[int], optional): A list of indices for indicating the decoder inputs. (Default value = None)\n            encoder_extra_args (Dict, optional): A dictionary containing extra arguments for the encoder. (Default value = dict())\n            decoder_extra_args (Dict, optional): A dictionary containing extra arguments for the decoder. (Default value = dict())\n\n        \"\"\"\n\n        super(UNet, self).__init__()\n\n        self.layers_config = layers_config\n        self.intermediary_outputs_indices = intermediary_outputs_indices\n        self.intermediary_inputs_indices = intermediary_inputs_indices\n\n        self.layers_config_encoder = self.layers_config[\"encoder\"]\n        self.layers_config_decoder = self.layers_config[\"decoder\"]\n\n        self.encoder_activations = self.layers_config[\"encoder_activations\"]\n        self.decoder_activations = self.layers_config[\"decoder_activations\"]\n\n        self.encoder_horizontal_outputs = dict()\n\n        # Configuring the encoder\n        encoder_type = self.layers_config_encoder.get(\"type\")\n        layers_config_encoder = self.layers_config_encoder.get(\"architecture\")\n\n        if encoder_type == \"cnn\":\n            self.encoder = CNNUnetEncoder(\n                layers=self.layers_config_encoder[\"architecture\"],\n                activations=self.encoder_activations,\n                intermediary_outputs_indices=self.intermediary_outputs_indices,\n                case=\"2d\",\n                name=\"encoder\",\n                **encoder_extra_args,\n            )\n        else:\n            raise Exception(f\"Option {encoder_type} is not available.\")\n\n        # Configuring the decoder\n        decoder_type = self.layers_config_decoder.get(\"type\")\n        layers_config_encoder = self.layers_config_encoder.get(\"architecture\")\n\n        if encoder_type == \"cnn\":\n            self.decoder = CNNUnetDecoder(\n                layers=self.layers_config_decoder[\"architecture\"],\n                activations=self.decoder_activations,\n                intermediary_inputs_indices=self.intermediary_inputs_indices,\n                case=\"2d\",\n                name=\"decoder\",\n                **decoder_extra_args,\n            )\n        else:\n            raise Exception(f\"Option {encoder_type} is not available.\")\n\n        self.add_module(\"encoder\", self.encoder)\n        self.add_module(\"decoder\", self.decoder)\n\n    @as_tensor\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"The U-Net forward method.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): A dataset to be inputted in the CNN U-Net encoder. (Default value = None)\n\n        Returns:\n            torch.Tensor: The U-Net output.\n\n        \"\"\"\n\n        encoder_main_output, encoder_intermediary_outputs = self.encoder(\n            input_data=input_data\n        )\n        output = self.decoder(\n            input_data=encoder_main_output,\n            intermediary_encoder_outputs=encoder_intermediary_outputs,\n        )\n\n        return output\n\n    def summary(self):\n        \"\"\"It shows a general view of the architecture.\"\"\"\n\n        print(self)\n</code></pre>"},{"location":"simulai_models/#simulai.models.UNet.__init__","title":"<code>__init__(layers_config=None, intermediary_outputs_indices=None, intermediary_inputs_indices=None, encoder_extra_args=dict(), decoder_extra_args=dict())</code>","text":"<p>U-Net.</p> <p>Parameters:</p> Name Type Description Default <code>layers_config</code> <code>Dict</code> <p>A dictionary containing the complete configuration for the</p> <code>None</code> <code>intermediary_outputs_indices</code> <code>List[int]</code> <p>A list of indices for indicating the encoder outputs. (Default value = None)</p> <code>None</code> <code>intermediary_inputs_indices</code> <code>List[int]</code> <p>A list of indices for indicating the decoder inputs. (Default value = None)</p> <code>None</code> <code>encoder_extra_args</code> <code>Dict</code> <p>A dictionary containing extra arguments for the encoder. (Default value = dict())</p> <code>dict()</code> <code>decoder_extra_args</code> <code>Dict</code> <p>A dictionary containing extra arguments for the decoder. (Default value = dict())</p> <code>dict()</code> Source code in <code>simulai/models/_pytorch_models/_unet.py</code> <pre><code>def __init__(\n    self,\n    layers_config: Dict = None,\n    intermediary_outputs_indices: List[int] = None,\n    intermediary_inputs_indices: List[int] = None,\n    encoder_extra_args: Dict = dict(),\n    decoder_extra_args: Dict = dict(),\n) -&gt; None:\n    \"\"\"U-Net.\n\n    Args:\n        layers_config (Dict, optional): A dictionary containing the complete configuration for the\n        U-Net encoder and decoder. (Default value = None)\n        intermediary_outputs_indices (List[int], optional): A list of indices for indicating the encoder outputs. (Default value = None)\n        intermediary_inputs_indices (List[int], optional): A list of indices for indicating the decoder inputs. (Default value = None)\n        encoder_extra_args (Dict, optional): A dictionary containing extra arguments for the encoder. (Default value = dict())\n        decoder_extra_args (Dict, optional): A dictionary containing extra arguments for the decoder. (Default value = dict())\n\n    \"\"\"\n\n    super(UNet, self).__init__()\n\n    self.layers_config = layers_config\n    self.intermediary_outputs_indices = intermediary_outputs_indices\n    self.intermediary_inputs_indices = intermediary_inputs_indices\n\n    self.layers_config_encoder = self.layers_config[\"encoder\"]\n    self.layers_config_decoder = self.layers_config[\"decoder\"]\n\n    self.encoder_activations = self.layers_config[\"encoder_activations\"]\n    self.decoder_activations = self.layers_config[\"decoder_activations\"]\n\n    self.encoder_horizontal_outputs = dict()\n\n    # Configuring the encoder\n    encoder_type = self.layers_config_encoder.get(\"type\")\n    layers_config_encoder = self.layers_config_encoder.get(\"architecture\")\n\n    if encoder_type == \"cnn\":\n        self.encoder = CNNUnetEncoder(\n            layers=self.layers_config_encoder[\"architecture\"],\n            activations=self.encoder_activations,\n            intermediary_outputs_indices=self.intermediary_outputs_indices,\n            case=\"2d\",\n            name=\"encoder\",\n            **encoder_extra_args,\n        )\n    else:\n        raise Exception(f\"Option {encoder_type} is not available.\")\n\n    # Configuring the decoder\n    decoder_type = self.layers_config_decoder.get(\"type\")\n    layers_config_encoder = self.layers_config_encoder.get(\"architecture\")\n\n    if encoder_type == \"cnn\":\n        self.decoder = CNNUnetDecoder(\n            layers=self.layers_config_decoder[\"architecture\"],\n            activations=self.decoder_activations,\n            intermediary_inputs_indices=self.intermediary_inputs_indices,\n            case=\"2d\",\n            name=\"decoder\",\n            **decoder_extra_args,\n        )\n    else:\n        raise Exception(f\"Option {encoder_type} is not available.\")\n\n    self.add_module(\"encoder\", self.encoder)\n    self.add_module(\"decoder\", self.decoder)\n</code></pre>"},{"location":"simulai_models/#simulai.models.UNet.forward","title":"<code>forward(input_data=None)</code>","text":"<p>The U-Net forward method.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>A dataset to be inputted in the CNN U-Net encoder. (Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The U-Net output.</p> Source code in <code>simulai/models/_pytorch_models/_unet.py</code> <pre><code>@as_tensor\ndef forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"The U-Net forward method.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): A dataset to be inputted in the CNN U-Net encoder. (Default value = None)\n\n    Returns:\n        torch.Tensor: The U-Net output.\n\n    \"\"\"\n\n    encoder_main_output, encoder_intermediary_outputs = self.encoder(\n        input_data=input_data\n    )\n    output = self.decoder(\n        input_data=encoder_main_output,\n        intermediary_encoder_outputs=encoder_intermediary_outputs,\n    )\n\n    return output\n</code></pre>"},{"location":"simulai_models/#simulai.models.UNet.summary","title":"<code>summary()</code>","text":"<p>It shows a general view of the architecture.</p> Source code in <code>simulai/models/_pytorch_models/_unet.py</code> <pre><code>def summary(self):\n    \"\"\"It shows a general view of the architecture.\"\"\"\n\n    print(self)\n</code></pre>"},{"location":"simulai_models/#deeponet","title":"DeepONet","text":"<p>             Bases: <code>NetworkTemplate</code></p> Source code in <code>simulai/models/_pytorch_models/_deeponet.py</code> <pre><code>class DeepONet(NetworkTemplate):\n    name = \"deeponet\"\n    engine = \"torch\"\n\n    def __init__(\n        self,\n        trunk_network: NetworkTemplate = None,\n        branch_network: NetworkTemplate = None,\n        decoder_network: NetworkTemplate = None,  # The decoder network is optional and considered\n        var_dim: int = 1,  # less effective than the output reshaping alternative\n        devices: Union[str, list] = \"cpu\",\n        product_type: str = None,\n        rescale_factors: np.ndarray = None,\n        model_id: str = None,\n        use_bias: bool = False,\n    ) -&gt; None:\n        \"\"\"Classical Deep Operator Network (DeepONet), a deep learning version\n        of the Universal Approximation Theorem.\n\n        Args:\n            trunk_network (NetworkTemplate, optional): Subnetwork for processing the coordinates inputs. (Default value = None)\n            branch_network (NetworkTemplate, optional): Subnetwork for processing the forcing/conditioning inputs. (Default value = None)\n            decoder_network (NetworkTemplate, optional): Subnetworks for converting the embedding to the output (optional). (Default value = None)\n            devices (Union[str, list], optional):  Devices in which the model will be executed. (Default value = \"cpu\")\n            product_type (str, optional): Type of product to execute in the embedding space. (Default value = None)\n            rescale_factors (np.ndarray, optional): Values used for rescaling the network outputs for a given order of magnitude. (Default value = None)\n            model_id (str, optional): Name for the model (Default value = None)\n            use_bias (bool, optional):  (Default value = False)\n\n        \"\"\"\n\n        super(DeepONet, self).__init__(devices=devices)\n\n        # Determining the kind of device to be used for allocating the\n        # subnetworks used in the DeepONet model\n        self.device = self._set_device(devices=devices)\n        self.use_bias = use_bias\n\n        self.trunk_network = self.to_wrap(entity=trunk_network, device=self.device)\n        self.branch_network = self.to_wrap(entity=branch_network, device=self.device)\n\n        self.add_module(\"trunk_network\", self.trunk_network)\n        self.add_module(\"branch_network\", self.branch_network)\n\n        if decoder_network is not None:\n            self.decoder_network = self.to_wrap(\n                entity=decoder_network, device=self.device\n            )\n            self.add_module(\"decoder_network\", self.decoder_network)\n        else:\n            self.decoder_network = decoder_network\n\n        self.product_type = product_type\n        self.model_id = model_id\n        self.var_dim = var_dim\n\n        # Rescaling factors for the output\n        if rescale_factors is not None:\n            assert (\n                len(rescale_factors) == var_dim\n            ), \"The number of rescaling factors must be equal to var_dim.\"\n            rescale_factors = torch.from_numpy(rescale_factors.astype(\"float32\"))\n            self.rescale_factors = self.to_wrap(\n                entity=rescale_factors, device=self.device\n            )\n        else:\n            self.rescale_factors = None\n\n        # Checking up whether the output of each subnetwork are in correct shape\n        assert self._latent_dimension_is_correct(self.trunk_network.output_size), (\n            \"The trunk network must have\"\n            \" one-dimensional output , \"\n            \"but received\"\n            f\"{self.trunk_network.output_size}\"\n        )\n\n        assert self._latent_dimension_is_correct(self.branch_network.output_size), (\n            \"The branch network must have\"\n            \" one-dimensional output,\"\n            \" but received\"\n            f\"{self.branch_network.output_size}\"\n        )\n\n        # If bias is being used, check whether the network outputs are compatible.\n        if self.use_bias:\n            print(\"Bias is being used.\")\n            self._bias_compatibility_is_correct(\n                dim_trunk=self.trunk_network.output_size,\n                dim_branch=self.branch_network.output_size,\n            )\n            self.bias_wrapper = self._wrapper_bias_active\n        else:\n            self.bias_wrapper = self._wrapper_bias_inactive\n\n        # Using a decoder on top of the model or not\n        if self.decoder_network is not None:\n            self.decoder_wrapper = self._wrapper_decoder_active\n        else:\n            self.decoder_wrapper = self._wrapper_decoder_inactive\n\n        # Using rescaling factors or not\n        if rescale_factors is not None:\n            self.rescale_wrapper = self._wrapper_rescale_active\n        else:\n            self.rescale_wrapper = self._wrapper_rescale_inactive\n\n        # Checking the compatibility of the subnetworks outputs for each kind of product being employed.\n        if self.product_type != \"dense\":\n            output_branch = self.branch_network.output_size\n            output_trunk = self.trunk_network.output_size\n\n            # It checks if the inner product operation can be performed.\n            if not self.use_bias:\n                assert output_branch == output_trunk, (\n                    f\"The output dimensions for the sub-networks\"\n                    f\" trunk and branch must be equal but are\"\n                    f\" {output_branch}\"\n                    f\" and {output_trunk}\"\n                )\n            else:\n                print(\"Bias compatibility was already verified.\")\n        else:\n            output_branch = self.branch_network.output_size\n\n            assert not output_branch % self.var_dim, (\n                f\"The number of branch latent outputs must\"\n                f\" be divisible by the number of variables,\"\n                f\" but received {output_branch}\"\n                f\" and {self.var_dim}\"\n            )\n\n        self.subnetworks = [\n            net\n            for net in [self.trunk_network, self.branch_network, self.decoder_network]\n            if net is not None\n        ]\n\n        self.input_trunk = None\n        self.input_branch = None\n\n        self.output = None\n        self.var_map = dict()\n\n        # TODO Checking up if the input of the decoder network has the correct dimension\n        if self.decoder_network is not None:\n            print(\"Decoder is being used.\")\n        else:\n            pass\n\n        # Selecting the correct forward approach to be used\n        self._forward = self._forward_selector_()\n\n        self.subnetworks_names = [\"trunk\", \"branch\"]\n\n    def _latent_dimension_is_correct(self, dim: Union[int, tuple]) -&gt; bool:\n        \"\"\"It checks if the latent dimension is consistent.\n\n        Args:\n            dim (Union[int, tuple]): Latent_space_dimension.\n\n        Returns:\n            bool: The confirmation about the dimensionality correctness.\n\n        \"\"\"\n\n        if type(dim) == int:\n            return True\n        elif type(dim) == tuple:\n            if len(tuple) == 1:\n                return True\n            else:\n                return False\n\n    def _bias_compatibility_is_correct(\n        self, dim_trunk: Union[int, tuple], dim_branch: Union[int, tuple]\n    ) -&gt; bool:\n        assert dim_branch == dim_trunk + self.var_dim, (\n            \"When using bias, the dimension\"\n            + \"of the branch output should be\"\n            + \"trunk output + var_dim.\"\n        )\n\n    def _forward_dense(\n        self, output_trunk: torch.Tensor = None, output_branch: torch.Tensor = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward method used when the embeddings are multiplied using a matrix-like product, it means, the trunk\n        network outputs serve as \"interpolation basis\" for the branch outputs.\n\n        Args:\n            output_trunk (torch.Tensor, optional): The embedding generated by the trunk network. (Default value = None)\n            output_branch (torch.Tensor, optional): The embedding generated by the branch network. (Default value = None)\n\n        Returns:\n            torch.Tensor: The product between the two embeddings.\n\n        \"\"\"\n\n        latent_dim = int(output_branch.shape[-1] / self.var_dim)\n        output_branch_reshaped = torch.reshape(\n            output_branch, (-1, self.var_dim, latent_dim)\n        )\n\n        output = torch.matmul(output_branch_reshaped, output_trunk[..., None])\n        output = torch.squeeze(output)\n\n        return output\n\n    def _forward_pointwise(\n        self, output_trunk: torch.Tensor = None, output_branch: torch.Tensor = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward method used when the embeddings are multiplied using a simple point-wise product, after that a\n        reshaping is applied in order to produce multiple outputs.\n\n        Args:\n            output_trunk (torch.Tensor, optional): The embedding generated by the trunk network. (Default value = None)\n            output_branch (torch.Tensor, optional): The embedding generated by the branch network. (Default value = None)\n\n        Returns:\n            torch.Tensor: The product between the two embeddings.\n\n        \"\"\"\n\n        latent_dim = int(output_trunk.shape[-1] / self.var_dim)\n        output_trunk_reshaped = torch.reshape(\n            output_trunk, (-1, latent_dim, self.var_dim)\n        )\n        output_branch_reshaped = torch.reshape(\n            output_branch, (-1, latent_dim, self.var_dim)\n        )\n        output = torch.sum(\n            output_trunk_reshaped * output_branch_reshaped, dim=-2, keepdim=False\n        )\n\n        return output\n\n    def _forward_vanilla(\n        self, output_trunk: torch.Tensor = None, output_branch: torch.Tensor = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward method used when the embeddings are multiplied using a simple point-wise product.\n\n        Args:\n            output_trunk (torch.Tensor, optional): The embedding generated by the trunk network. (Default value = None)\n            output_branch (torch.Tensor, optional): The embedding generated by the branch network. (Default value = None)\n\n        Returns:\n            torch.Tensor: The product between the two embeddings.\n\n        \"\"\"\n\n        output = torch.sum(output_trunk * output_branch, dim=-1, keepdim=True)\n\n        return output\n\n    def _forward_selector_(self) -&gt; callable:\n        \"\"\"It selects the forward method to be used.\n\n\n        Returns:\n            callable : The callable corresponding to the required forward method.\n\n        \"\"\"\n\n        if self.var_dim &gt; 1:\n            # It operates as a typical dense layer\n            if self.product_type == \"dense\":\n                return self._forward_dense\n            # It executes an inner product by parts between the outputs\n            # of the subnetworks branch and trunk\n            else:\n                return self._forward_pointwise\n        else:\n            return self._forward_vanilla\n\n    @property\n    def _var_map(self) -&gt; dict:\n        # It checks all the data arrays in self.var_map have the same\n        # batches dimension\n        batches_dimensions = set([value.shape[0] for value in self.var_map.values()])\n\n        assert (\n            len(batches_dimensions) == 1\n        ), \"This dataset is not proper to apply shuffling\"\n\n        dim = list(batches_dimensions)[0]\n\n        indices = np.arange(dim)\n\n        np.random.shuffle(indices)\n\n        var_map_shuffled = {key: value[indices] for key, value in self.var_map.items()}\n\n        return var_map_shuffled\n\n    @property\n    def weights(self) -&gt; list:\n        return sum([net.weights for net in self.subnetworks], [])\n\n    # Now, a sequence of wrappers\n    def _wrapper_bias_inactive(\n        self,\n        output_trunk: Union[np.ndarray, torch.Tensor] = None,\n        output_branch: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        output = self._forward(output_trunk=output_trunk, output_branch=output_branch)\n\n        return output\n\n    def _wrapper_bias_active(\n        self,\n        output_trunk: Union[np.ndarray, torch.Tensor] = None,\n        output_branch: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        output_branch_ = output_branch[:, : -self.var_dim]\n        bias = output_branch[:, -self.var_dim :]\n\n        output = (\n            self._forward(output_trunk=output_trunk, output_branch=output_branch_)\n            + bias\n        )\n\n        return output\n\n    def _wrapper_decoder_active(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        return self.decoder_network.forward(input_data=input_data)\n\n    def _wrapper_decoder_inactive(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        return input_data\n\n    def _wrapper_rescale_active(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        return input_data * self.rescale_factors\n\n    def _wrapper_rescale_inactive(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        return input_data\n\n    def forward(\n        self,\n        input_trunk: Union[np.ndarray, torch.Tensor] = None,\n        input_branch: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"Wrapper forward method.\n\n        Args:\n            input_trunk (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n            input_branch (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n\n        Returns:\n            torch.Tensor: The result of all the hidden operations in the network.\n\n        \"\"\"\n\n        # Forward method execution\n        output_trunk = self.to_wrap(\n            entity=self.trunk_network.forward(input_trunk), device=self.device\n        )\n\n        output_branch = self.to_wrap(\n            entity=self.branch_network.forward(input_branch), device=self.device\n        )\n\n        # Wrappers are applied to execute user-defined operations.\n        # When those operations are not selected, these wrappers simply\n        # bypass the inputs.\n        output = self.bias_wrapper(\n            output_trunk=output_trunk, output_branch=output_branch\n        )\n\n        return self.rescale_wrapper(input_data=self.decoder_wrapper(input_data=output))\n\n    @guarantee_device\n    def eval(\n        self,\n        trunk_data: Union[np.ndarray, torch.Tensor] = None,\n        branch_data: Union[np.ndarray, torch.Tensor] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"It uses the network to make evaluations.\n\n        Args:\n            trunk_data (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n            branch_data (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n\n        Returns:\n            np.ndarray: The result of all the hidden operations in the network.\n\n        \"\"\"\n\n        output_tensor = self.forward(input_trunk=trunk_data, input_branch=branch_data)\n\n        return output_tensor.cpu().detach().numpy()\n\n    @guarantee_device\n    def eval_subnetwork(\n        self, name: str = None, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; np.ndarray:\n        \"\"\"It evaluates the output of DeepONet subnetworks.\n\n        Args:\n            name (str, optional): Name of the subnetwork. (Default value = None)\n            input_data (Union[np.ndarray, torch.Tensor], optional): The data used as input for the subnetwork. (Default value = None)\n\n        Returns:\n            np.ndarray: The evaluation performed by the subnetwork.\n\n        \"\"\"\n\n        assert (\n            name in self.subnetworks_names\n        ), f\"The name {name} is not a subnetwork of {self}.\"\n\n        network_to_be_used = getattr(self, name + \"_network\")\n\n        return network_to_be_used.forward(input_data).cpu().detach().numpy()\n\n    def summary(self) -&gt; None:\n        print(\"Trunk Network:\")\n        self.trunk_network.summary()\n        print(\"Branch Network:\")\n        self.branch_network.summary()\n</code></pre>"},{"location":"simulai_models/#simulai.models.DeepONet.__init__","title":"<code>__init__(trunk_network=None, branch_network=None, decoder_network=None, var_dim=1, devices='cpu', product_type=None, rescale_factors=None, model_id=None, use_bias=False)</code>","text":"<p>Classical Deep Operator Network (DeepONet), a deep learning version of the Universal Approximation Theorem.</p> <p>Parameters:</p> Name Type Description Default <code>trunk_network</code> <code>NetworkTemplate</code> <p>Subnetwork for processing the coordinates inputs. (Default value = None)</p> <code>None</code> <code>branch_network</code> <code>NetworkTemplate</code> <p>Subnetwork for processing the forcing/conditioning inputs. (Default value = None)</p> <code>None</code> <code>decoder_network</code> <code>NetworkTemplate</code> <p>Subnetworks for converting the embedding to the output (optional). (Default value = None)</p> <code>None</code> <code>devices</code> <code>Union[str, list]</code> <p>Devices in which the model will be executed. (Default value = \"cpu\")</p> <code>'cpu'</code> <code>product_type</code> <code>str</code> <p>Type of product to execute in the embedding space. (Default value = None)</p> <code>None</code> <code>rescale_factors</code> <code>ndarray</code> <p>Values used for rescaling the network outputs for a given order of magnitude. (Default value = None)</p> <code>None</code> <code>model_id</code> <code>str</code> <p>Name for the model (Default value = None)</p> <code>None</code> <code>use_bias</code> <code>bool</code> <p>(Default value = False)</p> <code>False</code> Source code in <code>simulai/models/_pytorch_models/_deeponet.py</code> <pre><code>def __init__(\n    self,\n    trunk_network: NetworkTemplate = None,\n    branch_network: NetworkTemplate = None,\n    decoder_network: NetworkTemplate = None,  # The decoder network is optional and considered\n    var_dim: int = 1,  # less effective than the output reshaping alternative\n    devices: Union[str, list] = \"cpu\",\n    product_type: str = None,\n    rescale_factors: np.ndarray = None,\n    model_id: str = None,\n    use_bias: bool = False,\n) -&gt; None:\n    \"\"\"Classical Deep Operator Network (DeepONet), a deep learning version\n    of the Universal Approximation Theorem.\n\n    Args:\n        trunk_network (NetworkTemplate, optional): Subnetwork for processing the coordinates inputs. (Default value = None)\n        branch_network (NetworkTemplate, optional): Subnetwork for processing the forcing/conditioning inputs. (Default value = None)\n        decoder_network (NetworkTemplate, optional): Subnetworks for converting the embedding to the output (optional). (Default value = None)\n        devices (Union[str, list], optional):  Devices in which the model will be executed. (Default value = \"cpu\")\n        product_type (str, optional): Type of product to execute in the embedding space. (Default value = None)\n        rescale_factors (np.ndarray, optional): Values used for rescaling the network outputs for a given order of magnitude. (Default value = None)\n        model_id (str, optional): Name for the model (Default value = None)\n        use_bias (bool, optional):  (Default value = False)\n\n    \"\"\"\n\n    super(DeepONet, self).__init__(devices=devices)\n\n    # Determining the kind of device to be used for allocating the\n    # subnetworks used in the DeepONet model\n    self.device = self._set_device(devices=devices)\n    self.use_bias = use_bias\n\n    self.trunk_network = self.to_wrap(entity=trunk_network, device=self.device)\n    self.branch_network = self.to_wrap(entity=branch_network, device=self.device)\n\n    self.add_module(\"trunk_network\", self.trunk_network)\n    self.add_module(\"branch_network\", self.branch_network)\n\n    if decoder_network is not None:\n        self.decoder_network = self.to_wrap(\n            entity=decoder_network, device=self.device\n        )\n        self.add_module(\"decoder_network\", self.decoder_network)\n    else:\n        self.decoder_network = decoder_network\n\n    self.product_type = product_type\n    self.model_id = model_id\n    self.var_dim = var_dim\n\n    # Rescaling factors for the output\n    if rescale_factors is not None:\n        assert (\n            len(rescale_factors) == var_dim\n        ), \"The number of rescaling factors must be equal to var_dim.\"\n        rescale_factors = torch.from_numpy(rescale_factors.astype(\"float32\"))\n        self.rescale_factors = self.to_wrap(\n            entity=rescale_factors, device=self.device\n        )\n    else:\n        self.rescale_factors = None\n\n    # Checking up whether the output of each subnetwork are in correct shape\n    assert self._latent_dimension_is_correct(self.trunk_network.output_size), (\n        \"The trunk network must have\"\n        \" one-dimensional output , \"\n        \"but received\"\n        f\"{self.trunk_network.output_size}\"\n    )\n\n    assert self._latent_dimension_is_correct(self.branch_network.output_size), (\n        \"The branch network must have\"\n        \" one-dimensional output,\"\n        \" but received\"\n        f\"{self.branch_network.output_size}\"\n    )\n\n    # If bias is being used, check whether the network outputs are compatible.\n    if self.use_bias:\n        print(\"Bias is being used.\")\n        self._bias_compatibility_is_correct(\n            dim_trunk=self.trunk_network.output_size,\n            dim_branch=self.branch_network.output_size,\n        )\n        self.bias_wrapper = self._wrapper_bias_active\n    else:\n        self.bias_wrapper = self._wrapper_bias_inactive\n\n    # Using a decoder on top of the model or not\n    if self.decoder_network is not None:\n        self.decoder_wrapper = self._wrapper_decoder_active\n    else:\n        self.decoder_wrapper = self._wrapper_decoder_inactive\n\n    # Using rescaling factors or not\n    if rescale_factors is not None:\n        self.rescale_wrapper = self._wrapper_rescale_active\n    else:\n        self.rescale_wrapper = self._wrapper_rescale_inactive\n\n    # Checking the compatibility of the subnetworks outputs for each kind of product being employed.\n    if self.product_type != \"dense\":\n        output_branch = self.branch_network.output_size\n        output_trunk = self.trunk_network.output_size\n\n        # It checks if the inner product operation can be performed.\n        if not self.use_bias:\n            assert output_branch == output_trunk, (\n                f\"The output dimensions for the sub-networks\"\n                f\" trunk and branch must be equal but are\"\n                f\" {output_branch}\"\n                f\" and {output_trunk}\"\n            )\n        else:\n            print(\"Bias compatibility was already verified.\")\n    else:\n        output_branch = self.branch_network.output_size\n\n        assert not output_branch % self.var_dim, (\n            f\"The number of branch latent outputs must\"\n            f\" be divisible by the number of variables,\"\n            f\" but received {output_branch}\"\n            f\" and {self.var_dim}\"\n        )\n\n    self.subnetworks = [\n        net\n        for net in [self.trunk_network, self.branch_network, self.decoder_network]\n        if net is not None\n    ]\n\n    self.input_trunk = None\n    self.input_branch = None\n\n    self.output = None\n    self.var_map = dict()\n\n    # TODO Checking up if the input of the decoder network has the correct dimension\n    if self.decoder_network is not None:\n        print(\"Decoder is being used.\")\n    else:\n        pass\n\n    # Selecting the correct forward approach to be used\n    self._forward = self._forward_selector_()\n\n    self.subnetworks_names = [\"trunk\", \"branch\"]\n</code></pre>"},{"location":"simulai_models/#simulai.models.DeepONet.eval","title":"<code>eval(trunk_data=None, branch_data=None)</code>","text":"<p>It uses the network to make evaluations.</p> <p>Parameters:</p> Name Type Description Default <code>trunk_data</code> <code>Union[ndarray, Tensor]</code> <p>(Default value = None)</p> <code>None</code> <code>branch_data</code> <code>Union[ndarray, Tensor]</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The result of all the hidden operations in the network.</p> Source code in <code>simulai/models/_pytorch_models/_deeponet.py</code> <pre><code>@guarantee_device\ndef eval(\n    self,\n    trunk_data: Union[np.ndarray, torch.Tensor] = None,\n    branch_data: Union[np.ndarray, torch.Tensor] = None,\n) -&gt; np.ndarray:\n    \"\"\"It uses the network to make evaluations.\n\n    Args:\n        trunk_data (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n        branch_data (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n\n    Returns:\n        np.ndarray: The result of all the hidden operations in the network.\n\n    \"\"\"\n\n    output_tensor = self.forward(input_trunk=trunk_data, input_branch=branch_data)\n\n    return output_tensor.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.DeepONet.eval_subnetwork","title":"<code>eval_subnetwork(name=None, input_data=None)</code>","text":"<p>It evaluates the output of DeepONet subnetworks.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the subnetwork. (Default value = None)</p> <code>None</code> <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The data used as input for the subnetwork. (Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The evaluation performed by the subnetwork.</p> Source code in <code>simulai/models/_pytorch_models/_deeponet.py</code> <pre><code>@guarantee_device\ndef eval_subnetwork(\n    self, name: str = None, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; np.ndarray:\n    \"\"\"It evaluates the output of DeepONet subnetworks.\n\n    Args:\n        name (str, optional): Name of the subnetwork. (Default value = None)\n        input_data (Union[np.ndarray, torch.Tensor], optional): The data used as input for the subnetwork. (Default value = None)\n\n    Returns:\n        np.ndarray: The evaluation performed by the subnetwork.\n\n    \"\"\"\n\n    assert (\n        name in self.subnetworks_names\n    ), f\"The name {name} is not a subnetwork of {self}.\"\n\n    network_to_be_used = getattr(self, name + \"_network\")\n\n    return network_to_be_used.forward(input_data).cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.DeepONet.forward","title":"<code>forward(input_trunk=None, input_branch=None)</code>","text":"<p>Wrapper forward method.</p> <p>Parameters:</p> Name Type Description Default <code>input_trunk</code> <code>Union[ndarray, Tensor]</code> <p>(Default value = None)</p> <code>None</code> <code>input_branch</code> <code>Union[ndarray, Tensor]</code> <p>(Default value = None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The result of all the hidden operations in the network.</p> Source code in <code>simulai/models/_pytorch_models/_deeponet.py</code> <pre><code>def forward(\n    self,\n    input_trunk: Union[np.ndarray, torch.Tensor] = None,\n    input_branch: Union[np.ndarray, torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Wrapper forward method.\n\n    Args:\n        input_trunk (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n        input_branch (Union[np.ndarray, torch.Tensor], optional):  (Default value = None)\n\n    Returns:\n        torch.Tensor: The result of all the hidden operations in the network.\n\n    \"\"\"\n\n    # Forward method execution\n    output_trunk = self.to_wrap(\n        entity=self.trunk_network.forward(input_trunk), device=self.device\n    )\n\n    output_branch = self.to_wrap(\n        entity=self.branch_network.forward(input_branch), device=self.device\n    )\n\n    # Wrappers are applied to execute user-defined operations.\n    # When those operations are not selected, these wrappers simply\n    # bypass the inputs.\n    output = self.bias_wrapper(\n        output_trunk=output_trunk, output_branch=output_branch\n    )\n\n    return self.rescale_wrapper(input_data=self.decoder_wrapper(input_data=output))\n</code></pre>"},{"location":"simulai_models/#autoencodermlp","title":"AutoencoderMLP","text":"<p>             Bases: <code>NetworkTemplate</code></p> <p>This is an implementation of a Fully-connected AutoEncoder as Reduced Order Model;</p> <p>A MLP autoencoder architecture consists of two stages:</p> <ul> <li>Fully-connected encoder</li> <li>Fully connected decoder</li> </ul> <p>Graphical scheme:</p> <pre><code>        |         |\n        |  |   |  |\nZ -&gt;    |  | | |  |  -&gt; Z_til\n        |  |   |  |\n        |         |\n</code></pre> <p>ENCODER       DECODER</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>class AutoencoderMLP(NetworkTemplate):\n    r\"\"\"This is an implementation of a Fully-connected AutoEncoder as\n    Reduced Order Model;\n\n    A MLP autoencoder architecture consists of two stages:\n\n    - Fully-connected encoder\n    - Fully connected decoder\n\n    Graphical scheme:\n\n                |         |\n                |  |   |  |\n        Z -&gt;    |  | | |  |  -&gt; Z_til\n                |  |   |  |\n                |         |\n\n    ENCODER       DECODER\n\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: DenseNetwork = None,\n        decoder: DenseNetwork = None,\n        input_dim: Optional[int] = None,\n        output_dim: Optional[int] = None,\n        latent_dim: Optional[int] = None,\n        activation: Optional[Union[list, str]] = None,\n        shallow: Optional[bool] = False,\n        devices: Union[str, list] = \"cpu\",\n        name: str = None,\n    ) -&gt; None:\n        \"\"\"Initialize the AutoencoderMLP network\n\n        Args:\n            encoder (DenseNetwork, optional): The encoder network architecture. (Default value = None)\n            decoder (DenseNetwork, optional): The decoder network architecture. (Default value = None)\n            input_dim (Optional[int], optional): The input dimensions of the data, by default None.\n            output_dim (Optional[int], optional): The output dimensions of the data, by default None.\n            latent_dim (Optional[int], optional): The dimensions of the latent space, by default None.\n            activation (Optional[Union[list, str]], optional): The activation functions used by the network, by default None.\n            shallow (Optional[bool], optional): Whether the network should be shallow or not, by default False.\n            devices (Union[str, list], optional): The device(s) to be used for allocating subnetworks, by default \"cpu\".\n            name (str, optional): The name of the network, by default None.\n\n        \"\"\"\n\n        super(AutoencoderMLP, self).__init__(name=name)\n\n        self.weights = list()\n\n        # This option is used when no network is provided\n        # and it uses default choices for the architectures\n        if encoder == None and decoder == None:\n            encoder, decoder = mlp_autoencoder_auto(\n                input_dim=input_dim,\n                latent_dim=latent_dim,\n                output_dim=output_dim,\n                activation=activation,\n                shallow=shallow,\n            )\n\n        # Determining the kind of device to be used for allocating the\n        # subnetworks used in the DeepONet model\n        self.device = self._set_device(devices=devices)\n\n        self.encoder = self.to_wrap(entity=encoder, device=self.device)\n        self.decoder = self.to_wrap(entity=decoder, device=self.device)\n\n        self.add_module(\"encoder\", self.encoder)\n        self.add_module(\"decoder\", self.decoder)\n\n        self.weights += self.encoder.weights\n        self.weights += self.decoder.weights\n\n        self.last_encoder_channels = None\n\n        self.shapes_dict = dict()\n\n    def summary(self) -&gt; None:\n        \"\"\"Prints the summary of the network architecture\"\"\"\n        self.encoder.summary()\n        self.decoder.summary()\n\n    def projection(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Project the input dataset into the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n        Returns:\n            torch.Tensor: The dataset projected over the latent space.\n\n        \"\"\"\n        latent = self.encoder.forward(input_data=input_data)\n\n        return latent\n\n    def reconstruction(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Reconstruct the latent dataset to the original one.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The dataset to be reconstructed, by default None.\n\n        Returns:\n            torch.Tensor: The dataset reconstructed.\n\n        \"\"\"\n        reconstructed = self.decoder.forward(input_data=input_data)\n\n        return reconstructed\n\n    def forward(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Execute the complete projection/reconstruction pipeline.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input dataset, by default None.\n\n        Returns:\n            torch.Tensor: The dataset reconstructed.\n\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n        reconstructed = self.reconstruction(input_data=latent)\n\n        return reconstructed\n\n    def eval_projection(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Evaluate the projection of the input dataset into the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n        Returns:\n            np.ndarray: The dataset projected over the latent space.\n\n        \"\"\"\n        return self.projection(input_data=input_data).detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.__init__","title":"<code>__init__(encoder=None, decoder=None, input_dim=None, output_dim=None, latent_dim=None, activation=None, shallow=False, devices='cpu', name=None)</code>","text":"<p>Initialize the AutoencoderMLP network</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>DenseNetwork</code> <p>The encoder network architecture. (Default value = None)</p> <code>None</code> <code>decoder</code> <code>DenseNetwork</code> <p>The decoder network architecture. (Default value = None)</p> <code>None</code> <code>input_dim</code> <code>Optional[int]</code> <p>The input dimensions of the data, by default None.</p> <code>None</code> <code>output_dim</code> <code>Optional[int]</code> <p>The output dimensions of the data, by default None.</p> <code>None</code> <code>latent_dim</code> <code>Optional[int]</code> <p>The dimensions of the latent space, by default None.</p> <code>None</code> <code>activation</code> <code>Optional[Union[list, str]]</code> <p>The activation functions used by the network, by default None.</p> <code>None</code> <code>shallow</code> <code>Optional[bool]</code> <p>Whether the network should be shallow or not, by default False.</p> <code>False</code> <code>devices</code> <code>Union[str, list]</code> <p>The device(s) to be used for allocating subnetworks, by default \"cpu\".</p> <code>'cpu'</code> <code>name</code> <code>str</code> <p>The name of the network, by default None.</p> <code>None</code> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def __init__(\n    self,\n    encoder: DenseNetwork = None,\n    decoder: DenseNetwork = None,\n    input_dim: Optional[int] = None,\n    output_dim: Optional[int] = None,\n    latent_dim: Optional[int] = None,\n    activation: Optional[Union[list, str]] = None,\n    shallow: Optional[bool] = False,\n    devices: Union[str, list] = \"cpu\",\n    name: str = None,\n) -&gt; None:\n    \"\"\"Initialize the AutoencoderMLP network\n\n    Args:\n        encoder (DenseNetwork, optional): The encoder network architecture. (Default value = None)\n        decoder (DenseNetwork, optional): The decoder network architecture. (Default value = None)\n        input_dim (Optional[int], optional): The input dimensions of the data, by default None.\n        output_dim (Optional[int], optional): The output dimensions of the data, by default None.\n        latent_dim (Optional[int], optional): The dimensions of the latent space, by default None.\n        activation (Optional[Union[list, str]], optional): The activation functions used by the network, by default None.\n        shallow (Optional[bool], optional): Whether the network should be shallow or not, by default False.\n        devices (Union[str, list], optional): The device(s) to be used for allocating subnetworks, by default \"cpu\".\n        name (str, optional): The name of the network, by default None.\n\n    \"\"\"\n\n    super(AutoencoderMLP, self).__init__(name=name)\n\n    self.weights = list()\n\n    # This option is used when no network is provided\n    # and it uses default choices for the architectures\n    if encoder == None and decoder == None:\n        encoder, decoder = mlp_autoencoder_auto(\n            input_dim=input_dim,\n            latent_dim=latent_dim,\n            output_dim=output_dim,\n            activation=activation,\n            shallow=shallow,\n        )\n\n    # Determining the kind of device to be used for allocating the\n    # subnetworks used in the DeepONet model\n    self.device = self._set_device(devices=devices)\n\n    self.encoder = self.to_wrap(entity=encoder, device=self.device)\n    self.decoder = self.to_wrap(entity=decoder, device=self.device)\n\n    self.add_module(\"encoder\", self.encoder)\n    self.add_module(\"decoder\", self.decoder)\n\n    self.weights += self.encoder.weights\n    self.weights += self.decoder.weights\n\n    self.last_encoder_channels = None\n\n    self.shapes_dict = dict()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.eval_projection","title":"<code>eval_projection(input_data=None)</code>","text":"<p>Evaluate the projection of the input dataset into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be projected, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def eval_projection(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; np.ndarray:\n    \"\"\"Evaluate the projection of the input dataset into the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n    Returns:\n        np.ndarray: The dataset projected over the latent space.\n\n    \"\"\"\n    return self.projection(input_data=input_data).detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Execute the complete projection/reconstruction pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input dataset, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The dataset reconstructed.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def forward(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"Execute the complete projection/reconstruction pipeline.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input dataset, by default None.\n\n    Returns:\n        torch.Tensor: The dataset reconstructed.\n\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n    reconstructed = self.reconstruction(input_data=latent)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.projection","title":"<code>projection(input_data=None)</code>","text":"<p>Project the input dataset into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be projected, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def projection(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"Project the input dataset into the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n    Returns:\n        torch.Tensor: The dataset projected over the latent space.\n\n    \"\"\"\n    latent = self.encoder.forward(input_data=input_data)\n\n    return latent\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.reconstruction","title":"<code>reconstruction(input_data=None)</code>","text":"<p>Reconstruct the latent dataset to the original one.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>The dataset to be reconstructed, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The dataset reconstructed.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruction(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"Reconstruct the latent dataset to the original one.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): The dataset to be reconstructed, by default None.\n\n    Returns:\n        torch.Tensor: The dataset reconstructed.\n\n    \"\"\"\n    reconstructed = self.decoder.forward(input_data=input_data)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderMLP.summary","title":"<code>summary()</code>","text":"<p>Prints the summary of the network architecture</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def summary(self) -&gt; None:\n    \"\"\"Prints the summary of the network architecture\"\"\"\n    self.encoder.summary()\n    self.decoder.summary()\n</code></pre>"},{"location":"simulai_models/#autoencodercnn","title":"AutoencoderCNN","text":"<p>             Bases: <code>NetworkTemplate</code></p> <p>This is an implementation of a convolutional autoencoder as Reduced Order Model. An autoencoder architecture consists of three stages:</p> <ul> <li>The convolutional encoder</li> <li>The bottleneck stage, subdivided in:<ul> <li>Fully-connected encoder</li> <li>Fully connected decoder</li> </ul> </li> <li>The convolutional decoder</li> </ul> <p>Graphical scheme</p> <pre><code>Z -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n\n\n                ENCODER               DENSE BOTTLENECK           DECODER\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>class AutoencoderCNN(NetworkTemplate):\n    r\"\"\"This is an implementation of a convolutional autoencoder as Reduced Order Model.\n    An autoencoder architecture consists of three stages:\n\n    - The convolutional encoder\n    - The bottleneck stage, subdivided in:\n        - Fully-connected encoder\n        - Fully connected decoder\n    - The convolutional decoder\n\n    Graphical scheme\n\n        Z -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n\n\n                        ENCODER               DENSE BOTTLENECK           DECODER\n\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: ConvolutionalNetwork = None,\n        bottleneck_encoder: Linear = None,\n        bottleneck_decoder: Linear = None,\n        decoder: ConvolutionalNetwork = None,\n        encoder_activation: str = \"relu\",\n        input_dim: Optional[Tuple[int, ...]] = None,\n        output_dim: Optional[Tuple[int, ...]] = None,\n        latent_dim: Optional[int] = None,\n        kernel_size: Optional[int] = None,\n        activation: Optional[Union[list, str]] = None,\n        channels: Optional[int] = None,\n        case: Optional[str] = None,\n        shallow: Optional[bool] = False,\n        devices: Union[str, list] = \"cpu\",\n        name: str = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Initialize the AutoencoderCNN network.\n\n        Args:\n            encoder (ConvolutionalNetwork, optional): The encoder network architecture, by default None.\n            bottleneck_encoder (Linear, optional): The bottleneck encoder network architecture, by default None.\n            bottleneck_decoder (Linear, optional): The bottleneck decoder network architecture, by default None.\n            decoder (ConvolutionalNetwork, optional): The decoder network architecture, by default None.\n            encoder_activation (str, optional): The activation function used by the encoder network, by default 'relu'.\n            input_dim (Optional[Tuple[int, ...]], optional): The input dimensions of the data, by default None.\n            output_dim (Optional[Tuple[int, ...]], optional): The output dimensions of the data, by default None.\n            latent_dim (Optional[int], optional): The dimensions of the latent space, by default None.\n            kernel_size (Optional[int], optional):  (Default value = None)\n            activation (Optional[Union[list, str]], optional): The activation functions used by the network, by default None.\n            channels (Optional[int], optional): The number of channels of the convolutional layers, by default None.\n            case (Optional[str], optional): The type of convolutional encoder and decoder to be used, by default None.\n            shallow (Optional[bool], optional): Whether the network should be shallow or not, by default False.\n            devices (Union[str, list], optional): The device(s) to be used for allocating subnetworks, by default 'cpu'.\n            name (str, optional): The name of the network, by default None.\n            **kwargs\n\n        \"\"\"\n\n        super(AutoencoderCNN, self).__init__(name=name)\n\n        self.weights = list()\n\n        # Determining the kind of device to be used for allocating the\n        # subnetworks\n        self.device = self._set_device(devices=devices)\n\n        self.input_dim = None\n\n        # If not network is provided, the automatic generation\n        # pipeline is activated.\n        if all(\n            [\n                isn == None\n                for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n            ]\n        ):\n            self.input_dim = input_dim\n\n            (\n                encoder,\n                decoder,\n                bottleneck_encoder,\n                bottleneck_decoder,\n            ) = cnn_autoencoder_auto(\n                input_dim=input_dim,\n                latent_dim=latent_dim,\n                output_dim=output_dim,\n                activation=activation,\n                kernel_size=kernel_size,\n                channels=channels,\n                case=case,\n                shallow=shallow,\n            )\n\n        self.encoder = self.to_wrap(entity=encoder, device=self.device)\n        self.bottleneck_encoder = self.to_wrap(\n            entity=bottleneck_encoder, device=self.device\n        )\n        self.bottleneck_decoder = self.to_wrap(\n            entity=bottleneck_decoder, device=self.device\n        )\n        self.decoder = self.to_wrap(entity=decoder, device=self.device)\n\n        self.add_module(\"encoder\", self.encoder)\n        self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n        self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n        self.add_module(\"decoder\", self.decoder)\n\n        self.weights += self.encoder.weights\n        self.weights += self.bottleneck_encoder.weights\n        self.weights += self.bottleneck_decoder.weights\n        self.weights += self.decoder.weights\n\n        self.last_encoder_channels = None\n        self.before_flatten_dimension = None\n\n        self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n        self.shapes_dict = dict()\n\n    def summary(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n        input_shape: list = None,\n        verbose: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Prints the summary of the network architecture.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input dataset. (Default value = None)\n            input_shape (list, optional): The shape of the input data. (Default value = None)\n            verbose (bool, optional):  (Default value = True)\n\n        Returns:\n            torch.Tensor: The dataset projected over the latent space.\n\n        \"\"\"\n\n        if verbose == True:\n            if self.input_dim != None:\n                input_shape = self.input_dim\n            else:\n                pass\n\n            self.encoder.summary(\n                input_data=input_data, input_shape=input_shape, device=self.device\n            )\n\n            if isinstance(input_data, np.ndarray):\n                btnk_input = self.encoder.forward(input_data=input_data)\n            else:\n                assert (\n                    input_shape\n                ), \"It is necessary to have input_shape when input_data is None.\"\n                input_shape = self.encoder.input_size\n                input_shape[0] = 1\n\n                input_data = self.to_wrap(\n                    entity=torch.ones(input_shape), device=self.device\n                )\n\n                btnk_input = self.encoder.forward(input_data=input_data)\n\n            before_flatten_dimension = tuple(btnk_input.shape[1:])\n            btnk_input = btnk_input.reshape((-1, np.prod(btnk_input.shape[1:])))\n\n            latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n            self.bottleneck_encoder.summary()\n            self.bottleneck_decoder.summary()\n\n            bottleneck_output = self.encoder_activation(\n                self.bottleneck_decoder.forward(input_data=latent)\n            )\n\n            bottleneck_output = bottleneck_output.reshape(\n                (-1, *before_flatten_dimension)\n            )\n\n            self.decoder.summary(input_data=bottleneck_output, device=self.device)\n\n            # Saving the content of the subnetworks to the overall architecture dictionary\n            self.shapes_dict.update({\"encoder\": self.encoder.shapes_dict})\n            self.shapes_dict.update(\n                {\"bottleneck_encoder\": self.bottleneck_encoder.shapes_dict}\n            )\n            self.shapes_dict.update(\n                {\"bottleneck_decoder\": self.bottleneck_decoder.shapes_dict}\n            )\n            self.shapes_dict.update({\"decoder\": self.decoder.shapes_dict})\n\n        else:\n            print(self)\n\n    @as_tensor\n    def projection(self, input_data: Union[np.ndarray, torch.Tensor]) -&gt; torch.Tensor:\n        \"\"\"Project input dataset into the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor]): The dataset to be projected.\n\n        Returns:\n            torch.Tensor: The dataset projected over the latent space.\n\n        \"\"\"\n\n        btnk_input = self.encoder.forward(input_data=input_data)\n\n        self.before_flatten_dimension = tuple(btnk_input.shape[1:])\n\n        btnk_input = btnk_input.reshape((-1, np.prod(self.before_flatten_dimension)))\n\n        latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n        return latent\n\n    @as_tensor\n    def reconstruction(\n        self, input_data: Union[torch.Tensor, np.ndarray]\n    ) -&gt; torch.Tensor:\n        \"\"\"Reconstruct the latent dataset to the original one.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray]): The dataset to be reconstructed.\n\n        Returns:\n            torch.Tensor: The reconstructed dataset.\n\n        \"\"\"\n\n        bottleneck_output = self.encoder_activation(\n            self.bottleneck_decoder.forward(input_data=input_data)\n        )\n\n        bottleneck_output = bottleneck_output.reshape(\n            (-1,) + self.before_flatten_dimension\n        )\n\n        reconstructed = self.decoder.forward(input_data=bottleneck_output)\n\n        return reconstructed\n\n    def forward(self, input_data: Union[np.ndarray, torch.Tensor]) -&gt; torch.Tensor:\n        \"\"\"Execute the complete projection/reconstruction pipeline.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor]): The input dataset.\n\n        Returns:\n            torch.Tensor: The reconstructed dataset.\n\n        \"\"\"\n\n        latent = self.projection(input_data=input_data)\n        reconstructed = self.reconstruction(input_data=latent)\n\n        return reconstructed\n\n    def eval(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n        \"\"\"Evaluate the autoencoder on the given dataset.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be evaluated, by default None.\n\n        Returns:\n            np.ndarray: The dataset projected over the latent space.\n\n        \"\"\"\n\n        if isinstance(input_data, np.ndarray):\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        input_data = input_data.to(self.device)\n\n        return super().eval(input_data=input_data)\n\n    def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n        \"\"\"Project the input dataset into the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n        Returns:\n            np.ndarray: The dataset projected over the latent space.\n\n        \"\"\"\n\n        projected_data = self.projection(input_data=input_data)\n\n        return projected_data.cpu().detach().numpy()\n\n    def reconstruct(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Reconstructs the latent dataset to the original one.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be reconstructed. If not provided, uses the original input data, by default None.\n\n        Returns:\n            np.ndarray: The reconstructed dataset.\n\n        \"\"\"\n        reconstructed_data = self.reconstruction(input_data=input_data)\n        return reconstructed_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.__init__","title":"<code>__init__(encoder=None, bottleneck_encoder=None, bottleneck_decoder=None, decoder=None, encoder_activation='relu', input_dim=None, output_dim=None, latent_dim=None, kernel_size=None, activation=None, channels=None, case=None, shallow=False, devices='cpu', name=None, **kwargs)</code>","text":"<p>Initialize the AutoencoderCNN network.</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>ConvolutionalNetwork</code> <p>The encoder network architecture, by default None.</p> <code>None</code> <code>bottleneck_encoder</code> <code>Linear</code> <p>The bottleneck encoder network architecture, by default None.</p> <code>None</code> <code>bottleneck_decoder</code> <code>Linear</code> <p>The bottleneck decoder network architecture, by default None.</p> <code>None</code> <code>decoder</code> <code>ConvolutionalNetwork</code> <p>The decoder network architecture, by default None.</p> <code>None</code> <code>encoder_activation</code> <code>str</code> <p>The activation function used by the encoder network, by default 'relu'.</p> <code>'relu'</code> <code>input_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The input dimensions of the data, by default None.</p> <code>None</code> <code>output_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The output dimensions of the data, by default None.</p> <code>None</code> <code>latent_dim</code> <code>Optional[int]</code> <p>The dimensions of the latent space, by default None.</p> <code>None</code> <code>kernel_size</code> <code>Optional[int]</code> <p>(Default value = None)</p> <code>None</code> <code>activation</code> <code>Optional[Union[list, str]]</code> <p>The activation functions used by the network, by default None.</p> <code>None</code> <code>channels</code> <code>Optional[int]</code> <p>The number of channels of the convolutional layers, by default None.</p> <code>None</code> <code>case</code> <code>Optional[str]</code> <p>The type of convolutional encoder and decoder to be used, by default None.</p> <code>None</code> <code>shallow</code> <code>Optional[bool]</code> <p>Whether the network should be shallow or not, by default False.</p> <code>False</code> <code>devices</code> <code>Union[str, list]</code> <p>The device(s) to be used for allocating subnetworks, by default 'cpu'.</p> <code>'cpu'</code> <code>name</code> <code>str</code> <p>The name of the network, by default None.</p> <code>None</code> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def __init__(\n    self,\n    encoder: ConvolutionalNetwork = None,\n    bottleneck_encoder: Linear = None,\n    bottleneck_decoder: Linear = None,\n    decoder: ConvolutionalNetwork = None,\n    encoder_activation: str = \"relu\",\n    input_dim: Optional[Tuple[int, ...]] = None,\n    output_dim: Optional[Tuple[int, ...]] = None,\n    latent_dim: Optional[int] = None,\n    kernel_size: Optional[int] = None,\n    activation: Optional[Union[list, str]] = None,\n    channels: Optional[int] = None,\n    case: Optional[str] = None,\n    shallow: Optional[bool] = False,\n    devices: Union[str, list] = \"cpu\",\n    name: str = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Initialize the AutoencoderCNN network.\n\n    Args:\n        encoder (ConvolutionalNetwork, optional): The encoder network architecture, by default None.\n        bottleneck_encoder (Linear, optional): The bottleneck encoder network architecture, by default None.\n        bottleneck_decoder (Linear, optional): The bottleneck decoder network architecture, by default None.\n        decoder (ConvolutionalNetwork, optional): The decoder network architecture, by default None.\n        encoder_activation (str, optional): The activation function used by the encoder network, by default 'relu'.\n        input_dim (Optional[Tuple[int, ...]], optional): The input dimensions of the data, by default None.\n        output_dim (Optional[Tuple[int, ...]], optional): The output dimensions of the data, by default None.\n        latent_dim (Optional[int], optional): The dimensions of the latent space, by default None.\n        kernel_size (Optional[int], optional):  (Default value = None)\n        activation (Optional[Union[list, str]], optional): The activation functions used by the network, by default None.\n        channels (Optional[int], optional): The number of channels of the convolutional layers, by default None.\n        case (Optional[str], optional): The type of convolutional encoder and decoder to be used, by default None.\n        shallow (Optional[bool], optional): Whether the network should be shallow or not, by default False.\n        devices (Union[str, list], optional): The device(s) to be used for allocating subnetworks, by default 'cpu'.\n        name (str, optional): The name of the network, by default None.\n        **kwargs\n\n    \"\"\"\n\n    super(AutoencoderCNN, self).__init__(name=name)\n\n    self.weights = list()\n\n    # Determining the kind of device to be used for allocating the\n    # subnetworks\n    self.device = self._set_device(devices=devices)\n\n    self.input_dim = None\n\n    # If not network is provided, the automatic generation\n    # pipeline is activated.\n    if all(\n        [\n            isn == None\n            for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n        ]\n    ):\n        self.input_dim = input_dim\n\n        (\n            encoder,\n            decoder,\n            bottleneck_encoder,\n            bottleneck_decoder,\n        ) = cnn_autoencoder_auto(\n            input_dim=input_dim,\n            latent_dim=latent_dim,\n            output_dim=output_dim,\n            activation=activation,\n            kernel_size=kernel_size,\n            channels=channels,\n            case=case,\n            shallow=shallow,\n        )\n\n    self.encoder = self.to_wrap(entity=encoder, device=self.device)\n    self.bottleneck_encoder = self.to_wrap(\n        entity=bottleneck_encoder, device=self.device\n    )\n    self.bottleneck_decoder = self.to_wrap(\n        entity=bottleneck_decoder, device=self.device\n    )\n    self.decoder = self.to_wrap(entity=decoder, device=self.device)\n\n    self.add_module(\"encoder\", self.encoder)\n    self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n    self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n    self.add_module(\"decoder\", self.decoder)\n\n    self.weights += self.encoder.weights\n    self.weights += self.bottleneck_encoder.weights\n    self.weights += self.bottleneck_decoder.weights\n    self.weights += self.decoder.weights\n\n    self.last_encoder_channels = None\n    self.before_flatten_dimension = None\n\n    self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n    self.shapes_dict = dict()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.eval","title":"<code>eval(input_data=None)</code>","text":"<p>Evaluate the autoencoder on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be evaluated, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def eval(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n    \"\"\"Evaluate the autoencoder on the given dataset.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be evaluated, by default None.\n\n    Returns:\n        np.ndarray: The dataset projected over the latent space.\n\n    \"\"\"\n\n    if isinstance(input_data, np.ndarray):\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n    input_data = input_data.to(self.device)\n\n    return super().eval(input_data=input_data)\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.forward","title":"<code>forward(input_data)</code>","text":"<p>Execute the complete projection/reconstruction pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input dataset.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed dataset.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def forward(self, input_data: Union[np.ndarray, torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Execute the complete projection/reconstruction pipeline.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor]): The input dataset.\n\n    Returns:\n        torch.Tensor: The reconstructed dataset.\n\n    \"\"\"\n\n    latent = self.projection(input_data=input_data)\n    reconstructed = self.reconstruction(input_data=latent)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.project","title":"<code>project(input_data=None)</code>","text":"<p>Project the input dataset into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be projected, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n    \"\"\"Project the input dataset into the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be projected, by default None.\n\n    Returns:\n        np.ndarray: The dataset projected over the latent space.\n\n    \"\"\"\n\n    projected_data = self.projection(input_data=input_data)\n\n    return projected_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.projection","title":"<code>projection(input_data)</code>","text":"<p>Project input dataset into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be projected.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>@as_tensor\ndef projection(self, input_data: Union[np.ndarray, torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Project input dataset into the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor]): The dataset to be projected.\n\n    Returns:\n        torch.Tensor: The dataset projected over the latent space.\n\n    \"\"\"\n\n    btnk_input = self.encoder.forward(input_data=input_data)\n\n    self.before_flatten_dimension = tuple(btnk_input.shape[1:])\n\n    btnk_input = btnk_input.reshape((-1, np.prod(self.before_flatten_dimension)))\n\n    latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n    return latent\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.reconstruct","title":"<code>reconstruct(input_data=None)</code>","text":"<p>Reconstructs the latent dataset to the original one.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The dataset to be reconstructed. If not provided, uses the original input data, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The reconstructed dataset.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruct(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; np.ndarray:\n    \"\"\"Reconstructs the latent dataset to the original one.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The dataset to be reconstructed. If not provided, uses the original input data, by default None.\n\n    Returns:\n        np.ndarray: The reconstructed dataset.\n\n    \"\"\"\n    reconstructed_data = self.reconstruction(input_data=input_data)\n    return reconstructed_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.reconstruction","title":"<code>reconstruction(input_data)</code>","text":"<p>Reconstruct the latent dataset to the original one.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>The dataset to be reconstructed.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed dataset.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>@as_tensor\ndef reconstruction(\n    self, input_data: Union[torch.Tensor, np.ndarray]\n) -&gt; torch.Tensor:\n    \"\"\"Reconstruct the latent dataset to the original one.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray]): The dataset to be reconstructed.\n\n    Returns:\n        torch.Tensor: The reconstructed dataset.\n\n    \"\"\"\n\n    bottleneck_output = self.encoder_activation(\n        self.bottleneck_decoder.forward(input_data=input_data)\n    )\n\n    bottleneck_output = bottleneck_output.reshape(\n        (-1,) + self.before_flatten_dimension\n    )\n\n    reconstructed = self.decoder.forward(input_data=bottleneck_output)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderCNN.summary","title":"<code>summary(input_data=None, input_shape=None, verbose=True)</code>","text":"<p>Prints the summary of the network architecture.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input dataset. (Default value = None)</p> <code>None</code> <code>input_shape</code> <code>list</code> <p>The shape of the input data. (Default value = None)</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>(Default value = True)</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The dataset projected over the latent space.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def summary(\n    self,\n    input_data: Union[np.ndarray, torch.Tensor] = None,\n    input_shape: list = None,\n    verbose: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Prints the summary of the network architecture.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input dataset. (Default value = None)\n        input_shape (list, optional): The shape of the input data. (Default value = None)\n        verbose (bool, optional):  (Default value = True)\n\n    Returns:\n        torch.Tensor: The dataset projected over the latent space.\n\n    \"\"\"\n\n    if verbose == True:\n        if self.input_dim != None:\n            input_shape = self.input_dim\n        else:\n            pass\n\n        self.encoder.summary(\n            input_data=input_data, input_shape=input_shape, device=self.device\n        )\n\n        if isinstance(input_data, np.ndarray):\n            btnk_input = self.encoder.forward(input_data=input_data)\n        else:\n            assert (\n                input_shape\n            ), \"It is necessary to have input_shape when input_data is None.\"\n            input_shape = self.encoder.input_size\n            input_shape[0] = 1\n\n            input_data = self.to_wrap(\n                entity=torch.ones(input_shape), device=self.device\n            )\n\n            btnk_input = self.encoder.forward(input_data=input_data)\n\n        before_flatten_dimension = tuple(btnk_input.shape[1:])\n        btnk_input = btnk_input.reshape((-1, np.prod(btnk_input.shape[1:])))\n\n        latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n        self.bottleneck_encoder.summary()\n        self.bottleneck_decoder.summary()\n\n        bottleneck_output = self.encoder_activation(\n            self.bottleneck_decoder.forward(input_data=latent)\n        )\n\n        bottleneck_output = bottleneck_output.reshape(\n            (-1, *before_flatten_dimension)\n        )\n\n        self.decoder.summary(input_data=bottleneck_output, device=self.device)\n\n        # Saving the content of the subnetworks to the overall architecture dictionary\n        self.shapes_dict.update({\"encoder\": self.encoder.shapes_dict})\n        self.shapes_dict.update(\n            {\"bottleneck_encoder\": self.bottleneck_encoder.shapes_dict}\n        )\n        self.shapes_dict.update(\n            {\"bottleneck_decoder\": self.bottleneck_decoder.shapes_dict}\n        )\n        self.shapes_dict.update({\"decoder\": self.decoder.shapes_dict})\n\n    else:\n        print(self)\n</code></pre>"},{"location":"simulai_models/#autoencoderkoopman","title":"AutoencoderKoopman","text":"<p>             Bases: <code>NetworkTemplate</code></p> <p>This is an implementation of a Koopman autoencoder as a Reduced Order Model.</p> <p>A Koopman autoencoder architecture consists of five stages:</p> <ul> <li>The convolutional encoder [Optional]</li> <li>Fully-connected encoder</li> <li>Koopman operator</li> <li>Fully connected decoder</li> <li>The convolutional decoder [Optional]</li> </ul> <p>Graphical scheme</p> <pre><code>                                        (Koopman OPERATOR)\n                                                 ^\n                                          |      |      |\n                                          |  |   |   |  |\n   Z -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | - | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n                                          |  |       |  |\n                                          |             |\n\n                        ENCODER          DENSE BOTTLENECK        DECODER\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>class AutoencoderKoopman(NetworkTemplate):\n    r\"\"\"This is an implementation of a Koopman autoencoder as a Reduced Order Model.\n\n    A Koopman autoencoder architecture consists of five stages:\n\n    - The convolutional encoder [Optional]\n    - Fully-connected encoder\n    - Koopman operator\n    - Fully connected decoder\n    - The convolutional decoder [Optional]\n\n    Graphical scheme\n\n                                                (Koopman OPERATOR)\n                                                         ^\n                                                  |      |      |\n                                                  |  |   |   |  |\n           Z -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | - | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n                                                  |  |       |  |\n                                                  |             |\n\n                                ENCODER          DENSE BOTTLENECK        DECODER\n\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n        bottleneck_encoder: Optional[Union[Linear, DenseNetwork]] = None,\n        bottleneck_decoder: Optional[Union[Linear, DenseNetwork]] = None,\n        decoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n        input_dim: Optional[Tuple[int, ...]] = None,\n        output_dim: Optional[Tuple[int, ...]] = None,\n        latent_dim: Optional[int] = None,\n        activation: Optional[Union[list, str]] = None,\n        channels: Optional[int] = None,\n        case: Optional[str] = None,\n        architecture: Optional[str] = None,\n        shallow: Optional[bool] = False,\n        use_batch_norm: Optional[bool] = False,\n        encoder_activation: str = \"relu\",\n        devices: Union[str, list] = \"cpu\",\n        name: str = None,\n    ) -&gt; None:\n        \"\"\"Constructs a new instance of the Autoencoder\n\n        Args:\n            encoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The encoder network. Defaults to None.\n            bottleneck_encoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck encoder network. Defaults to None.\n            bottleneck_decoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck decoder network. Defaults to None.\n            decoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The decoder network. Defaults to None.\n            input_dim (Optional[Tuple[int, ...]], optional): The input dimensions. Used for automatic network generation. Defaults to None.\n            output_dim (Optional[Tuple[int, ...]], optional): The output dimensions. Used for automatic network generation. Defaults to None.\n            latent_dim (Optional[int], optional): The latent dimensions. Used for automatic network generation. Defaults to None.\n            activation (Optional[Union[list, str]], optional): The activation functions for each layer. Used for automatic network generation. Defaults to None.\n            channels (Optional[int], optional): The number of channels. Used for automatic network generation. Defaults to None.\n            case (Optional[str], optional): The type of problem. Used for automatic network generation. Defaults to None.\n            architecture (Optional[str], optional): The network architecture. Used for automatic network generation. Defaults to None.\n            shallow (Optional[bool], optional): Whether to use shallow or deep network. Used for automatic network generation. Defaults to False.\n            use_batch_norm (Optional[bool], optional):  (Default value = False)\n            encoder_activation (str, optional): The activation function for the encoder. Defaults to \"relu\".\n            devices (Union[str, list], optional): The devices to use. Defaults to \"cpu\".\n            name (str, optional): The name of the autoencoder. Defaults to None.\n\n        \"\"\"\n        super(AutoencoderKoopman, self).__init__(name=name)\n\n        self.weights = list()\n\n        # Determining the kind of device to be used for allocating the\n        # subnetworks\n        self.device = self._set_device(devices=devices)\n\n        self.input_dim = None\n\n        # If not network is provided, the automatic generation\n        # pipeline is activated.\n        if all(\n            [\n                isn == None\n                for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n            ]\n        ):\n            self.input_dim = input_dim\n\n            encoder, decoder, bottleneck_encoder, bottleneck_decoder = autoencoder_auto(\n                input_dim=input_dim,\n                latent_dim=latent_dim,\n                output_dim=output_dim,\n                activation=activation,\n                channels=channels,\n                architecture=architecture,\n                case=case,\n                shallow=shallow,\n                use_batch_norm=use_batch_norm,\n            )\n\n        self.encoder = encoder.to(self.device)\n        self.decoder = decoder.to(self.device)\n\n        self.add_module(\"encoder\", self.encoder)\n        self.add_module(\"decoder\", self.decoder)\n\n        self.weights += self.encoder.weights\n        self.weights += self.decoder.weights\n\n        # These subnetworks are optional\n        if bottleneck_encoder is not None and bottleneck_decoder is not None:\n            self.bottleneck_encoder = self.to_wrap(\n                entity=bottleneck_encoder, device=self.device\n            )\n            self.bottleneck_decoder = self.to_wrap(\n                entity=bottleneck_decoder, device=self.device\n            )\n\n            self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n            self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n            self.weights += self.bottleneck_encoder.weights\n            self.weights += self.bottleneck_decoder.weights\n\n        # These subnetworks are optional\n        if bottleneck_encoder is not None and bottleneck_decoder is not None:\n            self.bottleneck_encoder = self.to_wrap(\n                entity=bottleneck_encoder, device=self.device\n            )\n            self.bottleneck_decoder = self.to_wrap(\n                entity=bottleneck_decoder, device=self.device\n            )\n\n            self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n            self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n            self.weights += self.bottleneck_encoder.weights\n            self.weights += self.bottleneck_decoder.weights\n\n        if bottleneck_encoder is not None and bottleneck_decoder is not None:\n            self.projection = self._projection_with_bottleneck\n            self.reconstruction = self._reconstruction_with_bottleneck\n        else:\n            self.projection = self._projection\n            self.reconstruction = self._reconstruction\n\n        self.last_encoder_channels = None\n        self.before_flatten_dimension = None\n\n        self.latent_dimension = None\n\n        if bottleneck_encoder is not None:\n            self.latent_dimension = bottleneck_encoder.output_size\n        else:\n            self.latent_dimension = self.encoder.output_size\n\n        self.K_op = self.to_wrap(\n            entity=torch.nn.Linear(\n                self.latent_dimension, self.latent_dimension, bias=False\n            ).weight,\n            device=self.device,\n        )\n\n        self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n        self.shapes_dict = dict()\n\n    def summary(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n        input_shape: list = None,\n        verbose: bool = True,\n    ) -&gt; torch.Tensor:\n        if verbose == True:\n            if self.input_dim != None:\n                input_shape = list(self.input_dim)\n            else:\n                pass\n\n            self.encoder.summary(\n                input_data=input_data, input_shape=input_shape, device=self.device\n            )\n\n            self.before_flatten_dimension = tuple(self.encoder.output_size[1:])\n\n            if isinstance(input_data, np.ndarray):\n                btnk_input = self.encoder.forward(input_data=input_data)\n            else:\n                assert (\n                    input_shape\n                ), \"It is necessary to have input_shape when input_data is None.\"\n                input_shape = self.encoder.input_size\n                input_shape[0] = 1\n\n                input_data = self.to_wrap(\n                    entity=torch.ones(input_shape), device=self.device\n                )\n\n                btnk_input = self.encoder.forward(input_data=input_data)\n\n            before_flatten_dimension = tuple(btnk_input.shape[1:])\n            btnk_input = btnk_input.reshape((-1, np.prod(btnk_input.shape[1:])))\n\n            latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n            self.bottleneck_encoder.summary()\n\n            print(f\"The Koopman Operator has shape: {self.K_op.shape} \")\n\n            self.bottleneck_decoder.summary()\n\n            bottleneck_output = self.encoder_activation(\n                self.bottleneck_decoder.forward(input_data=latent)\n            )\n\n            bottleneck_output = bottleneck_output.reshape(\n                (-1, *before_flatten_dimension)\n            )\n\n            self.decoder.summary(input_data=bottleneck_output, device=self.device)\n\n            # Saving the content of the subnetworks to the overall architecture dictionary\n            self.shapes_dict.update({\"encoder\": self.encoder.shapes_dict})\n            self.shapes_dict.update(\n                {\"bottleneck_encoder\": self.bottleneck_encoder.shapes_dict}\n            )\n            self.shapes_dict.update(\n                {\"bottleneck_decoder\": self.bottleneck_decoder.shapes_dict}\n            )\n            self.shapes_dict.update({\"decoder\": self.decoder.shapes_dict})\n\n        else:\n            print(self)\n\n    @as_tensor\n    def _projection_with_bottleneck(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Computes the projection of the input data onto the bottleneck encoder.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The projected latent representation.\n\n        \"\"\"\n        btnk_input = self.encoder.forward(input_data=input_data)\n\n        self.before_flatten_dimension = tuple(btnk_input.shape[1:])\n\n        btnk_input = btnk_input.reshape((-1, np.prod(self.before_flatten_dimension)))\n\n        latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n        return latent\n\n    @as_tensor\n    def _projection(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Computes the projection of the input data onto the encoder.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The projected latent representation.\n\n        \"\"\"\n        latent = self.encoder.forward(input_data=input_data)\n\n        return latent\n\n    @as_tensor\n    def _reconstruction_with_bottleneck(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Reconstructs the input data using the bottleneck decoder.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The reconstructed data.\n\n        \"\"\"\n        bottleneck_output = self.encoder_activation(\n            self.bottleneck_decoder.forward(input_data=input_data)\n        )\n\n        bottleneck_output = bottleneck_output.reshape(\n            (-1,) + self.before_flatten_dimension\n        )\n\n        reconstructed = self.decoder.forward(input_data=bottleneck_output)\n\n        return reconstructed\n\n    @as_tensor\n    def _reconstruction(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Reconstructs the input data using the decoder.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The reconstructed data.\n\n        \"\"\"\n        reconstructed = self.decoder.forward(input_data=input_data)\n\n        return reconstructed\n\n    def latent_forward_m(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None, m: int = 1\n    ) -&gt; torch.Tensor:\n        \"\"\"Evaluates the operation $u^{u+m} = K^m u^{i}$\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n            m (int, optional): The number of Koopman iterations. Defaults to 1.\n\n        Returns:\n            torch.Tensor: The computed latent representation.\n\n        \"\"\"\n        return torch.matmul(input_data, torch.pow(self.K_op.T, m))\n\n    def latent_forward(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Evaluates the operation u^{u+1} = K u^{i}\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The computed latent representation.\n\n        \"\"\"\n        return torch.matmul(input_data, self.K_op.T)\n\n    def reconstruction_forward(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Evaluates the operation \u0168 = D(E(U))\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            torch.Tensor: The reconstructed data.\n\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n        reconstructed = self.reconstruction(input_data=latent)\n\n        return reconstructed\n\n    def reconstruction_forward_m(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None, m: int = 1\n    ) -&gt; torch.Tensor:\n        \"\"\"Evaluates the operation \u0168_m = D(K^m E(U))\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n            m (int, optional): The number of Koopman iterations. Defaults to 1.\n\n        Returns:\n            torch.Tensor: The reconstructed data.\n\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n        latent_m = self.latent_forward_m(input_data=latent, m=m)\n        reconstructed_m = self.reconstruction(input_data=latent_m)\n\n        return reconstructed_m\n\n    def predict(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None, n_steps: int = 1\n    ) -&gt; np.ndarray:\n        \"\"\"Predicts the reconstructed data for the input data after n_steps extrapolation in the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n            n_steps (int, optional): The number of extrapolations to perform. Defaults to 1.\n\n        Returns:\n            np.ndarray: The predicted reconstructed data.\n\n        \"\"\"\n        if isinstance(input_data, np.ndarray):\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        predictions = list()\n        latent = self.projection(input_data=input_data)\n        init_latent = latent\n\n        # Extrapolating in the latent space over n_steps steps\n        for s in range(n_steps):\n            latent_s = self.latent_forward(input_data=init_latent)\n            init_latent = latent_s\n            predictions.append(latent_s)\n\n        predictions = torch.vstack(predictions)\n\n        reconstructed_predictions = self.reconstruction(input_data=predictions)\n\n        return reconstructed_predictions.detach().numpy()\n\n    def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n        \"\"\"Projects the input data into the latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            np.ndarray: The projected data.\n\n        \"\"\"\n        projected_data = self.projection(input_data=input_data)\n\n        return projected_data.cpu().detach().numpy()\n\n    def reconstruct(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Reconstructs the input data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n        Returns:\n            np.ndarray: The reconstructed data.\n\n        \"\"\"\n        reconstructed_data = self.reconstruction(input_data=input_data)\n\n        return reconstructed_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.__init__","title":"<code>__init__(encoder=None, bottleneck_encoder=None, bottleneck_decoder=None, decoder=None, input_dim=None, output_dim=None, latent_dim=None, activation=None, channels=None, case=None, architecture=None, shallow=False, use_batch_norm=False, encoder_activation='relu', devices='cpu', name=None)</code>","text":"<p>Constructs a new instance of the Autoencoder</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>Union[ConvolutionalNetwork, DenseNetwork]</code> <p>The encoder network. Defaults to None.</p> <code>None</code> <code>bottleneck_encoder</code> <code>Optional[Union[Linear, DenseNetwork]]</code> <p>The bottleneck encoder network. Defaults to None.</p> <code>None</code> <code>bottleneck_decoder</code> <code>Optional[Union[Linear, DenseNetwork]]</code> <p>The bottleneck decoder network. Defaults to None.</p> <code>None</code> <code>decoder</code> <code>Union[ConvolutionalNetwork, DenseNetwork]</code> <p>The decoder network. Defaults to None.</p> <code>None</code> <code>input_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The input dimensions. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>output_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The output dimensions. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>latent_dim</code> <code>Optional[int]</code> <p>The latent dimensions. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>activation</code> <code>Optional[Union[list, str]]</code> <p>The activation functions for each layer. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>channels</code> <code>Optional[int]</code> <p>The number of channels. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>case</code> <code>Optional[str]</code> <p>The type of problem. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>architecture</code> <code>Optional[str]</code> <p>The network architecture. Used for automatic network generation. Defaults to None.</p> <code>None</code> <code>shallow</code> <code>Optional[bool]</code> <p>Whether to use shallow or deep network. Used for automatic network generation. Defaults to False.</p> <code>False</code> <code>use_batch_norm</code> <code>Optional[bool]</code> <p>(Default value = False)</p> <code>False</code> <code>encoder_activation</code> <code>str</code> <p>The activation function for the encoder. Defaults to \"relu\".</p> <code>'relu'</code> <code>devices</code> <code>Union[str, list]</code> <p>The devices to use. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>name</code> <code>str</code> <p>The name of the autoencoder. Defaults to None.</p> <code>None</code> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def __init__(\n    self,\n    encoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n    bottleneck_encoder: Optional[Union[Linear, DenseNetwork]] = None,\n    bottleneck_decoder: Optional[Union[Linear, DenseNetwork]] = None,\n    decoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n    input_dim: Optional[Tuple[int, ...]] = None,\n    output_dim: Optional[Tuple[int, ...]] = None,\n    latent_dim: Optional[int] = None,\n    activation: Optional[Union[list, str]] = None,\n    channels: Optional[int] = None,\n    case: Optional[str] = None,\n    architecture: Optional[str] = None,\n    shallow: Optional[bool] = False,\n    use_batch_norm: Optional[bool] = False,\n    encoder_activation: str = \"relu\",\n    devices: Union[str, list] = \"cpu\",\n    name: str = None,\n) -&gt; None:\n    \"\"\"Constructs a new instance of the Autoencoder\n\n    Args:\n        encoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The encoder network. Defaults to None.\n        bottleneck_encoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck encoder network. Defaults to None.\n        bottleneck_decoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck decoder network. Defaults to None.\n        decoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The decoder network. Defaults to None.\n        input_dim (Optional[Tuple[int, ...]], optional): The input dimensions. Used for automatic network generation. Defaults to None.\n        output_dim (Optional[Tuple[int, ...]], optional): The output dimensions. Used for automatic network generation. Defaults to None.\n        latent_dim (Optional[int], optional): The latent dimensions. Used for automatic network generation. Defaults to None.\n        activation (Optional[Union[list, str]], optional): The activation functions for each layer. Used for automatic network generation. Defaults to None.\n        channels (Optional[int], optional): The number of channels. Used for automatic network generation. Defaults to None.\n        case (Optional[str], optional): The type of problem. Used for automatic network generation. Defaults to None.\n        architecture (Optional[str], optional): The network architecture. Used for automatic network generation. Defaults to None.\n        shallow (Optional[bool], optional): Whether to use shallow or deep network. Used for automatic network generation. Defaults to False.\n        use_batch_norm (Optional[bool], optional):  (Default value = False)\n        encoder_activation (str, optional): The activation function for the encoder. Defaults to \"relu\".\n        devices (Union[str, list], optional): The devices to use. Defaults to \"cpu\".\n        name (str, optional): The name of the autoencoder. Defaults to None.\n\n    \"\"\"\n    super(AutoencoderKoopman, self).__init__(name=name)\n\n    self.weights = list()\n\n    # Determining the kind of device to be used for allocating the\n    # subnetworks\n    self.device = self._set_device(devices=devices)\n\n    self.input_dim = None\n\n    # If not network is provided, the automatic generation\n    # pipeline is activated.\n    if all(\n        [\n            isn == None\n            for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n        ]\n    ):\n        self.input_dim = input_dim\n\n        encoder, decoder, bottleneck_encoder, bottleneck_decoder = autoencoder_auto(\n            input_dim=input_dim,\n            latent_dim=latent_dim,\n            output_dim=output_dim,\n            activation=activation,\n            channels=channels,\n            architecture=architecture,\n            case=case,\n            shallow=shallow,\n            use_batch_norm=use_batch_norm,\n        )\n\n    self.encoder = encoder.to(self.device)\n    self.decoder = decoder.to(self.device)\n\n    self.add_module(\"encoder\", self.encoder)\n    self.add_module(\"decoder\", self.decoder)\n\n    self.weights += self.encoder.weights\n    self.weights += self.decoder.weights\n\n    # These subnetworks are optional\n    if bottleneck_encoder is not None and bottleneck_decoder is not None:\n        self.bottleneck_encoder = self.to_wrap(\n            entity=bottleneck_encoder, device=self.device\n        )\n        self.bottleneck_decoder = self.to_wrap(\n            entity=bottleneck_decoder, device=self.device\n        )\n\n        self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n        self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n        self.weights += self.bottleneck_encoder.weights\n        self.weights += self.bottleneck_decoder.weights\n\n    # These subnetworks are optional\n    if bottleneck_encoder is not None and bottleneck_decoder is not None:\n        self.bottleneck_encoder = self.to_wrap(\n            entity=bottleneck_encoder, device=self.device\n        )\n        self.bottleneck_decoder = self.to_wrap(\n            entity=bottleneck_decoder, device=self.device\n        )\n\n        self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n        self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n        self.weights += self.bottleneck_encoder.weights\n        self.weights += self.bottleneck_decoder.weights\n\n    if bottleneck_encoder is not None and bottleneck_decoder is not None:\n        self.projection = self._projection_with_bottleneck\n        self.reconstruction = self._reconstruction_with_bottleneck\n    else:\n        self.projection = self._projection\n        self.reconstruction = self._reconstruction\n\n    self.last_encoder_channels = None\n    self.before_flatten_dimension = None\n\n    self.latent_dimension = None\n\n    if bottleneck_encoder is not None:\n        self.latent_dimension = bottleneck_encoder.output_size\n    else:\n        self.latent_dimension = self.encoder.output_size\n\n    self.K_op = self.to_wrap(\n        entity=torch.nn.Linear(\n            self.latent_dimension, self.latent_dimension, bias=False\n        ).weight,\n        device=self.device,\n    )\n\n    self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n    self.shapes_dict = dict()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.latent_forward","title":"<code>latent_forward(input_data=None)</code>","text":"<p>Evaluates the operation u^{u+1} = K u^{i}</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The computed latent representation.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def latent_forward(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"Evaluates the operation u^{u+1} = K u^{i}\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n    Returns:\n        torch.Tensor: The computed latent representation.\n\n    \"\"\"\n    return torch.matmul(input_data, self.K_op.T)\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.latent_forward_m","title":"<code>latent_forward_m(input_data=None, m=1)</code>","text":"<p>Evaluates the operation $u^{u+m} = K^m u^{i}$</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <code>m</code> <code>int</code> <p>The number of Koopman iterations. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The computed latent representation.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def latent_forward_m(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None, m: int = 1\n) -&gt; torch.Tensor:\n    \"\"\"Evaluates the operation $u^{u+m} = K^m u^{i}$\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n        m (int, optional): The number of Koopman iterations. Defaults to 1.\n\n    Returns:\n        torch.Tensor: The computed latent representation.\n\n    \"\"\"\n    return torch.matmul(input_data, torch.pow(self.K_op.T, m))\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.predict","title":"<code>predict(input_data=None, n_steps=1)</code>","text":"<p>Predicts the reconstructed data for the input data after n_steps extrapolation in the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <code>n_steps</code> <code>int</code> <p>The number of extrapolations to perform. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The predicted reconstructed data.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def predict(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None, n_steps: int = 1\n) -&gt; np.ndarray:\n    \"\"\"Predicts the reconstructed data for the input data after n_steps extrapolation in the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n        n_steps (int, optional): The number of extrapolations to perform. Defaults to 1.\n\n    Returns:\n        np.ndarray: The predicted reconstructed data.\n\n    \"\"\"\n    if isinstance(input_data, np.ndarray):\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n    predictions = list()\n    latent = self.projection(input_data=input_data)\n    init_latent = latent\n\n    # Extrapolating in the latent space over n_steps steps\n    for s in range(n_steps):\n        latent_s = self.latent_forward(input_data=init_latent)\n        init_latent = latent_s\n        predictions.append(latent_s)\n\n    predictions = torch.vstack(predictions)\n\n    reconstructed_predictions = self.reconstruction(input_data=predictions)\n\n    return reconstructed_predictions.detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.project","title":"<code>project(input_data=None)</code>","text":"<p>Projects the input data into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The projected data.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n    \"\"\"Projects the input data into the latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n    Returns:\n        np.ndarray: The projected data.\n\n    \"\"\"\n    projected_data = self.projection(input_data=input_data)\n\n    return projected_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.reconstruct","title":"<code>reconstruct(input_data=None)</code>","text":"<p>Reconstructs the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The reconstructed data.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruct(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; np.ndarray:\n    \"\"\"Reconstructs the input data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n    Returns:\n        np.ndarray: The reconstructed data.\n\n    \"\"\"\n    reconstructed_data = self.reconstruction(input_data=input_data)\n\n    return reconstructed_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.reconstruction_forward","title":"<code>reconstruction_forward(input_data=None)</code>","text":"<p>Evaluates the operation \u0168 = D(E(U))</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed data.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruction_forward(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"Evaluates the operation \u0168 = D(E(U))\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n\n    Returns:\n        torch.Tensor: The reconstructed data.\n\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n    reconstructed = self.reconstruction(input_data=latent)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderKoopman.reconstruction_forward_m","title":"<code>reconstruction_forward_m(input_data=None, m=1)</code>","text":"<p>Evaluates the operation \u0168_m = D(K^m E(U))</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data. Defaults to None.</p> <code>None</code> <code>m</code> <code>int</code> <p>The number of Koopman iterations. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed data.</p> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruction_forward_m(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None, m: int = 1\n) -&gt; torch.Tensor:\n    \"\"\"Evaluates the operation \u0168_m = D(K^m E(U))\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data. Defaults to None.\n        m (int, optional): The number of Koopman iterations. Defaults to 1.\n\n    Returns:\n        torch.Tensor: The reconstructed data.\n\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n    latent_m = self.latent_forward_m(input_data=latent, m=m)\n    reconstructed_m = self.reconstruction(input_data=latent_m)\n\n    return reconstructed_m\n</code></pre>"},{"location":"simulai_models/#autoencodervariational","title":"AutoencoderVariational","text":"<p>             Bases: <code>NetworkTemplate</code></p> <p>This is an implementation of a Koopman autoencoder as a reduced order model.</p> <p>A variational autoencoder architecture consists of five stages:</p> <ul> <li>The convolutional encoder [Optional]</li> <li>Fully-connected encoder</li> <li>Gaussian noise</li> <li>Fully connected decoder</li> <li>The convolutional decoder [Optional]</li> </ul> <p>Graphical scheme</p> <pre><code>                                              Gaussian noise\n                                              ^\n                                       |      |      |\n                                       |  |   |   |  |\nZ -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | - | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n                                       |  |       |  |\n                                       |             |\n\n               ENCODER               DENSE BOTTLENECK           DECODER\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>class AutoencoderVariational(NetworkTemplate):\n    r\"\"\"This is an implementation of a Koopman autoencoder as a reduced order model.\n\n    A variational autoencoder architecture consists of five stages:\n\n    - The convolutional encoder [Optional]\n    - Fully-connected encoder\n    - Gaussian noise\n    - Fully connected decoder\n    - The convolutional decoder [Optional]\n\n    Graphical scheme\n\n                                                      Gaussian noise\n                                                      ^\n                                               |      |      |\n                                               |  |   |   |  |\n        Z -&gt; [Conv] -&gt; [Conv] -&gt; ... [Conv] -&gt; |  | | - | |  | -&gt; [Conv.T] -&gt; [Conv.T] -&gt; ... [Conv.T] -&gt; Z_til\n                                               |  |       |  |\n                                               |             |\n\n                       ENCODER               DENSE BOTTLENECK           DECODER\n\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n        bottleneck_encoder: Optional[Union[Linear, DenseNetwork]] = None,\n        bottleneck_decoder: Optional[Union[Linear, DenseNetwork]] = None,\n        decoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n        encoder_activation: str = \"relu\",\n        input_dim: Optional[Tuple[int, ...]] = None,\n        output_dim: Optional[Tuple[int, ...]] = None,\n        latent_dim: Optional[int] = None,\n        activation: Optional[Union[list, str]] = None,\n        channels: Optional[int] = None,\n        kernel_size: Optional[int] = None,\n        case: Optional[str] = None,\n        architecture: Optional[str] = None,\n        use_batch_norm: Optional[bool] = False,\n        shallow: Optional[bool] = False,\n        scale: float = 1e-3,\n        devices: Union[str, list] = \"cpu\",\n        name: str = None,\n        **kwargs,\n    ) -&gt; None:\n        r\"\"\"Constructor method.\n\n        Args:\n            encoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The encoder network. Defaults to None.\n            bottleneck_encoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck encoder network. Defaults to None.\n            bottleneck_decoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck decoder network. Defaults to None.\n            decoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The decoder network. Defaults to None.\n            encoder_activation (str, optional): The activation function to use in the encoder. Defaults to \"relu\".\n            input_dim (Optional[Tuple[int, ...]], optional): The input dimension of the data. Defaults to None.\n            output_dim (Optional[Tuple[int, ...]], optional): The output dimension of the data. Defaults to None.\n            latent_dim (Optional[int], optional): The size of the bottleneck layer. Defaults to None.\n            activation (Optional[Union[list, str]], optional): The activation function to use in the networks. Defaults to None.\n            channels (Optional[int], optional): The number of channels in the input data. Defaults to None.\n            kernel_size (Optional[int], optional): Convolutional kernel size. (Default value = None)\n            case (Optional[str], optional): The name of the autoencoder variant. Defaults to None.\n            architecture (Optional[str], optional): The architecture of the networks. Defaults to None.\n            use_batch_norm (Optional[bool], optional):  (Default value = False)\n            shallow (Optional[bool], optional): Whether to use a shallow network architecture. Defaults to False.\n            scale (float, optional): The scale of the initialization. Defaults to 1e-3.\n            devices (Union[str, list], optional): The device(s) to use for computation. Defaults to \"cpu\".\n            name (str, optional): The name of the autoencoder. Defaults to None.\n            **kwargs\n\n        \"\"\"\n        super(AutoencoderVariational, self).__init__(name=name)\n\n        self.weights = list()\n\n        # Determining the kind of device to be used for allocating the\n        # subnetworks\n        self.device = self._set_device(devices=devices)\n\n        self.input_dim = None\n\n        # If not network is provided, the automatic generation\n        # pipeline is activated.\n        if all(\n            [\n                isn == None\n                for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n            ]\n        ):\n            self.input_dim = input_dim\n\n            encoder, decoder, bottleneck_encoder, bottleneck_decoder = autoencoder_auto(\n                input_dim=input_dim,\n                latent_dim=latent_dim,\n                output_dim=output_dim,\n                activation=activation,\n                channels=channels,\n                kernel_size=kernel_size,\n                architecture=architecture,\n                case=case,\n                shallow=shallow,\n                use_batch_norm=use_batch_norm,\n                name=self.name,\n                **kwargs,\n            )\n\n        self.encoder = self.to_wrap(entity=encoder, device=self.device)\n        self.decoder = decoder.to(self.device)\n\n        self.add_module(\"encoder\", self.encoder)\n        self.add_module(\"decoder\", self.decoder)\n\n        self.weights += self.encoder.weights\n        self.weights += self.decoder.weights\n\n        self.there_is_bottleneck = False\n\n        # These subnetworks are optional\n        if bottleneck_encoder is not None and bottleneck_decoder is not None:\n            self.bottleneck_encoder = self.to_wrap(\n                entity=bottleneck_encoder, device=self.device\n            )\n            self.bottleneck_decoder = self.to_wrap(\n                entity=bottleneck_decoder, device=self.device\n            )\n\n            self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n            self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n            self.weights += self.bottleneck_encoder.weights\n            self.weights += self.bottleneck_decoder.weights\n\n            self.projection = self._projection_with_bottleneck\n            self.reconstruction = self._reconstruction_with_bottleneck\n\n            self.there_is_bottleneck = True\n\n        else:\n            self.projection = self._projection\n            self.reconstruction = self._reconstruction\n\n        self.last_encoder_channels = None\n        self.before_flatten_dimension = None\n\n        self.latent_dimension = None\n\n        if bottleneck_encoder is not None:\n            self.latent_dimension = bottleneck_encoder.output_size\n        else:\n            self.latent_dimension = self.encoder.output_size\n\n        self.z_mean = self.to_wrap(\n            entity=torch.nn.Linear(self.latent_dimension, self.latent_dimension),\n            device=self.device,\n        )\n\n        self.z_log_var = self.to_wrap(\n            entity=torch.nn.Linear(self.latent_dimension, self.latent_dimension),\n            device=self.device,\n        )\n\n        self.add_module(\"z_mean\", self.z_mean)\n        self.add_module(\"z_log_var\", self.z_log_var)\n\n        self.weights += [self.z_mean.weight]\n        self.weights += [self.z_log_var.weight]\n\n        self.mu = None\n        self.log_v = None\n        self.scale = scale\n\n        self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n        self.shapes_dict = dict()\n\n    def summary(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n        input_shape: list = None,\n        verbose: bool = True,\n        display: bool = True,\n    ) -&gt; torch.Tensor:\n        r\"\"\"Summarizes the overall architecture of the autoencoder and saves the content of the subnetworks to a dictionary.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): Input data to pass through the encoder, by default None\n            input_shape (list, optional): The shape of the input data if input_data is None, by default None\n            verbose (bool, optional):  (Default value = True)\n            display (bool, optional):  (Default value = True)\n\n        Returns:\n            torch.Tensor: The output of the autoencoder's decoder applied to the input data.\n\n        Raises:\n            Exception: If self.input_dim is not a tuple or an integer.\n            AssertionError: If input_shape is None when input_data is None.\n\n        Note:\n            The summary method calls the `summary` method of each of the subnetworks and saves the content of the subnetworks to the overall architecture dictionary. If there is a bottleneck network, it is also summarized and saved to the architecture dictionary.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; output_data = autoencoder.summary(input_data=input_data)\n        \"\"\"\n\n        if verbose == True:\n            if self.input_dim != None:\n                if type(self.input_dim) == tuple:\n                    input_shape = list(self.input_dim)\n                elif type(self.input_dim) == int:\n                    input_shape = [None, self.input_dim]\n                else:\n                    raise Exception(\n                        f\"input_dim is expected to be tuple or int, but received {type(self.input_dim)}\"\n                    )\n            else:\n                pass\n\n            self.encoder.summary(\n                input_data=input_data,\n                input_shape=input_shape,\n                device=self.device,\n                display=display,\n            )\n\n            if type(self.encoder.output_size) == tuple:\n                self.before_flatten_dimension = tuple(self.encoder.output_size[1:])\n                input_shape = self.encoder.input_size\n            elif type(self.encoder.output_size) == int:\n                input_shape = [None, self.encoder.input_size]\n            else:\n                pass\n\n            if isinstance(input_data, np.ndarray):\n                btnk_input = self.encoder.forward(input_data=input_data)\n            else:\n                assert (\n                    input_shape\n                ), \"It is necessary to have input_shape when input_data is None.\"\n\n                input_shape[0] = 1\n\n                input_data = self.to_wrap(\n                    entity=torch.ones(input_shape), device=self.device\n                )\n\n                btnk_input = self.encoder.forward(input_data=input_data)\n\n            before_flatten_dimension = tuple(btnk_input.shape[1:])\n            btnk_input = btnk_input.reshape((-1, np.prod(btnk_input.shape[1:])))\n\n            # Bottleneck networks is are optional\n            if self.there_is_bottleneck:\n                latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n                self.bottleneck_encoder.summary(display=display)\n                self.bottleneck_decoder.summary(display=display)\n\n                bottleneck_output = self.encoder_activation(\n                    self.bottleneck_decoder.forward(input_data=latent)\n                )\n\n                bottleneck_output = bottleneck_output.reshape(\n                    (-1, *before_flatten_dimension)\n                )\n            else:\n                bottleneck_output = btnk_input\n\n            self.decoder.summary(\n                input_data=bottleneck_output, device=self.device, display=display\n            )\n\n            # Saving the content of the subnetworks to the overall architecture dictionary\n            self.shapes_dict.update({\"encoder\": self.encoder.shapes_dict})\n\n            # Bottleneck networks is are optional\n            if self.there_is_bottleneck:\n                self.shapes_dict.update(\n                    {\"bottleneck_encoder\": self.bottleneck_encoder.shapes_dict}\n                )\n                self.shapes_dict.update(\n                    {\"bottleneck_decoder\": self.bottleneck_decoder.shapes_dict}\n                )\n\n            self.shapes_dict.update({\"decoder\": self.decoder.shapes_dict})\n\n        else:\n            print(self)\n\n    @as_tensor\n    def _projection_with_bottleneck(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the encoder and bottleneck encoder to input data and returns the output.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the encoder, by default None\n\n        Returns:\n            torch.Tensor: The output of the bottleneck encoder applied to the input data.\n        Note:\n            This function is used for projection of the input data into the bottleneck space.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; output_data = autoencoder._projection_with_bottleneck(input_data=input_data)\n        \"\"\"\n        btnk_input = self.encoder.forward(input_data=input_data)\n\n        self.before_flatten_dimension = tuple(self.encoder.output_size[1:])\n\n        btnk_input = btnk_input.reshape((-1, np.prod(self.before_flatten_dimension)))\n\n        latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n        return latent\n\n    @as_tensor\n    def _projection(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the encoder to input data and returns the output.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the encoder, by default None\n\n        Returns:\n            torch.Tensor: The output of the encoder applied to the input data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; output_data = autoencoder._projection(input_data=input_data)\n        \"\"\"\n        latent = self.encoder.forward(input_data=input_data)\n\n        return latent\n\n    @as_tensor\n    def _reconstruction_with_bottleneck(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the bottleneck decoder and decoder to input data and returns the output.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input data to pass through the bottleneck decoder and decoder, by default None\n\n        Returns:\n            torch.Tensor: The output of the decoder applied to the bottleneck decoder's output.\n        Note:\n            This function is used for reconstruction of the input data from the bottleneck space.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; bottleneck_output = autoencoder._projection_with_bottleneck(input_data=input_data)\n            &gt;&gt;&gt; output_data = autoencoder._reconstruction_with_bottleneck(input_data=bottleneck_output)\n        \"\"\"\n        bottleneck_output = self.encoder_activation(\n            (self.bottleneck_decoder.forward(input_data=input_data))\n        )\n\n        bottleneck_output = bottleneck_output.reshape(\n            (-1,) + self.before_flatten_dimension\n        )\n\n        reconstructed = self.decoder.forward(input_data=bottleneck_output)\n\n        return reconstructed\n\n    @as_tensor\n    def _reconstruction(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the decoder to input data and returns the output.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input data to pass through the decoder, by default None\n\n        Returns:\n            torch.Tensor: The output of the decoder applied to the input data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; output_data = autoencoder._reconstruction(input_data=input_data)\n        \"\"\"\n        reconstructed = self.decoder.forward(input_data=input_data)\n\n        return reconstructed\n\n    def Mu(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None, to_numpy: bool = False\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        r\"\"\"Computes the mean of the encoded input data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the mean, by default None\n            to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: The mean of the encoded input data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; mu = autoencoder.Mu(input_data=input_data)\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n\n        if to_numpy == True:\n            return self.z_mean(latent).detach().numpy()\n        else:\n            return self.z_mean(latent)\n\n    def Sigma(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None, to_numpy: bool = False\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        r\"\"\"Computes the standard deviation of the encoded input data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the standard deviation, by default None\n            to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: The standard deviation of the encoded input data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; sigma = autoencoder.Sigma(input_data=input_data)\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n\n        if to_numpy == True:\n            return torch.exp(self.z_log_var(latent) / 2).detach().numpy()\n        else:\n            return torch.exp(self.z_log_var(latent) / 2)\n\n    def CoVariance(\n        self,\n        input_data: Union[np.ndarray, torch.Tensor] = None,\n        inv: bool = False,\n        to_numpy: bool = False,\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        r\"\"\"Computes the covariance matrix of the encoded input data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the covariance matrix, by default None\n            inv (bool, optional): If True, returns the inverse of the covariance matrix, by default False\n            to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: The covariance matrix (or its inverse) of the encoded input data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; covariance = autoencoder.CoVariance(input_data=input_data)\n        \"\"\"\n        if inv == False:\n            Sigma_inv = 1 / self.Sigma(input_data=input_data)\n            covariance = torch.diag_embed(Sigma_inv)\n\n        else:\n            Sigma = self.Sigma(input_data=input_data)\n            covariance = torch.diag_embed(Sigma)\n\n        if to_numpy == True:\n            return covariance.detach().numpy()\n        else:\n            return covariance\n\n    def latent_gaussian_noisy(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Generates a noisy latent representation of the input data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and generate a noisy latent representation, by default None\n\n        Returns:\n            torch.Tensor: A noisy latent representation of the input data.\n        Note:\n            This function adds Gaussian noise to the mean and standard deviation of the encoded input data to generate a noisy latent representation.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; noisy_latent = autoencoder.latent_gaussian_noisy(input_data=input_data)\n        \"\"\"\n        self.mu = self.z_mean(input_data)\n        self.log_v = self.z_log_var(input_data)\n        eps = self.scale * torch.autograd.Variable(\n            torch.randn(*self.log_v.size())\n        ).type_as(self.log_v)\n\n        return self.mu + torch.exp(self.log_v / 2.0) * eps\n\n    def reconstruction_forward(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the encoder, adds Gaussian noise to the encoded data, and then applies the decoder to generate a reconstructed output.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the autoencoder, by default None\n\n        Returns:\n            torch.Tensor: The reconstructed output of the autoencoder.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_forward(input_data=input_data)\n        \"\"\"\n        latent = self.projection(input_data=input_data)\n        latent_noisy = self.latent_gaussian_noisy(input_data=latent)\n        reconstructed = self.reconstruction(input_data=latent_noisy)\n\n        return reconstructed\n\n    def reconstruction_eval(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"Applies the encoder, computes the mean of the encoded data, and then applies the decoder to generate a reconstructed output.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the autoencoder, by default None\n\n        Returns:\n            torch.Tensor: The reconstructed output of the autoencoder.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_eval(input_data=input_data)\n        \"\"\"\n        encoder_output = self.projection(input_data=input_data)\n        latent = self.z_mean(encoder_output)\n        reconstructed = self.reconstruction(input_data=latent)\n\n        return reconstructed\n\n    def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n        r\"\"\"Projects the input data onto the autoencoder's latent space.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to project onto the autoencoder's latent space, by default None\n\n        Returns:\n            np.ndarray: The input data projected onto the autoencoder's latent space.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; projected_data = autoencoder.project(input_data=input_data)\n        \"\"\"\n        if isinstance(input_data, np.ndarray):\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        input_data = input_data.to(self.device)\n\n        projected_data_latent = self.Mu(input_data=input_data)\n\n        return projected_data_latent.cpu().detach().numpy()\n\n    def reconstruct(\n        self, input_data: Union[np.ndarray, torch.Tensor] = None\n    ) -&gt; np.ndarray:\n        r\"\"\"Reconstructs the input data using the trained autoencoder.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to reconstruct, by default None\n\n        Returns:\n            np.ndarray: The reconstructed data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruct(input_data=input_data)\n        \"\"\"\n        if isinstance(input_data, np.ndarray):\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        input_data = input_data.to(self.device)\n\n        reconstructed_data = self.reconstruction(input_data=input_data)\n\n        return reconstructed_data.cpu().detach().numpy()\n\n    def eval(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n        r\"\"\"Reconstructs the input data using the mean of the encoded data.\n\n        Args:\n            input_data (Union[np.ndarray, torch.Tensor], optional): The input data to reconstruct, by default None\n\n        Returns:\n            np.ndarray: The reconstructed data.\n        Example::\n\n            &gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n            &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n            &gt;&gt;&gt; reconstructed_data = autoencoder.eval(input_data=input_data)\n        \"\"\"\n\n        if isinstance(input_data, np.ndarray):\n            input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n        input_data = input_data.to(self.device)\n\n        return self.reconstruction_eval(input_data=input_data).cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.CoVariance","title":"<code>CoVariance(input_data=None, inv=False, to_numpy=False)</code>","text":"<p>Computes the covariance matrix of the encoded input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to encode and compute the covariance matrix, by default None</p> <code>None</code> <code>inv</code> <code>bool</code> <p>If True, returns the inverse of the covariance matrix, by default False</p> <code>False</code> <code>to_numpy</code> <code>bool</code> <p>If True, returns the result as a NumPy array, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: The covariance matrix (or its inverse) of the encoded input data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; covariance = autoencoder.CoVariance(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def CoVariance(\n    self,\n    input_data: Union[np.ndarray, torch.Tensor] = None,\n    inv: bool = False,\n    to_numpy: bool = False,\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    r\"\"\"Computes the covariance matrix of the encoded input data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the covariance matrix, by default None\n        inv (bool, optional): If True, returns the inverse of the covariance matrix, by default False\n        to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: The covariance matrix (or its inverse) of the encoded input data.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; covariance = autoencoder.CoVariance(input_data=input_data)\n    \"\"\"\n    if inv == False:\n        Sigma_inv = 1 / self.Sigma(input_data=input_data)\n        covariance = torch.diag_embed(Sigma_inv)\n\n    else:\n        Sigma = self.Sigma(input_data=input_data)\n        covariance = torch.diag_embed(Sigma)\n\n    if to_numpy == True:\n        return covariance.detach().numpy()\n    else:\n        return covariance\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.Mu","title":"<code>Mu(input_data=None, to_numpy=False)</code>","text":"<p>Computes the mean of the encoded input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to encode and compute the mean, by default None</p> <code>None</code> <code>to_numpy</code> <code>bool</code> <p>If True, returns the result as a NumPy array, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: The mean of the encoded input data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; mu = autoencoder.Mu(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def Mu(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None, to_numpy: bool = False\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    r\"\"\"Computes the mean of the encoded input data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the mean, by default None\n        to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: The mean of the encoded input data.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; mu = autoencoder.Mu(input_data=input_data)\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n\n    if to_numpy == True:\n        return self.z_mean(latent).detach().numpy()\n    else:\n        return self.z_mean(latent)\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.Sigma","title":"<code>Sigma(input_data=None, to_numpy=False)</code>","text":"<p>Computes the standard deviation of the encoded input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to encode and compute the standard deviation, by default None</p> <code>None</code> <code>to_numpy</code> <code>bool</code> <p>If True, returns the result as a NumPy array, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: The standard deviation of the encoded input data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; sigma = autoencoder.Sigma(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def Sigma(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None, to_numpy: bool = False\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    r\"\"\"Computes the standard deviation of the encoded input data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and compute the standard deviation, by default None\n        to_numpy (bool, optional): If True, returns the result as a NumPy array, by default False\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: The standard deviation of the encoded input data.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; sigma = autoencoder.Sigma(input_data=input_data)\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n\n    if to_numpy == True:\n        return torch.exp(self.z_log_var(latent) / 2).detach().numpy()\n    else:\n        return torch.exp(self.z_log_var(latent) / 2)\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.__init__","title":"<code>__init__(encoder=None, bottleneck_encoder=None, bottleneck_decoder=None, decoder=None, encoder_activation='relu', input_dim=None, output_dim=None, latent_dim=None, activation=None, channels=None, kernel_size=None, case=None, architecture=None, use_batch_norm=False, shallow=False, scale=0.001, devices='cpu', name=None, **kwargs)</code>","text":"<p>Constructor method.</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>Union[ConvolutionalNetwork, DenseNetwork]</code> <p>The encoder network. Defaults to None.</p> <code>None</code> <code>bottleneck_encoder</code> <code>Optional[Union[Linear, DenseNetwork]]</code> <p>The bottleneck encoder network. Defaults to None.</p> <code>None</code> <code>bottleneck_decoder</code> <code>Optional[Union[Linear, DenseNetwork]]</code> <p>The bottleneck decoder network. Defaults to None.</p> <code>None</code> <code>decoder</code> <code>Union[ConvolutionalNetwork, DenseNetwork]</code> <p>The decoder network. Defaults to None.</p> <code>None</code> <code>encoder_activation</code> <code>str</code> <p>The activation function to use in the encoder. Defaults to \"relu\".</p> <code>'relu'</code> <code>input_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The input dimension of the data. Defaults to None.</p> <code>None</code> <code>output_dim</code> <code>Optional[Tuple[int, ...]]</code> <p>The output dimension of the data. Defaults to None.</p> <code>None</code> <code>latent_dim</code> <code>Optional[int]</code> <p>The size of the bottleneck layer. Defaults to None.</p> <code>None</code> <code>activation</code> <code>Optional[Union[list, str]]</code> <p>The activation function to use in the networks. Defaults to None.</p> <code>None</code> <code>channels</code> <code>Optional[int]</code> <p>The number of channels in the input data. Defaults to None.</p> <code>None</code> <code>kernel_size</code> <code>Optional[int]</code> <p>Convolutional kernel size. (Default value = None)</p> <code>None</code> <code>case</code> <code>Optional[str]</code> <p>The name of the autoencoder variant. Defaults to None.</p> <code>None</code> <code>architecture</code> <code>Optional[str]</code> <p>The architecture of the networks. Defaults to None.</p> <code>None</code> <code>use_batch_norm</code> <code>Optional[bool]</code> <p>(Default value = False)</p> <code>False</code> <code>shallow</code> <code>Optional[bool]</code> <p>Whether to use a shallow network architecture. Defaults to False.</p> <code>False</code> <code>scale</code> <code>float</code> <p>The scale of the initialization. Defaults to 1e-3.</p> <code>0.001</code> <code>devices</code> <code>Union[str, list]</code> <p>The device(s) to use for computation. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>name</code> <code>str</code> <p>The name of the autoencoder. Defaults to None.</p> <code>None</code> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def __init__(\n    self,\n    encoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n    bottleneck_encoder: Optional[Union[Linear, DenseNetwork]] = None,\n    bottleneck_decoder: Optional[Union[Linear, DenseNetwork]] = None,\n    decoder: Union[ConvolutionalNetwork, DenseNetwork] = None,\n    encoder_activation: str = \"relu\",\n    input_dim: Optional[Tuple[int, ...]] = None,\n    output_dim: Optional[Tuple[int, ...]] = None,\n    latent_dim: Optional[int] = None,\n    activation: Optional[Union[list, str]] = None,\n    channels: Optional[int] = None,\n    kernel_size: Optional[int] = None,\n    case: Optional[str] = None,\n    architecture: Optional[str] = None,\n    use_batch_norm: Optional[bool] = False,\n    shallow: Optional[bool] = False,\n    scale: float = 1e-3,\n    devices: Union[str, list] = \"cpu\",\n    name: str = None,\n    **kwargs,\n) -&gt; None:\n    r\"\"\"Constructor method.\n\n    Args:\n        encoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The encoder network. Defaults to None.\n        bottleneck_encoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck encoder network. Defaults to None.\n        bottleneck_decoder (Optional[Union[Linear, DenseNetwork]], optional): The bottleneck decoder network. Defaults to None.\n        decoder (Union[ConvolutionalNetwork, DenseNetwork], optional): The decoder network. Defaults to None.\n        encoder_activation (str, optional): The activation function to use in the encoder. Defaults to \"relu\".\n        input_dim (Optional[Tuple[int, ...]], optional): The input dimension of the data. Defaults to None.\n        output_dim (Optional[Tuple[int, ...]], optional): The output dimension of the data. Defaults to None.\n        latent_dim (Optional[int], optional): The size of the bottleneck layer. Defaults to None.\n        activation (Optional[Union[list, str]], optional): The activation function to use in the networks. Defaults to None.\n        channels (Optional[int], optional): The number of channels in the input data. Defaults to None.\n        kernel_size (Optional[int], optional): Convolutional kernel size. (Default value = None)\n        case (Optional[str], optional): The name of the autoencoder variant. Defaults to None.\n        architecture (Optional[str], optional): The architecture of the networks. Defaults to None.\n        use_batch_norm (Optional[bool], optional):  (Default value = False)\n        shallow (Optional[bool], optional): Whether to use a shallow network architecture. Defaults to False.\n        scale (float, optional): The scale of the initialization. Defaults to 1e-3.\n        devices (Union[str, list], optional): The device(s) to use for computation. Defaults to \"cpu\".\n        name (str, optional): The name of the autoencoder. Defaults to None.\n        **kwargs\n\n    \"\"\"\n    super(AutoencoderVariational, self).__init__(name=name)\n\n    self.weights = list()\n\n    # Determining the kind of device to be used for allocating the\n    # subnetworks\n    self.device = self._set_device(devices=devices)\n\n    self.input_dim = None\n\n    # If not network is provided, the automatic generation\n    # pipeline is activated.\n    if all(\n        [\n            isn == None\n            for isn in [encoder, decoder, bottleneck_encoder, bottleneck_decoder]\n        ]\n    ):\n        self.input_dim = input_dim\n\n        encoder, decoder, bottleneck_encoder, bottleneck_decoder = autoencoder_auto(\n            input_dim=input_dim,\n            latent_dim=latent_dim,\n            output_dim=output_dim,\n            activation=activation,\n            channels=channels,\n            kernel_size=kernel_size,\n            architecture=architecture,\n            case=case,\n            shallow=shallow,\n            use_batch_norm=use_batch_norm,\n            name=self.name,\n            **kwargs,\n        )\n\n    self.encoder = self.to_wrap(entity=encoder, device=self.device)\n    self.decoder = decoder.to(self.device)\n\n    self.add_module(\"encoder\", self.encoder)\n    self.add_module(\"decoder\", self.decoder)\n\n    self.weights += self.encoder.weights\n    self.weights += self.decoder.weights\n\n    self.there_is_bottleneck = False\n\n    # These subnetworks are optional\n    if bottleneck_encoder is not None and bottleneck_decoder is not None:\n        self.bottleneck_encoder = self.to_wrap(\n            entity=bottleneck_encoder, device=self.device\n        )\n        self.bottleneck_decoder = self.to_wrap(\n            entity=bottleneck_decoder, device=self.device\n        )\n\n        self.add_module(\"bottleneck_encoder\", self.bottleneck_encoder)\n        self.add_module(\"bottleneck_decoder\", self.bottleneck_decoder)\n\n        self.weights += self.bottleneck_encoder.weights\n        self.weights += self.bottleneck_decoder.weights\n\n        self.projection = self._projection_with_bottleneck\n        self.reconstruction = self._reconstruction_with_bottleneck\n\n        self.there_is_bottleneck = True\n\n    else:\n        self.projection = self._projection\n        self.reconstruction = self._reconstruction\n\n    self.last_encoder_channels = None\n    self.before_flatten_dimension = None\n\n    self.latent_dimension = None\n\n    if bottleneck_encoder is not None:\n        self.latent_dimension = bottleneck_encoder.output_size\n    else:\n        self.latent_dimension = self.encoder.output_size\n\n    self.z_mean = self.to_wrap(\n        entity=torch.nn.Linear(self.latent_dimension, self.latent_dimension),\n        device=self.device,\n    )\n\n    self.z_log_var = self.to_wrap(\n        entity=torch.nn.Linear(self.latent_dimension, self.latent_dimension),\n        device=self.device,\n    )\n\n    self.add_module(\"z_mean\", self.z_mean)\n    self.add_module(\"z_log_var\", self.z_log_var)\n\n    self.weights += [self.z_mean.weight]\n    self.weights += [self.z_log_var.weight]\n\n    self.mu = None\n    self.log_v = None\n    self.scale = scale\n\n    self.encoder_activation = self._get_operation(operation=encoder_activation)\n\n    self.shapes_dict = dict()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.eval","title":"<code>eval(input_data=None)</code>","text":"<p>Reconstructs the input data using the mean of the encoded data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to reconstruct, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The reconstructed data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; reconstructed_data = autoencoder.eval(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def eval(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n    r\"\"\"Reconstructs the input data using the mean of the encoded data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to reconstruct, by default None\n\n    Returns:\n        np.ndarray: The reconstructed data.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; reconstructed_data = autoencoder.eval(input_data=input_data)\n    \"\"\"\n\n    if isinstance(input_data, np.ndarray):\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n    input_data = input_data.to(self.device)\n\n    return self.reconstruction_eval(input_data=input_data).cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.latent_gaussian_noisy","title":"<code>latent_gaussian_noisy(input_data=None)</code>","text":"<p>Generates a noisy latent representation of the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to encode and generate a noisy latent representation, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: A noisy latent representation of the input data.</p> <p>Note:     This function adds Gaussian noise to the mean and standard deviation of the encoded input data to generate a noisy latent representation. Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; noisy_latent = autoencoder.latent_gaussian_noisy(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def latent_gaussian_noisy(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    r\"\"\"Generates a noisy latent representation of the input data.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to encode and generate a noisy latent representation, by default None\n\n    Returns:\n        torch.Tensor: A noisy latent representation of the input data.\n    Note:\n        This function adds Gaussian noise to the mean and standard deviation of the encoded input data to generate a noisy latent representation.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; noisy_latent = autoencoder.latent_gaussian_noisy(input_data=input_data)\n    \"\"\"\n    self.mu = self.z_mean(input_data)\n    self.log_v = self.z_log_var(input_data)\n    eps = self.scale * torch.autograd.Variable(\n        torch.randn(*self.log_v.size())\n    ).type_as(self.log_v)\n\n    return self.mu + torch.exp(self.log_v / 2.0) * eps\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.project","title":"<code>project(input_data=None)</code>","text":"<p>Projects the input data onto the autoencoder's latent space.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to project onto the autoencoder's latent space, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The input data projected onto the autoencoder's latent space.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; projected_data = autoencoder.project(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def project(self, input_data: Union[np.ndarray, torch.Tensor] = None) -&gt; np.ndarray:\n    r\"\"\"Projects the input data onto the autoencoder's latent space.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to project onto the autoencoder's latent space, by default None\n\n    Returns:\n        np.ndarray: The input data projected onto the autoencoder's latent space.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; projected_data = autoencoder.project(input_data=input_data)\n    \"\"\"\n    if isinstance(input_data, np.ndarray):\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n    input_data = input_data.to(self.device)\n\n    projected_data_latent = self.Mu(input_data=input_data)\n\n    return projected_data_latent.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.reconstruct","title":"<code>reconstruct(input_data=None)</code>","text":"<p>Reconstructs the input data using the trained autoencoder.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to reconstruct, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The reconstructed data.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; reconstructed_data = autoencoder.reconstruct(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruct(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; np.ndarray:\n    r\"\"\"Reconstructs the input data using the trained autoencoder.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to reconstruct, by default None\n\n    Returns:\n        np.ndarray: The reconstructed data.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = Autoencoder(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruct(input_data=input_data)\n    \"\"\"\n    if isinstance(input_data, np.ndarray):\n        input_data = torch.from_numpy(input_data.astype(ARRAY_DTYPE))\n\n    input_data = input_data.to(self.device)\n\n    reconstructed_data = self.reconstruction(input_data=input_data)\n\n    return reconstructed_data.cpu().detach().numpy()\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.reconstruction_eval","title":"<code>reconstruction_eval(input_data=None)</code>","text":"<p>Applies the encoder, computes the mean of the encoded data, and then applies the decoder to generate a reconstructed output.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to pass through the autoencoder, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed output of the autoencoder.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_eval(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruction_eval(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    r\"\"\"Applies the encoder, computes the mean of the encoded data, and then applies the decoder to generate a reconstructed output.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the autoencoder, by default None\n\n    Returns:\n        torch.Tensor: The reconstructed output of the autoencoder.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_eval(input_data=input_data)\n    \"\"\"\n    encoder_output = self.projection(input_data=input_data)\n    latent = self.z_mean(encoder_output)\n    reconstructed = self.reconstruction(input_data=latent)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.reconstruction_forward","title":"<code>reconstruction_forward(input_data=None)</code>","text":"<p>Applies the encoder, adds Gaussian noise to the encoded data, and then applies the decoder to generate a reconstructed output.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>The input data to pass through the autoencoder, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The reconstructed output of the autoencoder.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_forward(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def reconstruction_forward(\n    self, input_data: Union[np.ndarray, torch.Tensor] = None\n) -&gt; torch.Tensor:\n    r\"\"\"Applies the encoder, adds Gaussian noise to the encoded data, and then applies the decoder to generate a reconstructed output.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): The input data to pass through the autoencoder, by default None\n\n    Returns:\n        torch.Tensor: The reconstructed output of the autoencoder.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; reconstructed_data = autoencoder.reconstruction_forward(input_data=input_data)\n    \"\"\"\n    latent = self.projection(input_data=input_data)\n    latent_noisy = self.latent_gaussian_noisy(input_data=latent)\n    reconstructed = self.reconstruction(input_data=latent_noisy)\n\n    return reconstructed\n</code></pre>"},{"location":"simulai_models/#simulai.models.AutoencoderVariational.summary","title":"<code>summary(input_data=None, input_shape=None, verbose=True, display=True)</code>","text":"<p>Summarizes the overall architecture of the autoencoder and saves the content of the subnetworks to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[ndarray, Tensor]</code> <p>Input data to pass through the encoder, by default None</p> <code>None</code> <code>input_shape</code> <code>list</code> <p>The shape of the input data if input_data is None, by default None</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>(Default value = True)</p> <code>True</code> <code>display</code> <code>bool</code> <p>(Default value = True)</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The output of the autoencoder's decoder applied to the input data.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If self.input_dim is not a tuple or an integer.</p> <code>AssertionError</code> <p>If input_shape is None when input_data is None.</p> Note <p>The summary method calls the <code>summary</code> method of each of the subnetworks and saves the content of the subnetworks to the overall architecture dictionary. If there is a bottleneck network, it is also summarized and saved to the architecture dictionary.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n&gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n&gt;&gt;&gt; output_data = autoencoder.summary(input_data=input_data)\n</code></pre> Source code in <code>simulai/models/_pytorch_models/_autoencoder.py</code> <pre><code>def summary(\n    self,\n    input_data: Union[np.ndarray, torch.Tensor] = None,\n    input_shape: list = None,\n    verbose: bool = True,\n    display: bool = True,\n) -&gt; torch.Tensor:\n    r\"\"\"Summarizes the overall architecture of the autoencoder and saves the content of the subnetworks to a dictionary.\n\n    Args:\n        input_data (Union[np.ndarray, torch.Tensor], optional): Input data to pass through the encoder, by default None\n        input_shape (list, optional): The shape of the input data if input_data is None, by default None\n        verbose (bool, optional):  (Default value = True)\n        display (bool, optional):  (Default value = True)\n\n    Returns:\n        torch.Tensor: The output of the autoencoder's decoder applied to the input data.\n\n    Raises:\n        Exception: If self.input_dim is not a tuple or an integer.\n        AssertionError: If input_shape is None when input_data is None.\n\n    Note:\n        The summary method calls the `summary` method of each of the subnetworks and saves the content of the subnetworks to the overall architecture dictionary. If there is a bottleneck network, it is also summarized and saved to the architecture dictionary.\n    Example::\n\n        &gt;&gt;&gt; autoencoder = AutoencoderVariational(input_dim=(28, 28, 1))\n        &gt;&gt;&gt; input_data = np.random.rand(1, 28, 28, 1)\n        &gt;&gt;&gt; output_data = autoencoder.summary(input_data=input_data)\n    \"\"\"\n\n    if verbose == True:\n        if self.input_dim != None:\n            if type(self.input_dim) == tuple:\n                input_shape = list(self.input_dim)\n            elif type(self.input_dim) == int:\n                input_shape = [None, self.input_dim]\n            else:\n                raise Exception(\n                    f\"input_dim is expected to be tuple or int, but received {type(self.input_dim)}\"\n                )\n        else:\n            pass\n\n        self.encoder.summary(\n            input_data=input_data,\n            input_shape=input_shape,\n            device=self.device,\n            display=display,\n        )\n\n        if type(self.encoder.output_size) == tuple:\n            self.before_flatten_dimension = tuple(self.encoder.output_size[1:])\n            input_shape = self.encoder.input_size\n        elif type(self.encoder.output_size) == int:\n            input_shape = [None, self.encoder.input_size]\n        else:\n            pass\n\n        if isinstance(input_data, np.ndarray):\n            btnk_input = self.encoder.forward(input_data=input_data)\n        else:\n            assert (\n                input_shape\n            ), \"It is necessary to have input_shape when input_data is None.\"\n\n            input_shape[0] = 1\n\n            input_data = self.to_wrap(\n                entity=torch.ones(input_shape), device=self.device\n            )\n\n            btnk_input = self.encoder.forward(input_data=input_data)\n\n        before_flatten_dimension = tuple(btnk_input.shape[1:])\n        btnk_input = btnk_input.reshape((-1, np.prod(btnk_input.shape[1:])))\n\n        # Bottleneck networks is are optional\n        if self.there_is_bottleneck:\n            latent = self.bottleneck_encoder.forward(input_data=btnk_input)\n\n            self.bottleneck_encoder.summary(display=display)\n            self.bottleneck_decoder.summary(display=display)\n\n            bottleneck_output = self.encoder_activation(\n                self.bottleneck_decoder.forward(input_data=latent)\n            )\n\n            bottleneck_output = bottleneck_output.reshape(\n                (-1, *before_flatten_dimension)\n            )\n        else:\n            bottleneck_output = btnk_input\n\n        self.decoder.summary(\n            input_data=bottleneck_output, device=self.device, display=display\n        )\n\n        # Saving the content of the subnetworks to the overall architecture dictionary\n        self.shapes_dict.update({\"encoder\": self.encoder.shapes_dict})\n\n        # Bottleneck networks is are optional\n        if self.there_is_bottleneck:\n            self.shapes_dict.update(\n                {\"bottleneck_encoder\": self.bottleneck_encoder.shapes_dict}\n            )\n            self.shapes_dict.update(\n                {\"bottleneck_decoder\": self.bottleneck_decoder.shapes_dict}\n            )\n\n        self.shapes_dict.update({\"decoder\": self.decoder.shapes_dict})\n\n    else:\n        print(self)\n</code></pre>"},{"location":"simulai_regression/","title":"simulai.regression","text":""},{"location":"simulai_regression/#dense","title":"Dense","text":""},{"location":"simulai_regression/#linear","title":"Linear","text":"<p>             Bases: <code>NetworkTemplate</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class Linear(NetworkTemplate):\n    name = \"linear\"\n    engine = \"torch\"\n\n    def __init__(\n        self,\n        input_size: int = None,\n        output_size: int = None,\n        bias: bool = True,\n        name: str = None,\n    ) -&gt; None:\n        \"\"\"Linear operator F(u) = Au + b\n\n        Args:\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            bias (bool, optional): Using bias tensor or not. (Default value = True)\n            name (str, optional): A name for identifying the model. (Default value = None)\n\n        \"\"\"\n\n        super(Linear, self).__init__(name=name)\n\n        self.input_size = input_size\n        self.output_size = output_size\n\n        self.activations_str = None\n\n        self.layers = [torch.nn.Linear(input_size, output_size, bias=bias)]\n\n        self.add_module(self.name + \"_\" + \"linear_op\", self.layers[0])\n\n        self.weights = [item.weight for item in self.layers]\n\n        self.bias = [item.bias for item in self.layers]\n\n        self.name = name\n\n    @as_tensor\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Applying the operator Linear.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): Data to be processed using Linear. (Default value = None)\n\n        \"\"\"\n\n        return self.layers[0](input_data)\n\n    def to_numpy(self):\n        \"\"\"It converts the tensors in Linear to numpy.ndarray.\"\"\"\n\n        return LinearNumpy(layer=self.layers[0], name=self.name)\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.Linear.__init__","title":"<code>__init__(input_size=None, output_size=None, bias=True, name=None)</code>","text":"<p>Linear operator F(u) = Au + b</p> <p>Parameters:</p> Name Type Description Default <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>bias</code> <code>bool</code> <p>Using bias tensor or not. (Default value = True)</p> <code>True</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    input_size: int = None,\n    output_size: int = None,\n    bias: bool = True,\n    name: str = None,\n) -&gt; None:\n    \"\"\"Linear operator F(u) = Au + b\n\n    Args:\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        bias (bool, optional): Using bias tensor or not. (Default value = True)\n        name (str, optional): A name for identifying the model. (Default value = None)\n\n    \"\"\"\n\n    super(Linear, self).__init__(name=name)\n\n    self.input_size = input_size\n    self.output_size = output_size\n\n    self.activations_str = None\n\n    self.layers = [torch.nn.Linear(input_size, output_size, bias=bias)]\n\n    self.add_module(self.name + \"_\" + \"linear_op\", self.layers[0])\n\n    self.weights = [item.weight for item in self.layers]\n\n    self.bias = [item.bias for item in self.layers]\n\n    self.name = name\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.Linear.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Applying the operator Linear.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>Data to be processed using Linear. (Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>@as_tensor\ndef forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"Applying the operator Linear.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): Data to be processed using Linear. (Default value = None)\n\n    \"\"\"\n\n    return self.layers[0](input_data)\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.Linear.to_numpy","title":"<code>to_numpy()</code>","text":"<p>It converts the tensors in Linear to numpy.ndarray.</p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def to_numpy(self):\n    \"\"\"It converts the tensors in Linear to numpy.ndarray.\"\"\"\n\n    return LinearNumpy(layer=self.layers[0], name=self.name)\n</code></pre>"},{"location":"simulai_regression/#slfnn","title":"SLFNN","text":"<p>             Bases: <code>Linear</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class SLFNN(Linear):\n    def __init__(\n        self,\n        input_size: int = None,\n        output_size: int = None,\n        bias: bool = True,\n        name: str = None,\n        activation: str = \"tanh\",\n    ) -&gt; None:\n        \"\"\"Single layer fully-connected (dense) neural network\n\n        Args:\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            bias (bool, optional): Using bias tensor or not. (Default value = True)\n            name (str, optional): A name for identifying the model. (Default value = None)\n            activation (str, optional): Activation function. (Default value = \"tanh\")\n\n        \"\"\"\n\n        super(SLFNN, self).__init__(\n            input_size=input_size, output_size=output_size, bias=bias, name=name\n        )\n\n        self.activation = self._get_operation(operation=activation)\n\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Applying the operator Linear.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): Data to be processed using SLFNN. (Default value = None)\n\n        \"\"\"\n\n        return self.activation(super().forward(input_data=input_data))\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.SLFNN.__init__","title":"<code>__init__(input_size=None, output_size=None, bias=True, name=None, activation='tanh')</code>","text":"<p>Single layer fully-connected (dense) neural network</p> <p>Parameters:</p> Name Type Description Default <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>bias</code> <code>bool</code> <p>Using bias tensor or not. (Default value = True)</p> <code>True</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = None)</p> <code>None</code> <code>activation</code> <code>str</code> <p>Activation function. (Default value = \"tanh\")</p> <code>'tanh'</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    input_size: int = None,\n    output_size: int = None,\n    bias: bool = True,\n    name: str = None,\n    activation: str = \"tanh\",\n) -&gt; None:\n    \"\"\"Single layer fully-connected (dense) neural network\n\n    Args:\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        bias (bool, optional): Using bias tensor or not. (Default value = True)\n        name (str, optional): A name for identifying the model. (Default value = None)\n        activation (str, optional): Activation function. (Default value = \"tanh\")\n\n    \"\"\"\n\n    super(SLFNN, self).__init__(\n        input_size=input_size, output_size=output_size, bias=bias, name=name\n    )\n\n    self.activation = self._get_operation(operation=activation)\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.SLFNN.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Applying the operator Linear.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>Data to be processed using SLFNN. (Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"Applying the operator Linear.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): Data to be processed using SLFNN. (Default value = None)\n\n    \"\"\"\n\n    return self.activation(super().forward(input_data=input_data))\n</code></pre>"},{"location":"simulai_regression/#shallownetwork","title":"ShallowNetwork","text":"<p>             Bases: <code>SLFNN</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class ShallowNetwork(SLFNN):\n    def __init__(\n        self,\n        input_size: int = None,\n        hidden_size: int = None,\n        output_size: int = None,\n        bias: bool = True,\n        name: str = None,\n        activation: str = \"tanh\",\n    ) -&gt; None:\n        \"\"\"ELM-like (Extreme Learning Machine) shallow network\n\n        Args:\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            hidden_size (int, optional): Dimension of the hidden (intermediary) state. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            bias (bool, optional): Using bias or not for the last layer. (Default value = True)\n            name (str, optional): A name for identifying the model. (Default value = None)\n            activation (str, optional): Activation function. (Default value = \"tanh\")\n\n        \"\"\"\n\n        super(ShallowNetwork, self).__init__(\n            input_size=input_size, output_size=hidden_size, bias=bias, name=name\n        )\n\n        self.output_layer = Linear(\n            input_size=hidden_size, output_size=output_size, bias=False, name=\"output\"\n        )\n\n        self.output_size = output_size\n\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional):  (Default value = None)\n\n        \"\"\"\n\n        hidden_state = self.activation(super().forward(input_data=input_data))\n\n        return self.output_layer.forward(input_data=hidden_state)\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ShallowNetwork.__init__","title":"<code>__init__(input_size=None, hidden_size=None, output_size=None, bias=True, name=None, activation='tanh')</code>","text":"<p>ELM-like (Extreme Learning Machine) shallow network</p> <p>Parameters:</p> Name Type Description Default <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>hidden_size</code> <code>int</code> <p>Dimension of the hidden (intermediary) state. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>bias</code> <code>bool</code> <p>Using bias or not for the last layer. (Default value = True)</p> <code>True</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = None)</p> <code>None</code> <code>activation</code> <code>str</code> <p>Activation function. (Default value = \"tanh\")</p> <code>'tanh'</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    input_size: int = None,\n    hidden_size: int = None,\n    output_size: int = None,\n    bias: bool = True,\n    name: str = None,\n    activation: str = \"tanh\",\n) -&gt; None:\n    \"\"\"ELM-like (Extreme Learning Machine) shallow network\n\n    Args:\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        hidden_size (int, optional): Dimension of the hidden (intermediary) state. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        bias (bool, optional): Using bias or not for the last layer. (Default value = True)\n        name (str, optional): A name for identifying the model. (Default value = None)\n        activation (str, optional): Activation function. (Default value = \"tanh\")\n\n    \"\"\"\n\n    super(ShallowNetwork, self).__init__(\n        input_size=input_size, output_size=hidden_size, bias=bias, name=name\n    )\n\n    self.output_layer = Linear(\n        input_size=hidden_size, output_size=output_size, bias=False, name=\"output\"\n    )\n\n    self.output_size = output_size\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ShallowNetwork.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>(Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional):  (Default value = None)\n\n    \"\"\"\n\n    hidden_state = self.activation(super().forward(input_data=input_data))\n\n    return self.output_layer.forward(input_data=hidden_state)\n</code></pre>"},{"location":"simulai_regression/#densenetwork","title":"DenseNetwork","text":"<p>             Bases: <code>NetworkTemplate</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class DenseNetwork(NetworkTemplate):\n    name = \"dense\"\n    engine = \"torch\"\n\n    def __init__(\n        self,\n        layers_units: list = None,\n        activations: Union[list, str] = None,\n        input_size: int = None,\n        output_size: int = None,\n        normalization: str = \"bypass\",\n        name: str = \"\",\n        last_bias: bool = True,\n        last_activation: str = \"identity\",\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Dense (fully-connected) neural network written in PyTorch\n\n        Args:\n            layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n            activations (Union[list, str], optional): List of activations for each layer or a single string\n            informing the activation used for all of them. (Default value = None)\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n            name (str, optional): A name for identifying the model. (Default value = \"\")\n            last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n            last_activation (str, optional): Activation for the last layer (default is 'identity').\n            **kwargs\n\n        \"\"\"\n\n        super(DenseNetwork, self).__init__()\n\n        assert layers_units, \"Please, set a list of units for each layer\"\n\n        assert activations, (\n            \"Please, set a list of activation functions\" \"or a string for all of them.\"\n        )\n\n        # These activations support gain evaluation for the initial state\n        self.gain_supported_activations = [\"sigmoid\", \"tanh\", \"relu\", \"leaky_relu\"]\n\n        # Default attributes\n        self.layers_units = layers_units\n        self.input_size = input_size\n        self.output_size = output_size\n        self.normalization = normalization\n        self.name = name\n        self.last_bias = last_bias\n\n        # For extra and not ever required parameters\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n        # Getting up parameters from host\n        self._get_from_guest(activation=activations)\n\n        self.weights = list()\n\n        # The total number of layers includes the output layer\n        self.n_layers = len(self.layers_units) + 1\n\n        self.default_last_activation = last_activation\n\n        self.activations, self.activations_str = self._setup_activations(\n            activation=activations\n        )\n\n        self.initializations = [\n            self._determine_initialization(activation)\n            for activation in self.activations_str\n        ]\n\n        self.layers = self._setup_hidden_layers(last_bias=last_bias)\n\n        array_layers = self._numpy_layers()\n        n_layers = len(self.layers)\n\n        self.shapes = [item.shape for item in list(sum(array_layers, []))]\n\n        self.stitch_idx = self._make_stitch_idx()\n\n        self.layers_map = [[ll, ll + 1] for ll in range(0, 2 * n_layers, 2)]\n\n    def _calculate_gain(self, activation: str = \"Tanh\") -&gt; float:\n        \"\"\"It evaluates a multiplier coefficient, named as `gain`,\n        which is used to enhance the funcionality of each kind of activation\n        function.\n\n        Args:\n            activation (str, optional):  (Default value = \"Tanh\")\n\n        \"\"\"\n\n        if type(activation) is not str:\n            assert hasattr(\n                activation, \"name\"\n            ), f\"Activation object {type(activation)} must have attribute \u00b4name\u00b4.\"\n            name = getattr(activation, \"name\")\n        else:\n            name = activation\n\n        if name.lower() in self.gain_supported_activations:\n            return torch.nn.init.calculate_gain(name.lower())\n        else:\n            return 1\n\n    @staticmethod\n    def _determine_initialization(activation: str = \"Tanh\") -&gt; str:\n        \"\"\"It determines the most proper initialization method for each\n        activation function.\n\n        Args:\n            activation (str, optional): Activation function. (Default value = \"Tanh\")\n\n        \"\"\"\n\n        if type(activation) is not str:\n            assert hasattr(\n                activation, \"name\"\n            ), f\"Activation object {type(activation)} must have attribute \u00b4name\u00b4.\"\n            name = getattr(activation, \"name\")\n        else:\n            name = activation\n\n        if name in [\"ReLU\"]:\n            return \"kaiming\"\n        elif name == \"Siren\":\n            return \"siren\"\n        else:\n            return \"xavier\"\n\n    def _setup_layer(\n        self,\n        input_size: int = 0,\n        output_size: int = 0,\n        initialization: str = None,\n        bias: bool = True,\n        first_layer: bool = False,\n    ) -&gt; torch.nn.Linear:\n        \"\"\"\n\n        Args:\n            input_size (int, optional): Dimension of the input. (Default value = 0)\n            output_size (int, optional): Dimension of the output. (Default value = 0)\n            initialization (str, optional): Initialization method. (Default value = None)\n            bias (bool, optional): Using bias tensor or not. (Default value = True)\n            first_layer (bool, optional): Is this layer the first layer or not. (Default value = False)\n\n        \"\"\"\n\n        # It instantiates a linear operation\n        # f: y^l = f(x^(l-1)) = (W^l).dot(x^(l-1)) + b^l\n        layer = torch.nn.Linear(input_size, output_size, bias=bias)\n\n        if initialization == \"xavier\":\n            torch.nn.init.xavier_normal_(\n                layer.weight, gain=self._calculate_gain(self.activations_str[0])\n            )\n            return layer\n\n        # The Siren initialization requires some special consideration\n        elif initialization == \"siren\":\n            assert (\n                self.c is not None\n            ), \"When using siren, the parameter c must be defined.\"\n            assert (\n                self.omega_0 is not None\n            ), \"When using siren, the parameter omega_0 must be defined.\"\n\n            if first_layer == True:\n                m = 1 / input_size\n            else:\n                m = np.sqrt(self.c / input_size) / self.omega_0\n\n            torch.nn.init.trunc_normal_(layer.weight, a=-m, b=m)\n            b = np.sqrt(1 / input_size)\n            torch.nn.init.trunc_normal_(layer.bias, a=-b, b=b)\n            return layer\n\n        elif initialization == \"kaiming\":\n            return layer  # Kaiming is the default initialization in PyTorch\n\n        else:\n            print(\n                \"Initialization method still not implemented.\\\n                  Using Kaiming instead\"\n            )\n\n            return layer\n\n    # The forward step of the network\n    @as_tensor\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"It executes the forward step for the DenseNetwork.\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): The input tensor to be processed by DenseNetwork. (Default value = None)\n\n        \"\"\"\n\n        input_tensor_ = input_data\n\n        # TODO It can be done using the PyTorch Sequential object\n        for layer_id in range(len(self.layers)):\n            output_tensor_ = self.layers[layer_id](input_tensor_)\n            _output_tensor_ = self.activations[layer_id](output_tensor_)\n            input_tensor_ = _output_tensor_\n\n        output_tensor = input_tensor_\n\n        return output_tensor\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.DenseNetwork.__init__","title":"<code>__init__(layers_units=None, activations=None, input_size=None, output_size=None, normalization='bypass', name='', last_bias=True, last_activation='identity', **kwargs)</code>","text":"<p>Dense (fully-connected) neural network written in PyTorch</p> <p>Parameters:</p> Name Type Description Default <code>layers_units</code> <code>list</code> <p>List with the number of neurons for each layer. (Default value = None)</p> <code>None</code> <code>activations</code> <code>Union[list, str]</code> <p>List of activations for each layer or a single string</p> <code>None</code> <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>normalization</code> <code>str</code> <p>Kind of normalization used between two layers. (Default value = \"bypass\")</p> <code>'bypass'</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = \"\")</p> <code>''</code> <code>last_bias</code> <code>bool</code> <p>Using bias in the last layer or not. (Default value = True)</p> <code>True</code> <code>last_activation</code> <code>str</code> <p>Activation for the last layer (default is 'identity').</p> <code>'identity'</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    layers_units: list = None,\n    activations: Union[list, str] = None,\n    input_size: int = None,\n    output_size: int = None,\n    normalization: str = \"bypass\",\n    name: str = \"\",\n    last_bias: bool = True,\n    last_activation: str = \"identity\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"Dense (fully-connected) neural network written in PyTorch\n\n    Args:\n        layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n        activations (Union[list, str], optional): List of activations for each layer or a single string\n        informing the activation used for all of them. (Default value = None)\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n        name (str, optional): A name for identifying the model. (Default value = \"\")\n        last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n        last_activation (str, optional): Activation for the last layer (default is 'identity').\n        **kwargs\n\n    \"\"\"\n\n    super(DenseNetwork, self).__init__()\n\n    assert layers_units, \"Please, set a list of units for each layer\"\n\n    assert activations, (\n        \"Please, set a list of activation functions\" \"or a string for all of them.\"\n    )\n\n    # These activations support gain evaluation for the initial state\n    self.gain_supported_activations = [\"sigmoid\", \"tanh\", \"relu\", \"leaky_relu\"]\n\n    # Default attributes\n    self.layers_units = layers_units\n    self.input_size = input_size\n    self.output_size = output_size\n    self.normalization = normalization\n    self.name = name\n    self.last_bias = last_bias\n\n    # For extra and not ever required parameters\n    for k, v in kwargs.items():\n        setattr(self, k, v)\n\n    # Getting up parameters from host\n    self._get_from_guest(activation=activations)\n\n    self.weights = list()\n\n    # The total number of layers includes the output layer\n    self.n_layers = len(self.layers_units) + 1\n\n    self.default_last_activation = last_activation\n\n    self.activations, self.activations_str = self._setup_activations(\n        activation=activations\n    )\n\n    self.initializations = [\n        self._determine_initialization(activation)\n        for activation in self.activations_str\n    ]\n\n    self.layers = self._setup_hidden_layers(last_bias=last_bias)\n\n    array_layers = self._numpy_layers()\n    n_layers = len(self.layers)\n\n    self.shapes = [item.shape for item in list(sum(array_layers, []))]\n\n    self.stitch_idx = self._make_stitch_idx()\n\n    self.layers_map = [[ll, ll + 1] for ll in range(0, 2 * n_layers, 2)]\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.DenseNetwork.forward","title":"<code>forward(input_data=None)</code>","text":"<p>It executes the forward step for the DenseNetwork.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>The input tensor to be processed by DenseNetwork. (Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>@as_tensor\ndef forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"It executes the forward step for the DenseNetwork.\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): The input tensor to be processed by DenseNetwork. (Default value = None)\n\n    \"\"\"\n\n    input_tensor_ = input_data\n\n    # TODO It can be done using the PyTorch Sequential object\n    for layer_id in range(len(self.layers)):\n        output_tensor_ = self.layers[layer_id](input_tensor_)\n        _output_tensor_ = self.activations[layer_id](output_tensor_)\n        input_tensor_ = _output_tensor_\n\n    output_tensor = input_tensor_\n\n    return output_tensor\n</code></pre>"},{"location":"simulai_regression/#resdensenetwork","title":"ResDenseNetwork","text":"<p>             Bases: <code>DenseNetwork</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class ResDenseNetwork(DenseNetwork):\n    name = \"residualdense\"\n    engine = \"torch\"\n\n    def __init__(\n        self,\n        layers_units: list = None,\n        activations: Union[list, str] = None,\n        input_size: int = None,\n        output_size: int = None,\n        normalization: str = \"bypass\",\n        name: str = \"\",\n        last_bias: bool = True,\n        last_activation: str = \"identity\",\n        residual_size: int = 1,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Residual Dense (fully-connected) neural network written in PyTorch\n\n        Args:\n            layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n            activations (Union[list, str], optional): List of activations for each layer or a single string\n            informing the activation used for all of them. (Default value = None)\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n            name (str, optional): A name for identifying the model. (Default value = \"\")\n            last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n            last_activation (str, optional): Activation for the last layer (default is 'identity').\n            residual_size (int, optional): Size of the residual block. (Default value = 1)\n            **kwargs\n\n        \"\"\"\n\n        super().__init__(\n            layers_units=layers_units,\n            activations=activations,\n            input_size=input_size,\n            output_size=output_size,\n            normalization=normalization,\n            name=name,\n            last_bias=last_bias,\n            last_activation=last_activation,\n            **kwargs,\n        )\n\n        # Considering the activations layers\n        self.residual_size = 2 * residual_size\n        self.ratio = 0.5\n\n        # Excluding the input and output layers\n        merged_layers = self._merge(layer=self.layers, act=self.activations)\n\n        assert len(merged_layers[2:-2]) % self.residual_size == 0, (\n            \"The number of layers must be divisible\"\n            \" by the residual block size,\"\n            f\" but received {len(merged_layers)} and {residual_size}\"\n        )\n\n        self.n_residual_blocks = int(len(merged_layers[2:-2]) / self.residual_size)\n\n        sub_layers = [\n            item.tolist()\n            for item in np.split(np.array(merged_layers[2:-2]), self.n_residual_blocks)\n        ]\n\n        self.input_block = torch.nn.Sequential(*merged_layers[:2])\n        self.hidden_blocks = [torch.nn.Sequential(*item) for item in sub_layers]\n        self.output_block = torch.nn.Sequential(*merged_layers[-2:])\n\n    # Merging the layers into a reasonable sequence\n    def _merge(self, layer: list = None, act: list = None) -&gt; list:\n        \"\"\"It merges the dense layers and the activations into a single block.\n\n        Args:\n            layer (list, optional): List of dense layers. (Default value = None)\n            act (list, optional): List of activation functions. (Default value = None)\n\n        \"\"\"\n\n        merged_list = list()\n\n        for i, j in zip(layer, act):\n            merged_list.append(i)\n            merged_list.append(j)\n\n        return merged_list\n\n    def summary(self):\n        \"\"\"It prints a summary of the network.\"\"\"\n\n        super().summary()\n\n        print(\"Residual Blocks:\\n\")\n\n        print(self.input_block)\n        print(self.hidden_blocks)\n        print(self.output_block)\n\n    @as_tensor\n    def forward(\n        self, input_data: Union[torch.Tensor, np.ndarray] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional):  (Default value = None)\n\n        \"\"\"\n\n        input_tensor_ = input_data\n\n        input_tensor_ = self.input_block(input_tensor_)\n\n        for block in self.hidden_blocks:\n            output_tensor_ = self.ratio * (input_tensor_ + block(input_tensor_))\n\n            input_tensor_ = output_tensor_\n\n        output_tensor = self.output_block(input_tensor_)\n\n        return output_tensor\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ResDenseNetwork.__init__","title":"<code>__init__(layers_units=None, activations=None, input_size=None, output_size=None, normalization='bypass', name='', last_bias=True, last_activation='identity', residual_size=1, **kwargs)</code>","text":"<p>Residual Dense (fully-connected) neural network written in PyTorch</p> <p>Parameters:</p> Name Type Description Default <code>layers_units</code> <code>list</code> <p>List with the number of neurons for each layer. (Default value = None)</p> <code>None</code> <code>activations</code> <code>Union[list, str]</code> <p>List of activations for each layer or a single string</p> <code>None</code> <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>normalization</code> <code>str</code> <p>Kind of normalization used between two layers. (Default value = \"bypass\")</p> <code>'bypass'</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = \"\")</p> <code>''</code> <code>last_bias</code> <code>bool</code> <p>Using bias in the last layer or not. (Default value = True)</p> <code>True</code> <code>last_activation</code> <code>str</code> <p>Activation for the last layer (default is 'identity').</p> <code>'identity'</code> <code>residual_size</code> <code>int</code> <p>Size of the residual block. (Default value = 1)</p> <code>1</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    layers_units: list = None,\n    activations: Union[list, str] = None,\n    input_size: int = None,\n    output_size: int = None,\n    normalization: str = \"bypass\",\n    name: str = \"\",\n    last_bias: bool = True,\n    last_activation: str = \"identity\",\n    residual_size: int = 1,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Residual Dense (fully-connected) neural network written in PyTorch\n\n    Args:\n        layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n        activations (Union[list, str], optional): List of activations for each layer or a single string\n        informing the activation used for all of them. (Default value = None)\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n        name (str, optional): A name for identifying the model. (Default value = \"\")\n        last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n        last_activation (str, optional): Activation for the last layer (default is 'identity').\n        residual_size (int, optional): Size of the residual block. (Default value = 1)\n        **kwargs\n\n    \"\"\"\n\n    super().__init__(\n        layers_units=layers_units,\n        activations=activations,\n        input_size=input_size,\n        output_size=output_size,\n        normalization=normalization,\n        name=name,\n        last_bias=last_bias,\n        last_activation=last_activation,\n        **kwargs,\n    )\n\n    # Considering the activations layers\n    self.residual_size = 2 * residual_size\n    self.ratio = 0.5\n\n    # Excluding the input and output layers\n    merged_layers = self._merge(layer=self.layers, act=self.activations)\n\n    assert len(merged_layers[2:-2]) % self.residual_size == 0, (\n        \"The number of layers must be divisible\"\n        \" by the residual block size,\"\n        f\" but received {len(merged_layers)} and {residual_size}\"\n    )\n\n    self.n_residual_blocks = int(len(merged_layers[2:-2]) / self.residual_size)\n\n    sub_layers = [\n        item.tolist()\n        for item in np.split(np.array(merged_layers[2:-2]), self.n_residual_blocks)\n    ]\n\n    self.input_block = torch.nn.Sequential(*merged_layers[:2])\n    self.hidden_blocks = [torch.nn.Sequential(*item) for item in sub_layers]\n    self.output_block = torch.nn.Sequential(*merged_layers[-2:])\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ResDenseNetwork.forward","title":"<code>forward(input_data=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>(Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>@as_tensor\ndef forward(\n    self, input_data: Union[torch.Tensor, np.ndarray] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional):  (Default value = None)\n\n    \"\"\"\n\n    input_tensor_ = input_data\n\n    input_tensor_ = self.input_block(input_tensor_)\n\n    for block in self.hidden_blocks:\n        output_tensor_ = self.ratio * (input_tensor_ + block(input_tensor_))\n\n        input_tensor_ = output_tensor_\n\n    output_tensor = self.output_block(input_tensor_)\n\n    return output_tensor\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ResDenseNetwork.summary","title":"<code>summary()</code>","text":"<p>It prints a summary of the network.</p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def summary(self):\n    \"\"\"It prints a summary of the network.\"\"\"\n\n    super().summary()\n\n    print(\"Residual Blocks:\\n\")\n\n    print(self.input_block)\n    print(self.hidden_blocks)\n    print(self.output_block)\n</code></pre>"},{"location":"simulai_regression/#convexdensenetwork","title":"ConvexDenseNetwork","text":"<p>             Bases: <code>DenseNetwork</code></p> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>class ConvexDenseNetwork(DenseNetwork):\n    name = \"convexdense\"\n    engine = \"torch\"\n\n    def __init__(\n        self,\n        layers_units: list = None,\n        activations: Union[list, str] = None,\n        input_size: int = None,\n        output_size: int = None,\n        normalization: str = \"bypass\",\n        name: str = \"\",\n        last_bias: bool = True,\n        last_activation: str = \"identity\",\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Dense network with convex combinations in the hidden layers.\n        This architecture is useful when combined to the Improved Version of DeepONets\n\n        Args:\n            layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n            activations (Union[list, str], optional): List of activations for each layer or a single string\n            informing the activation used for all of them. (Default value = None)\n            input_size (int, optional): Dimension of the input. (Default value = None)\n            output_size (int, optional): Dimension of the output. (Default value = None)\n            normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n            name (str, optional): A name for identifying the model. (Default value = \"\")\n            last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n            last_activation (str, optional): Activation for the last layer (default is 'identity').\n            **kwargs\n\n        \"\"\"\n\n        self.hidden_size = None\n        assert self._check_regular_net(layers_units=layers_units), (\n            \"All the hidden layers must be equal in\" \"a Convex Dense Network.\"\n        )\n\n        super().__init__(\n            layers_units=layers_units,\n            activations=activations,\n            input_size=input_size,\n            output_size=output_size,\n            normalization=normalization,\n            name=name,\n            last_bias=last_bias,\n            last_activation=last_activation,\n            **kwargs,\n        )\n\n    def _check_regular_net(self, layers_units: list) -&gt; bool:\n        \"\"\"It checks if all the layers has the same number of neurons.\n\n        Args:\n            layers_units (list):\n\n        \"\"\"\n\n        mean = int(sum(layers_units) / len(layers_units))\n        self.hidden_size = mean\n\n        if len([True for j in layers_units if j == mean]) == len(layers_units):\n            return True\n        else:\n            return False\n\n    @as_tensor\n    def forward(\n        self,\n        input_data: Union[torch.Tensor, np.ndarray] = None,\n        u: Union[torch.Tensor, np.ndarray] = None,\n        v: Union[torch.Tensor, np.ndarray] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n\n        Args:\n            input_data (Union[torch.Tensor, np.ndarray], optional): Input data to be processed using ConvexDenseNetwork. (Default value = None)\n            u (Union[torch.Tensor, np.ndarray], optional): Input generated by the first auxiliar encoder (external model). (Default value = None)\n            v (Union[torch.Tensor, np.ndarray], optional): Input generated by the second auxiliar encoder (external model). (Default value = None)\n\n        \"\"\"\n\n        input_tensor_ = input_data\n\n        # The first layer operation has no difference from the Vanilla one\n        first_output = self.activations[0](self.layers[0](input_tensor_))\n\n        input_tensor_ = first_output\n\n        layers_hidden = self.layers[1:-1]\n        activations_hidden = self.activations[1:-1]\n\n        for layer_id in range(len(layers_hidden)):\n            output_tensor_ = layers_hidden[layer_id](input_tensor_)\n            z = activations_hidden[layer_id](output_tensor_)\n            _output_tensor_ = (1 - z) * u + z * v\n\n            input_tensor_ = _output_tensor_\n\n        # The last layer operation too\n        last_output = self.activations[-1](self.layers[-1](input_tensor_))\n        output_tensor = last_output\n\n        return output_tensor\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ConvexDenseNetwork.__init__","title":"<code>__init__(layers_units=None, activations=None, input_size=None, output_size=None, normalization='bypass', name='', last_bias=True, last_activation='identity', **kwargs)</code>","text":"<p>Dense network with convex combinations in the hidden layers. This architecture is useful when combined to the Improved Version of DeepONets</p> <p>Parameters:</p> Name Type Description Default <code>layers_units</code> <code>list</code> <p>List with the number of neurons for each layer. (Default value = None)</p> <code>None</code> <code>activations</code> <code>Union[list, str]</code> <p>List of activations for each layer or a single string</p> <code>None</code> <code>input_size</code> <code>int</code> <p>Dimension of the input. (Default value = None)</p> <code>None</code> <code>output_size</code> <code>int</code> <p>Dimension of the output. (Default value = None)</p> <code>None</code> <code>normalization</code> <code>str</code> <p>Kind of normalization used between two layers. (Default value = \"bypass\")</p> <code>'bypass'</code> <code>name</code> <code>str</code> <p>A name for identifying the model. (Default value = \"\")</p> <code>''</code> <code>last_bias</code> <code>bool</code> <p>Using bias in the last layer or not. (Default value = True)</p> <code>True</code> <code>last_activation</code> <code>str</code> <p>Activation for the last layer (default is 'identity').</p> <code>'identity'</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>def __init__(\n    self,\n    layers_units: list = None,\n    activations: Union[list, str] = None,\n    input_size: int = None,\n    output_size: int = None,\n    normalization: str = \"bypass\",\n    name: str = \"\",\n    last_bias: bool = True,\n    last_activation: str = \"identity\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"Dense network with convex combinations in the hidden layers.\n    This architecture is useful when combined to the Improved Version of DeepONets\n\n    Args:\n        layers_units (list, optional): List with the number of neurons for each layer. (Default value = None)\n        activations (Union[list, str], optional): List of activations for each layer or a single string\n        informing the activation used for all of them. (Default value = None)\n        input_size (int, optional): Dimension of the input. (Default value = None)\n        output_size (int, optional): Dimension of the output. (Default value = None)\n        normalization (str, optional): Kind of normalization used between two layers. (Default value = \"bypass\")\n        name (str, optional): A name for identifying the model. (Default value = \"\")\n        last_bias (bool, optional): Using bias in the last layer or not. (Default value = True)\n        last_activation (str, optional): Activation for the last layer (default is 'identity').\n        **kwargs\n\n    \"\"\"\n\n    self.hidden_size = None\n    assert self._check_regular_net(layers_units=layers_units), (\n        \"All the hidden layers must be equal in\" \"a Convex Dense Network.\"\n    )\n\n    super().__init__(\n        layers_units=layers_units,\n        activations=activations,\n        input_size=input_size,\n        output_size=output_size,\n        normalization=normalization,\n        name=name,\n        last_bias=last_bias,\n        last_activation=last_activation,\n        **kwargs,\n    )\n</code></pre>"},{"location":"simulai_regression/#simulai.regression.ConvexDenseNetwork.forward","title":"<code>forward(input_data=None, u=None, v=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Union[Tensor, ndarray]</code> <p>Input data to be processed using ConvexDenseNetwork. (Default value = None)</p> <code>None</code> <code>u</code> <code>Union[Tensor, ndarray]</code> <p>Input generated by the first auxiliar encoder (external model). (Default value = None)</p> <code>None</code> <code>v</code> <code>Union[Tensor, ndarray]</code> <p>Input generated by the second auxiliar encoder (external model). (Default value = None)</p> <code>None</code> Source code in <code>simulai/regression/_pytorch/_dense.py</code> <pre><code>@as_tensor\ndef forward(\n    self,\n    input_data: Union[torch.Tensor, np.ndarray] = None,\n    u: Union[torch.Tensor, np.ndarray] = None,\n    v: Union[torch.Tensor, np.ndarray] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n\n    Args:\n        input_data (Union[torch.Tensor, np.ndarray], optional): Input data to be processed using ConvexDenseNetwork. (Default value = None)\n        u (Union[torch.Tensor, np.ndarray], optional): Input generated by the first auxiliar encoder (external model). (Default value = None)\n        v (Union[torch.Tensor, np.ndarray], optional): Input generated by the second auxiliar encoder (external model). (Default value = None)\n\n    \"\"\"\n\n    input_tensor_ = input_data\n\n    # The first layer operation has no difference from the Vanilla one\n    first_output = self.activations[0](self.layers[0](input_tensor_))\n\n    input_tensor_ = first_output\n\n    layers_hidden = self.layers[1:-1]\n    activations_hidden = self.activations[1:-1]\n\n    for layer_id in range(len(layers_hidden)):\n        output_tensor_ = layers_hidden[layer_id](input_tensor_)\n        z = activations_hidden[layer_id](output_tensor_)\n        _output_tensor_ = (1 - z) * u + z * v\n\n        input_tensor_ = _output_tensor_\n\n    # The last layer operation too\n    last_output = self.activations[-1](self.layers[-1](input_tensor_))\n    output_tensor = last_output\n\n    return output_tensor\n</code></pre>"},{"location":"simulai_residuals/","title":"simulai.residuals","text":"<p>             Bases: <code>Module</code></p> <p>The SymbolicOperatorClass is a class that constructs tensor operators using symbolic expressions written in PyTorch.</p> <p>Returns:</p> Name Type Description <code>object</code> <p>An instance of the SymbolicOperatorClass.</p> Source code in <code>simulai/residuals/_pytorch_residuals.py</code> <pre><code>class SymbolicOperator(torch.nn.Module):\n    \"\"\"The SymbolicOperatorClass is a class that constructs tensor operators using symbolic expressions written in PyTorch.\n\n\n    Returns:\n        object: An instance of the SymbolicOperatorClass.\n    \"\"\"\n\n    def __init__(\n        self,\n        expressions: List[Union[sympy.Expr, str]] = None,\n        input_vars: List[Union[sympy.Symbol, str]] = None,\n        output_vars: List[Union[sympy.Symbol, str]] = None,\n        function: callable = None,\n        gradient: callable = None,\n        keys: str = None,\n        inputs_key=None,\n        constants: dict = None,\n        trainable_parameters: dict = None,\n        external_functions: dict = dict(),\n        processing: str = \"serial\",\n        device: str = \"cpu\",\n        engine: str = \"torch\",\n        auxiliary_expressions: list = None,\n    ) -&gt; None:\n        if engine == \"torch\":\n            super(SymbolicOperator, self).__init__()\n        else:\n            pass\n\n        self.engine = importlib.import_module(engine)\n\n        self.constants = constants\n\n        if trainable_parameters is not None:\n            self.trainable_parameters = trainable_parameters\n\n        else:\n            self.trainable_parameters = dict()\n\n        self.external_functions = external_functions\n        self.processing = processing\n        self.periodic_bc_protected_key = \"periodic\"\n\n        self.protected_funcs = [\"cos\", \"sin\", \"sqrt\", \"exp\"]\n        self.protected_operators = [\"L\", \"Div\", \"Identity\", \"Kronecker\"]\n\n        self.protected_funcs_subs = self._construct_protected_functions()\n        self.protected_operators_subs = self._construct_implict_operators()\n\n        # Configuring the device to be used during the fitting process\n        if device == \"gpu\":\n            if not torch.cuda.is_available():\n                print(\"Warning: There is no GPU available, using CPU instead.\")\n                device = \"cpu\"\n            else:\n                device = \"cuda\"\n                print(\"Using GPU.\")\n        elif device == \"cpu\":\n            print(\"Using CPU.\")\n        else:\n            raise Exception(f\"The device must be cpu or gpu, but received: {device}\")\n\n        self.device = device\n\n        self.expressions = [self._parse_expression(expr=expr) for expr in expressions]\n\n        if isinstance(auxiliary_expressions, dict):\n            self.auxiliary_expressions = {\n                key: self._parse_expression(expr=expr)\n                for key, expr in auxiliary_expressions.items()\n            }\n        else:\n            self.auxiliary_expressions = auxiliary_expressions\n\n        self.input_vars = [self._parse_variable(var=var) for var in input_vars]\n        self.output_vars = [self._parse_variable(var=var) for var in output_vars]\n\n        self.input_names = [var.name for var in self.input_vars]\n        self.output_names = [var.name for var in self.output_vars]\n        self.keys = keys\n\n        if inputs_key != None:\n            self.inputs_key = self._parse_inputs_key(inputs_key=inputs_key)\n        else:\n            self.inputs_key = inputs_key\n\n        self.all_vars = self.input_vars + self.output_vars\n\n        if self.inputs_key is not None:\n            self.forward = self._forward_dict\n        else:\n            self.forward = self._forward_tensor\n\n        self.function = function\n        self.diff_symbol = D\n\n        self.output = None\n\n        self.f_expressions = list()\n        self.g_expressions = dict()\n\n        self.feed_vars = None\n\n        for name in self.output_names:\n            setattr(self, name, None)\n\n        # Defining functions for returning each variable of the regression\n        # function\n        for index, name in enumerate(self.output_names):\n            setattr(\n                self,\n                name,\n                lambda data: self.function.forward(input_data=data)[..., index][\n                    ..., None\n                ],\n            )\n\n        # If no external gradient is provided, use the core gradient evaluator\n        if gradient is None:\n            gradient_function = self.gradient\n        else:\n            gradient_function = gradient\n\n        subs = {self.diff_symbol.name: gradient_function}\n        subs.update(self.external_functions)\n        subs.update(self.protected_funcs_subs)\n\n        for expr in self.expressions:\n            if not callable(expr):\n                f_expr = sympy.lambdify(self.all_vars, expr, subs)\n            else:\n                f_expr = expr\n\n            self.f_expressions.append(f_expr)\n\n        if self.auxiliary_expressions is not None:\n            for key, expr in self.auxiliary_expressions.items():\n                if not callable(expr):\n                    g_expr = sympy.lambdify(self.all_vars, expr, subs)\n                else:\n                    g_expr = expr\n\n                self.g_expressions[key] = g_expr\n\n        # Method for executing the expressions evaluation\n        if self.processing == \"serial\":\n            self.process_expression = self._process_expression_serial\n        else:\n            raise Exception(f\"Processing case {self.processing} not supported.\")\n\n    def _construct_protected_functions(self):\n        \"\"\"This function creates a dictionary of protected functions from the engine object attribute.\n\n\n        Returns:\n            dict: A dictionary of function names and their corresponding function objects.\n        \"\"\"\n        protected_funcs = {\n            func: getattr(self.engine, func) for func in self.protected_funcs\n        }\n\n        return protected_funcs\n\n    def _construct_implict_operators(self):\n        \"\"\"This function creates a dictionary of protected operators from the operators engine module.\n\n\n        Returns:\n            dict: A dictionary of operator names and their corresponding function objects.\n        \"\"\"\n        operators_engine = importlib.import_module(\"simulai.tokens\")\n\n        protected_operators = {\n            func: getattr(operators_engine, func) for func in self.protected_operators\n        }\n\n        return protected_operators\n\n    def _parse_key_interval(self, intv: str) -&gt; List:\n        begin, end = intv.split(\",\")\n\n        end = int(end[:-1])\n        begin = int(begin)\n        end = int(end + 1)\n\n        return np.arange(begin, end).astype(int).tolist()\n\n    def _parse_inputs_key(self, inputs_key: str = None) -&gt; dict:\n        # Sentences separator: '|'\n        sep = \"|\"\n        # Index identifier: ':'\n        inx = \":\"\n        # Interval identifier\n        intv = \"[\"\n\n        # Removing possible spaces in the inputs_key string\n        inputs_key = inputs_key.replace(\" \", \"\")\n\n        try:\n            split_components = inputs_key.split(sep)\n        except ValueError:\n            split_components = inputs_key\n\n        keys_dict = dict()\n        for s in split_components:\n            try:\n                if len(s.split(inx)) &gt; 1:\n                    key, index = s.split(inx)\n\n                    if not key in keys_dict:\n                        keys_dict[key] = list()\n                        keys_dict[key].append(int(index))\n\n                    else:\n                        keys_dict[key].append(int(index))\n\n                elif len(s.split(intv)) &gt; 1:\n                    key, interval_str = s.split(intv)\n                    interval = self._parse_key_interval(interval_str)\n                    keys_dict[key] = interval\n\n                else:\n                    raise ValueError\n\n            except ValueError:\n                keys_dict[s] = -1\n\n        return keys_dict\n\n    def _collect_data_from_inputs_list(self, inputs_list: dict = None) -&gt; list:\n        data = list()\n        for k, v in self.inputs_key.items():\n            if v == -1:\n                if inputs_list[k].shape[1] == 1:\n                    data_ = [inputs_list[k]]\n                else:\n                    data_ = list(torch.split(inputs_list[k], 1, dim=1))\n            else:\n                data_ = [inputs_list[k][:, i : i + 1] for i in v]\n\n            data += data_\n\n        return data\n\n    def _parse_expression(self, expr=Union[sympy.Expr, str]) -&gt; sympy.Expr:\n        \"\"\"Parses the input expression and returns a SymPy expression.\n\n        Args:\n            expr (Union[sympy.Expr, str], optional, optional): The expression to parse, by default None. It can either be a SymPy expression or a string.\n\n        Returns:\n            sympy.Expr: The parsed SymPy expression.\n\n        Raises:\n            Exception: If the `constants` attribute is not defined, and the input expression is a string.\n\n\n        \"\"\"\n        if isinstance(expr, str):\n            try:\n                expr_ = sympify(\n                    expr, locals=self.protected_operators_subs, evaluate=False\n                )\n\n                if self.constants is not None:\n                    expr_ = expr_.subs(self.constants)\n                if self.trainable_parameters is not None:\n                    expr_ = expr_.subs(self.trainable_parameters)\n            except ValueError:\n                if self.constants is not None:\n                    _expr = expr\n                    for key, value in self.constants.items():\n                        _expr = _expr.replace(key, str(value))\n\n                    expr_ = parse_expr(_expr, evaluate=0)\n                else:\n                    raise Exception(\"It is necessary to define a constants dict.\")\n        elif callable(expr):\n            expr_ = expr\n        else:\n            if self.constants is not None:\n                expr_ = expr.subs(self.constants)\n            else:\n                expr_ = expr\n\n        return expr_\n\n    def _parse_variable(self, var=Union[sympy.Symbol, str]) -&gt; sympy.Symbol:\n        \"\"\"Parse the input variable and return a SymPy Symbol.\n\n        Args:\n            var (Union[sympy.Symbol, str], optional, optional): The input variable, either a SymPy Symbol or a string. (Default value = Union[sympy.Symbol, str])\n\n        Returns:\n            sympy.Symbol: A SymPy Symbol representing the input variable.\n\n        \"\"\"\n        if isinstance(var, str):\n            return sympy.Symbol(var)\n        else:\n            return var\n\n    def _forward_tensor(self, input_data: torch.Tensor = None) -&gt; torch.Tensor:\n        \"\"\"Forward the input tensor through the function.\n\n        Args:\n            input_data (torch.Tensor, optional): The input tensor. (Default value = None)\n\n        Returns:\n            torch.Tensor: The output tensor after forward pass.\n\n        \"\"\"\n        return self.function.forward(input_data=input_data)\n\n    def _forward_dict(self, input_data: dict = None) -&gt; torch.Tensor:\n        \"\"\"Forward the input dictionary through the function.\n\n        Args:\n            input_data (dict, optional): The input dictionary. (Default value = None)\n\n        Returns:\n            torch.Tensor: The output tensor after forward pass.\n\n        \"\"\"\n        return self.function.forward(**input_data)\n\n    def _process_expression_serial(self, feed_vars: dict = None) -&gt; List[torch.Tensor]:\n        \"\"\"Process the expression list serially using the given feed variables.\n\n        Args:\n            feed_vars (dict, optional): The feed variables. (Default value = None)\n\n        Returns:\n            List[torch.Tensor]: A list of tensors after evaluating the expressions serially.\n\n        \"\"\"\n        return [f(**feed_vars).to(self.device) for f in self.f_expressions]\n\n    def _process_expression_individual(\n        self, index: int = None, feed_vars: dict = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Evaluates a single expression specified by index from the f_expressions list with given feed variables.\n\n        Args:\n            index (int, optional): Index of the expression to be evaluated, by default None\n            feed_vars (dict, optional): Dictionary of feed variables, by default None\n\n        Returns:\n            torch.Tensor: Result of evaluating the specified expression with given feed variables\n\n        \"\"\"\n        return self.f_expressions[index](**feed_vars).to(self.device)\n\n    def __call__(\n        self, inputs_data: Union[np.ndarray, dict] = None\n    ) -&gt; List[torch.Tensor]:\n        \"\"\"Evaluate the symbolic expression.\n\n        This function takes either a numpy array or a dictionary of numpy arrays as input.\n\n        Args:\n            inputs_data (Union[np.ndarray, dict], optional): Union (Default value = None)\n\n        Returns:\n            List[torch.Tensor]: List[torch.Tensor]: A list of tensors containing the evaluated expressions.\n\n            Raises:\n\n        Raises:\n            does: not match with the inputs_key attribute\n\n        \"\"\"\n        constructor = MakeTensor(\n            input_names=self.input_names, output_names=self.output_names\n        )\n\n        inputs_list = constructor(input_data=inputs_data, device=self.device)\n\n        output = self.forward(input_data=inputs_list)\n\n        output = output.to(self.device)  # TODO Check if it is necessary\n\n        outputs_list = torch.split(output, 1, dim=-1)\n\n        outputs = {key: value for key, value in zip(self.output_names, outputs_list)}\n\n        if type(inputs_list) is list:\n            inputs = {key: value for key, value in zip(self.input_names, inputs_list)}\n\n        elif type(inputs_list) is dict:\n            assert (\n                self.inputs_key is not None\n            ), \"If inputs_list is dict, \\\n                it is necessary to provide\\\n                a key.\"\n\n            inputs_list = self._collect_data_from_inputs_list(inputs_list=inputs_list)\n\n            inputs = {key: value for key, value in zip(self.input_names, inputs_list)}\n        else:\n            raise Exception(\n                f\"Format {type(inputs_list)} not supported \\\n                            for inputs_list\"\n            )\n\n        feed_vars = {**outputs, **inputs}\n\n        # It returns a list of tensors containing the expressions\n        # evaluated over a domain\n        return self.process_expression(feed_vars=feed_vars)\n\n    def eval_expression(self, key, inputs_list):\n        \"\"\"This function evaluates an expression stored in the class attribute 'g_expressions' using the inputs in 'inputs_list'. If the expression has a periodic boundary condition, the function evaluates the expression at the lower and upper boundaries and returns the difference. If the inputs are provided as a list, they are split into individual tensors and stored in a dictionary with the keys as the input names. If the inputs are provided as an np.ndarray, they are converted to tensors and split along the second axis. If the inputs are provided as a dict, they are extracted using the 'inputs_key' attribute. The inputs, along with the outputs obtained from running the function, are then passed as arguments to the expression using the 'g(**feed_vars)' syntax.\n\n        Args:\n            key (str): the key used to retrieve the expression from the 'g_expressions' attribute\n            inputs_list (list): either a list of arrays, an np.ndarray, or a dict containing the inputs to the function\n\n        Returns:\n            the result of evaluating the expression using the inputs.:\n\n        \"\"\"\n\n        try:\n            g = self.g_expressions.get(key)\n        except:\n            raise Exception(f\"The expression {key} does not exist.\")\n\n        # Periodic boundary conditions\n        if self.periodic_bc_protected_key in key:\n            assert isinstance(inputs_list, list), (\n                \"When a periodic boundary expression is used,\"\n                \" the input must be a list of arrays.\"\n            )\n\n            # Lower bound\n            constructor = MakeTensor(\n                input_names=self.input_names, output_names=self.output_names\n            )\n\n            tensors_list = constructor(input_data=inputs_list[0], device=self.device)\n\n            inputs_L = {\n                key: value for key, value in zip(self.input_names, tensors_list)\n            }\n\n            output = self.function.forward(input_data=tensors_list)\n\n            output = output.to(self.device)  # TODO Check if it is necessary\n\n            outputs_list = torch.split(output, 1, dim=-1)\n\n            outputs_L = {\n                key: value for key, value in zip(self.output_names, outputs_list)\n            }\n\n            feed_vars_L = {**inputs_L, **outputs_L}\n\n            # Upper bound\n            constructor = MakeTensor(\n                input_names=self.input_names, output_names=self.output_names\n            )\n\n            tensors_list = constructor(input_data=inputs_list[-1], device=self.device)\n\n            inputs_U = {\n                key: value for key, value in zip(self.input_names, tensors_list)\n            }\n\n            output = self.function.forward(input_data=tensors_list)\n\n            output = output.to(self.device)  # TODO Check if it is necessary\n\n            outputs_list = torch.split(output, 1, dim=-1)\n\n            outputs_U = {\n                key: value for key, value in zip(self.output_names, outputs_list)\n            }\n\n            feed_vars_U = {**inputs_U, **outputs_U}\n\n            # Evaluating the boundaries equality\n            return g(**feed_vars_L) - g(**feed_vars_U)\n\n        # The non-periodic cases\n        else:\n            constructor = MakeTensor(\n                input_names=self.input_names, output_names=self.output_names\n            )\n\n            inputs_list = constructor(input_data=inputs_list, device=self.device)\n\n            output = self.function.forward(input_data=inputs_list)\n\n            outputs_list = torch.split(output, 1, dim=-1)\n\n            outputs = {\n                key: value for key, value in zip(self.output_names, outputs_list)\n            }\n\n            if type(inputs_list) is list:\n                inputs = {\n                    key: value for key, value in zip(self.input_names, inputs_list)\n                }\n\n            elif type(inputs_list) is np.ndarray:\n                arrays_list = np.split(inputs_list, inputs_list.shape[1], axis=1)\n                tensors_list = [torch.from_numpy(arr) for arr in arrays_list]\n\n                for t in tensors_list:\n                    t.requires_grad = True\n\n                inputs = {\n                    key: value for key, value in zip(self.input_names, tensors_list)\n                }\n\n            elif type(inputs_list) is dict:\n                assert (\n                    self.inputs_key is not None\n                ), \"If inputs_list is dict, \\\n                                                     it is necessary to provide\\\n                                                     a key.\"\n\n                inputs = {\n                    key: value\n                    for key, value in zip(\n                        self.input_names, inputs_list[self.inputs_key]\n                    )\n                }\n\n            else:\n                raise Exception(\n                    f\"Format {type(inputs_list)} not supported \\\n                                for inputs_list\"\n                )\n\n            feed_vars = {**inputs, **outputs}\n\n            return g(**feed_vars)\n\n    @staticmethod\n    def gradient(feature, param):\n        \"\"\"Calculates the gradient of the given feature with respect to the given parameter.\n\n        Args:\n            feature (torch.Tensor): Tensor with the input feature.\n            param (torch.Tensor): Tensor with the parameter to calculate the gradient with respect to.\n\n        Returns:\n            torch.Tensor: Tensor with the gradient of the feature with respect to the given parameter.\n        Example::\n\n            &gt;&gt;&gt; feature = torch.tensor([1, 2, 3], dtype=torch.float32)\n            &gt;&gt;&gt; param = torch.tensor([2, 3, 4], dtype=torch.float32)\n            &gt;&gt;&gt; gradient(feature, param)\n            tensor([1., 1., 1.], grad_fn=&lt;AddBackward0&gt;)\n        \"\"\"\n        grad_ = grad(\n            feature,\n            param,\n            grad_outputs=torch.ones_like(feature),\n            create_graph=True,\n            allow_unused=True,\n            retain_graph=True,\n        )\n\n        return grad_[0]\n\n    def jac(self, inputs):\n        \"\"\"Calculates the Jacobian of the forward function of the model with respect to its inputs.\n\n        Args:\n            inputs (torch.Tensor): Tensor with the input data to the forward function.\n\n        Returns:\n            torch.Tensor: Tensor with the Jacobian of the forward function with respect to its inputs.\n        Example::\n\n            &gt;&gt;&gt; inputs = torch.tensor([[1, 2, 3], [2, 3, 4]], dtype=torch.float32)\n            &gt;&gt;&gt; jac(inputs)\n            tensor([[1., 1., 1.],\n                    [1., 1., 1.]], grad_fn=&lt;MulBackward0&gt;)\n        \"\"\"\n\n        def inner(inputs):\n            return self.forward(input_data=inputs)\n\n        return jacobian(inner, inputs)\n</code></pre>"},{"location":"simulai_residuals/#simulai.residuals.SymbolicOperator.__call__","title":"<code>__call__(inputs_data=None)</code>","text":"<p>Evaluate the symbolic expression.</p> <p>This function takes either a numpy array or a dictionary of numpy arrays as input.</p> <p>Parameters:</p> Name Type Description Default <code>inputs_data</code> <code>Union[ndarray, dict]</code> <p>Union (Default value = None)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>List[Tensor]</code> <p>List[torch.Tensor]: List[torch.Tensor]: A list of tensors containing the evaluated expressions.</p> <code>Raises</code> <code>List[Tensor]</code> <p>Raises:</p> Type Description <code>does</code> <p>not match with the inputs_key attribute</p> Source code in <code>simulai/residuals/_pytorch_residuals.py</code> <pre><code>def __call__(\n    self, inputs_data: Union[np.ndarray, dict] = None\n) -&gt; List[torch.Tensor]:\n    \"\"\"Evaluate the symbolic expression.\n\n    This function takes either a numpy array or a dictionary of numpy arrays as input.\n\n    Args:\n        inputs_data (Union[np.ndarray, dict], optional): Union (Default value = None)\n\n    Returns:\n        List[torch.Tensor]: List[torch.Tensor]: A list of tensors containing the evaluated expressions.\n\n        Raises:\n\n    Raises:\n        does: not match with the inputs_key attribute\n\n    \"\"\"\n    constructor = MakeTensor(\n        input_names=self.input_names, output_names=self.output_names\n    )\n\n    inputs_list = constructor(input_data=inputs_data, device=self.device)\n\n    output = self.forward(input_data=inputs_list)\n\n    output = output.to(self.device)  # TODO Check if it is necessary\n\n    outputs_list = torch.split(output, 1, dim=-1)\n\n    outputs = {key: value for key, value in zip(self.output_names, outputs_list)}\n\n    if type(inputs_list) is list:\n        inputs = {key: value for key, value in zip(self.input_names, inputs_list)}\n\n    elif type(inputs_list) is dict:\n        assert (\n            self.inputs_key is not None\n        ), \"If inputs_list is dict, \\\n            it is necessary to provide\\\n            a key.\"\n\n        inputs_list = self._collect_data_from_inputs_list(inputs_list=inputs_list)\n\n        inputs = {key: value for key, value in zip(self.input_names, inputs_list)}\n    else:\n        raise Exception(\n            f\"Format {type(inputs_list)} not supported \\\n                        for inputs_list\"\n        )\n\n    feed_vars = {**outputs, **inputs}\n\n    # It returns a list of tensors containing the expressions\n    # evaluated over a domain\n    return self.process_expression(feed_vars=feed_vars)\n</code></pre>"},{"location":"simulai_residuals/#simulai.residuals.SymbolicOperator.eval_expression","title":"<code>eval_expression(key, inputs_list)</code>","text":"<p>This function evaluates an expression stored in the class attribute 'g_expressions' using the inputs in 'inputs_list'. If the expression has a periodic boundary condition, the function evaluates the expression at the lower and upper boundaries and returns the difference. If the inputs are provided as a list, they are split into individual tensors and stored in a dictionary with the keys as the input names. If the inputs are provided as an np.ndarray, they are converted to tensors and split along the second axis. If the inputs are provided as a dict, they are extracted using the 'inputs_key' attribute. The inputs, along with the outputs obtained from running the function, are then passed as arguments to the expression using the 'g(**feed_vars)' syntax.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>the key used to retrieve the expression from the 'g_expressions' attribute</p> required <code>inputs_list</code> <code>list</code> <p>either a list of arrays, an np.ndarray, or a dict containing the inputs to the function</p> required <p>Returns:</p> Type Description <p>the result of evaluating the expression using the inputs.:</p> Source code in <code>simulai/residuals/_pytorch_residuals.py</code> <pre><code>def eval_expression(self, key, inputs_list):\n    \"\"\"This function evaluates an expression stored in the class attribute 'g_expressions' using the inputs in 'inputs_list'. If the expression has a periodic boundary condition, the function evaluates the expression at the lower and upper boundaries and returns the difference. If the inputs are provided as a list, they are split into individual tensors and stored in a dictionary with the keys as the input names. If the inputs are provided as an np.ndarray, they are converted to tensors and split along the second axis. If the inputs are provided as a dict, they are extracted using the 'inputs_key' attribute. The inputs, along with the outputs obtained from running the function, are then passed as arguments to the expression using the 'g(**feed_vars)' syntax.\n\n    Args:\n        key (str): the key used to retrieve the expression from the 'g_expressions' attribute\n        inputs_list (list): either a list of arrays, an np.ndarray, or a dict containing the inputs to the function\n\n    Returns:\n        the result of evaluating the expression using the inputs.:\n\n    \"\"\"\n\n    try:\n        g = self.g_expressions.get(key)\n    except:\n        raise Exception(f\"The expression {key} does not exist.\")\n\n    # Periodic boundary conditions\n    if self.periodic_bc_protected_key in key:\n        assert isinstance(inputs_list, list), (\n            \"When a periodic boundary expression is used,\"\n            \" the input must be a list of arrays.\"\n        )\n\n        # Lower bound\n        constructor = MakeTensor(\n            input_names=self.input_names, output_names=self.output_names\n        )\n\n        tensors_list = constructor(input_data=inputs_list[0], device=self.device)\n\n        inputs_L = {\n            key: value for key, value in zip(self.input_names, tensors_list)\n        }\n\n        output = self.function.forward(input_data=tensors_list)\n\n        output = output.to(self.device)  # TODO Check if it is necessary\n\n        outputs_list = torch.split(output, 1, dim=-1)\n\n        outputs_L = {\n            key: value for key, value in zip(self.output_names, outputs_list)\n        }\n\n        feed_vars_L = {**inputs_L, **outputs_L}\n\n        # Upper bound\n        constructor = MakeTensor(\n            input_names=self.input_names, output_names=self.output_names\n        )\n\n        tensors_list = constructor(input_data=inputs_list[-1], device=self.device)\n\n        inputs_U = {\n            key: value for key, value in zip(self.input_names, tensors_list)\n        }\n\n        output = self.function.forward(input_data=tensors_list)\n\n        output = output.to(self.device)  # TODO Check if it is necessary\n\n        outputs_list = torch.split(output, 1, dim=-1)\n\n        outputs_U = {\n            key: value for key, value in zip(self.output_names, outputs_list)\n        }\n\n        feed_vars_U = {**inputs_U, **outputs_U}\n\n        # Evaluating the boundaries equality\n        return g(**feed_vars_L) - g(**feed_vars_U)\n\n    # The non-periodic cases\n    else:\n        constructor = MakeTensor(\n            input_names=self.input_names, output_names=self.output_names\n        )\n\n        inputs_list = constructor(input_data=inputs_list, device=self.device)\n\n        output = self.function.forward(input_data=inputs_list)\n\n        outputs_list = torch.split(output, 1, dim=-1)\n\n        outputs = {\n            key: value for key, value in zip(self.output_names, outputs_list)\n        }\n\n        if type(inputs_list) is list:\n            inputs = {\n                key: value for key, value in zip(self.input_names, inputs_list)\n            }\n\n        elif type(inputs_list) is np.ndarray:\n            arrays_list = np.split(inputs_list, inputs_list.shape[1], axis=1)\n            tensors_list = [torch.from_numpy(arr) for arr in arrays_list]\n\n            for t in tensors_list:\n                t.requires_grad = True\n\n            inputs = {\n                key: value for key, value in zip(self.input_names, tensors_list)\n            }\n\n        elif type(inputs_list) is dict:\n            assert (\n                self.inputs_key is not None\n            ), \"If inputs_list is dict, \\\n                                                 it is necessary to provide\\\n                                                 a key.\"\n\n            inputs = {\n                key: value\n                for key, value in zip(\n                    self.input_names, inputs_list[self.inputs_key]\n                )\n            }\n\n        else:\n            raise Exception(\n                f\"Format {type(inputs_list)} not supported \\\n                            for inputs_list\"\n            )\n\n        feed_vars = {**inputs, **outputs}\n\n        return g(**feed_vars)\n</code></pre>"},{"location":"simulai_residuals/#simulai.residuals.SymbolicOperator.gradient","title":"<code>gradient(feature, param)</code>  <code>staticmethod</code>","text":"<p>Calculates the gradient of the given feature with respect to the given parameter.</p> <p>Parameters:</p> Name Type Description Default <code>feature</code> <code>Tensor</code> <p>Tensor with the input feature.</p> required <code>param</code> <code>Tensor</code> <p>Tensor with the parameter to calculate the gradient with respect to.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: Tensor with the gradient of the feature with respect to the given parameter.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; feature = torch.tensor([1, 2, 3], dtype=torch.float32)\n&gt;&gt;&gt; param = torch.tensor([2, 3, 4], dtype=torch.float32)\n&gt;&gt;&gt; gradient(feature, param)\ntensor([1., 1., 1.], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> Source code in <code>simulai/residuals/_pytorch_residuals.py</code> <pre><code>@staticmethod\ndef gradient(feature, param):\n    \"\"\"Calculates the gradient of the given feature with respect to the given parameter.\n\n    Args:\n        feature (torch.Tensor): Tensor with the input feature.\n        param (torch.Tensor): Tensor with the parameter to calculate the gradient with respect to.\n\n    Returns:\n        torch.Tensor: Tensor with the gradient of the feature with respect to the given parameter.\n    Example::\n\n        &gt;&gt;&gt; feature = torch.tensor([1, 2, 3], dtype=torch.float32)\n        &gt;&gt;&gt; param = torch.tensor([2, 3, 4], dtype=torch.float32)\n        &gt;&gt;&gt; gradient(feature, param)\n        tensor([1., 1., 1.], grad_fn=&lt;AddBackward0&gt;)\n    \"\"\"\n    grad_ = grad(\n        feature,\n        param,\n        grad_outputs=torch.ones_like(feature),\n        create_graph=True,\n        allow_unused=True,\n        retain_graph=True,\n    )\n\n    return grad_[0]\n</code></pre>"},{"location":"simulai_residuals/#simulai.residuals.SymbolicOperator.jac","title":"<code>jac(inputs)</code>","text":"<p>Calculates the Jacobian of the forward function of the model with respect to its inputs.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Tensor</code> <p>Tensor with the input data to the forward function.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: Tensor with the Jacobian of the forward function with respect to its inputs.</p> <p>Example::</p> <pre><code>&gt;&gt;&gt; inputs = torch.tensor([[1, 2, 3], [2, 3, 4]], dtype=torch.float32)\n&gt;&gt;&gt; jac(inputs)\ntensor([[1., 1., 1.],\n        [1., 1., 1.]], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> Source code in <code>simulai/residuals/_pytorch_residuals.py</code> <pre><code>def jac(self, inputs):\n    \"\"\"Calculates the Jacobian of the forward function of the model with respect to its inputs.\n\n    Args:\n        inputs (torch.Tensor): Tensor with the input data to the forward function.\n\n    Returns:\n        torch.Tensor: Tensor with the Jacobian of the forward function with respect to its inputs.\n    Example::\n\n        &gt;&gt;&gt; inputs = torch.tensor([[1, 2, 3], [2, 3, 4]], dtype=torch.float32)\n        &gt;&gt;&gt; jac(inputs)\n        tensor([[1., 1., 1.],\n                [1., 1., 1.]], grad_fn=&lt;MulBackward0&gt;)\n    \"\"\"\n\n    def inner(inputs):\n        return self.forward(input_data=inputs)\n\n    return jacobian(inner, inputs)\n</code></pre>"}]}